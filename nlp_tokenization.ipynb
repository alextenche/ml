{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/alex/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import sent_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"This is a test to see nltk in action. Should be interesting.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is a test to see nltk in action.', 'Should be interesting.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is a test to see nltk in action.', 'Should be interesting.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'test', 'to', 'see', 'nltk', 'in', 'action', '.', 'Should', 'be', 'interesting', '.']\n"
     ]
    }
   ],
   "source": [
    "words=nltk.word_tokenize(text)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please write a texttesting the length of a text\n",
      "the length of text is 6 words\n"
     ]
    }
   ],
   "source": [
    "r=input('please write a text')\n",
    "print('the length of text is', len(nltk.word_tokenize(r)), 'words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'is',\n",
       " 'a',\n",
       " 'test',\n",
       " 'to',\n",
       " 'see',\n",
       " 'nltk',\n",
       " 'in',\n",
       " 'action.',\n",
       " 'Should',\n",
       " 'be',\n",
       " 'interesting',\n",
       " '.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "treeTokenizer = TreebankWordTokenizer()\n",
    "treeTokenizer.tokenize(\"This is a test to see nltk in action. Should be interesting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Do', \"n't\", 'hesitate', 'to', 'ask', 'questions']\n"
     ]
    }
   ],
   "source": [
    "text=nltk.word_tokenize(\"Don't hesitate to ask questions\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Don', \"'\", 't', 'hesitate', 'to', 'ask', 'questions']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tokenizer=WordPunctTokenizer()\n",
    "tokenizer.tokenize(\"Don't hesitate to ask questions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['It', 'is', 'a', 'plesant', 'evening', '.'], ['Guests', ',', 'who', 'came', 'from', 'US', 'arrived', 'at', 'the', 'venue'], ['Food', 'was', 'tasty', '.']]\n"
     ]
    }
   ],
   "source": [
    "text=[\" It is a plesant evening.\", \"Guests, who came from US arrived at the venue\", \"Food was tasty.\"]\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokenized_docs=[word_tokenize(doc) for doc in text]\n",
    "print(tokenized_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Don', \"'t\", 'hesitate', 'to', 'ask', 'questions']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "sent=\"Don't hesitate to ask questions\"\n",
    "print(regexp_tokenize(sent, pattern='\\w+|\\$[\\d.]+|\\S+'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['She', 'She']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "sent=\" She secured 90.56 % in class X . She is a meritorious student\"\n",
    "capt=RegexpTokenizer('[A-Z]\\w+')\n",
    "capt.tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' She secured 90.56 % in class X . She is a meritorious student']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "sent=\" She secured 90.56 % in class X . She is a meritorious student\"\n",
    "from nltk.tokenize import BlanklineTokenizer\n",
    "BlanklineTokenizer().tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['She',\n",
       " 'secured',\n",
       " '90.56',\n",
       " '%',\n",
       " 'in',\n",
       " 'class',\n",
       " 'X',\n",
       " '.',\n",
       " 'She',\n",
       " 'is',\n",
       " 'a',\n",
       " 'meritorious',\n",
       " 'student']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "sent=\" She secured 90.56 % in class X . She is a meritorious student\"\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "WhitespaceTokenizer().tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['She', 'secured', '90.56', '%', 'in', 'class', 'X', '.', 'She', 'is', 'a', 'meritorious', 'student']\n",
      "['She', 'secured', '90.56', '%', 'in', 'class', 'X', '.', 'She', 'is', 'a', 'meritorious', 'student']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "sent=\"She secured 90.56 % in class X . She is a meritorious student\"\n",
    "print(sent.split())\n",
    "print(sent.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent=\"She secured 90.56 % in class X \\n. She is a meritorious student\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['She secured 90.56 % in class X ', '. She is a meritorious student', '']\n"
     ]
    }
   ],
   "source": [
    "print(sent.split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['She secured 90.56 % in class X ', '. She is a meritorious student']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import LineTokenizer\n",
    "LineTokenizer(blanklines='keep').tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['She secured 90.56 % in class X ', '. She is a meritorious student']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import LineTokenizer\n",
    "LineTokenizer(blanklines='discard').tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'She',\n",
       " 'secured',\n",
       " '90.56',\n",
       " '%',\n",
       " 'in',\n",
       " 'class',\n",
       " 'X',\n",
       " '\\n.',\n",
       " 'She',\n",
       " 'is',\n",
       " 'a',\n",
       " 'meritorious',\n",
       " 'student\\n']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "sent=\" She secured 90.56 % in class X \\n. She is a meritorious student\\n\"\n",
    "from nltk.tokenize import SpaceTokenizer\n",
    "SpaceTokenizer().tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 4),\n",
       " (5, 12),\n",
       " (13, 18),\n",
       " (19, 20),\n",
       " (21, 23),\n",
       " (24, 29),\n",
       " (30, 31),\n",
       " (33, 34),\n",
       " (35, 38),\n",
       " (39, 41),\n",
       " (42, 43),\n",
       " (44, 55),\n",
       " (56, 63)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "sent=\" She secured 90.56 % in class X \\n. She is a meritorious student\\n\"\n",
    "list(WhitespaceTokenizer().span_tokenize(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 3),\n",
       " (1, 7),\n",
       " (1, 5),\n",
       " (1, 1),\n",
       " (1, 2),\n",
       " (1, 5),\n",
       " (1, 1),\n",
       " (2, 1),\n",
       " (1, 3),\n",
       " (1, 2),\n",
       " (1, 1),\n",
       " (1, 11),\n",
       " (1, 7)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.tokenize.util import spans_to_relative\n",
    "sent=\" She secured 90.56 % in class X \\n. She is a meritorious student\\n\"\n",
    "list(spans_to_relative(WhitespaceTokenizer().span_tokenize(sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 4), (5, 12), (13, 18), (19, 20), (21, 23), (24, 29), (30, 31), (32, 34), (35, 38), (39, 41), (42, 43), (44, 55), (56, 64)]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize.util import string_span_tokenize\n",
    "sent=\" She secured 90.56 % in class X \\n. She is a meritorious student\\n\"\n",
    "print(list(string_span_tokenize(sent, \" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
