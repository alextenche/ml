{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import seed\n",
    "seed(42)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import boston_housing\n",
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 14        \n",
      "=================================================================\n",
      "Total params: 196\n",
      "Trainable params: 196\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "basic_model =  Sequential()\n",
    "basic_model.add(Dense(units=13, input_dim = 13, kernel_initializer='normal'))\n",
    "basic_model.add(Dense(units=1, kernel_initializer='normal', activation='linear'))\n",
    "basic_model.compile(optimizer=SGD(lr=0.00001), loss='mean_absolute_error', metrics=['accuracy'])\n",
    "basic_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 32)                448       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 993\n",
      "Trainable params: 993\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "advanced_model =  Sequential()\n",
    "advanced_model.add(Dense(units=32, input_dim = 13, kernel_initializer='truncated_normal'))\n",
    "advanced_model.add(Dense(units=16, kernel_initializer='truncated_normal'))\n",
    "advanced_model.add(Dense(units=1, kernel_initializer='truncated_normal'))\n",
    "advanced_model.compile(optimizer='adam', loss='mean_absolute_error', metrics=['accuracy'])\n",
    "advanced_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 363 samples, validate on 41 samples\n",
      "Epoch 1/100\n",
      "363/363 [==============================] - 0s 350us/step - loss: 20.9210 - acc: 0.0000e+00 - val_loss: 19.4423 - val_acc: 0.0244\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 32us/step - loss: 19.8208 - acc: 0.0055 - val_loss: 18.4733 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 24us/step - loss: 18.8247 - acc: 0.0000e+00 - val_loss: 17.5105 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 38us/step - loss: 17.8672 - acc: 0.0000e+00 - val_loss: 16.6172 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 47us/step - loss: 16.9736 - acc: 0.0000e+00 - val_loss: 15.8081 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 30us/step - loss: 16.1667 - acc: 0.0000e+00 - val_loss: 15.0702 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 28us/step - loss: 15.4722 - acc: 0.0000e+00 - val_loss: 14.4067 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 48us/step - loss: 14.8932 - acc: 0.0028 - val_loss: 13.8728 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 36us/step - loss: 14.4201 - acc: 0.0028 - val_loss: 13.3876 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 62us/step - loss: 13.9976 - acc: 0.0000e+00 - val_loss: 12.9279 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 42us/step - loss: 13.6053 - acc: 0.0000e+00 - val_loss: 12.5182 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 22us/step - loss: 13.2492 - acc: 0.0000e+00 - val_loss: 12.1339 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 40us/step - loss: 12.9102 - acc: 0.0000e+00 - val_loss: 11.7804 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 42us/step - loss: 12.5953 - acc: 0.0028 - val_loss: 11.4697 - val_acc: 0.0488\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 36us/step - loss: 12.2998 - acc: 0.0028 - val_loss: 11.2155 - val_acc: 0.0244\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 30us/step - loss: 12.0306 - acc: 0.0000e+00 - val_loss: 11.0074 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 68us/step - loss: 11.7797 - acc: 0.0000e+00 - val_loss: 10.7972 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 42us/step - loss: 11.5388 - acc: 0.0000e+00 - val_loss: 10.5910 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 46us/step - loss: 11.3186 - acc: 0.0000e+00 - val_loss: 10.3930 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 30us/step - loss: 11.1209 - acc: 0.0000e+00 - val_loss: 10.2023 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 26us/step - loss: 10.9393 - acc: 0.0000e+00 - val_loss: 10.0224 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 33us/step - loss: 10.7772 - acc: 0.0028 - val_loss: 9.8561 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 57us/step - loss: 10.6178 - acc: 0.0028 - val_loss: 9.7060 - val_acc: 0.0244\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 50us/step - loss: 10.4657 - acc: 0.0083 - val_loss: 9.5692 - val_acc: 0.0244\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 26us/step - loss: 10.3160 - acc: 0.0055 - val_loss: 9.4479 - val_acc: 0.0244\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 42us/step - loss: 10.1823 - acc: 0.0028 - val_loss: 9.3321 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 56us/step - loss: 10.0623 - acc: 0.0028 - val_loss: 9.2164 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 37us/step - loss: 9.9512 - acc: 0.0000e+00 - val_loss: 9.1069 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 34us/step - loss: 9.8494 - acc: 0.0028 - val_loss: 9.0004 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 43us/step - loss: 9.7519 - acc: 0.0028 - val_loss: 8.8940 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 44us/step - loss: 9.6585 - acc: 0.0028 - val_loss: 8.7859 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 66us/step - loss: 9.5629 - acc: 0.0028 - val_loss: 8.6796 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 31us/step - loss: 9.4702 - acc: 0.0028 - val_loss: 8.5783 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 21us/step - loss: 9.3830 - acc: 0.0000e+00 - val_loss: 8.4839 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 25us/step - loss: 9.3009 - acc: 0.0000e+00 - val_loss: 8.3940 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 23us/step - loss: 9.2238 - acc: 0.0000e+00 - val_loss: 8.3041 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 33us/step - loss: 9.1470 - acc: 0.0000e+00 - val_loss: 8.2184 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 20us/step - loss: 9.0739 - acc: 0.0028 - val_loss: 8.1354 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 26us/step - loss: 8.9975 - acc: 0.0000e+00 - val_loss: 8.0530 - val_acc: 0.0244\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 18us/step - loss: 8.9207 - acc: 0.0028 - val_loss: 7.9738 - val_acc: 0.0244\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 28us/step - loss: 8.8479 - acc: 0.0028 - val_loss: 7.8944 - val_acc: 0.0244\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 25us/step - loss: 8.7724 - acc: 0.0028 - val_loss: 7.8264 - val_acc: 0.0244\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 29us/step - loss: 8.7044 - acc: 0.0028 - val_loss: 7.7594 - val_acc: 0.0244\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 25us/step - loss: 8.6277 - acc: 0.0028 - val_loss: 7.6934 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 61us/step - loss: 8.5509 - acc: 0.0028 - val_loss: 7.6270 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 23us/step - loss: 8.4806 - acc: 0.0028 - val_loss: 7.5619 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 25us/step - loss: 8.4115 - acc: 0.0028 - val_loss: 7.4989 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 43us/step - loss: 8.3407 - acc: 0.0028 - val_loss: 7.4343 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 41us/step - loss: 8.2739 - acc: 0.0028 - val_loss: 7.3712 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 38us/step - loss: 8.2094 - acc: 0.0028 - val_loss: 7.3087 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 36us/step - loss: 8.1448 - acc: 0.0028 - val_loss: 7.2464 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 51us/step - loss: 8.0809 - acc: 0.0028 - val_loss: 7.1861 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 31us/step - loss: 8.0225 - acc: 0.0028 - val_loss: 7.1267 - val_acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 20us/step - loss: 7.9603 - acc: 0.0028 - val_loss: 7.0677 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 28us/step - loss: 7.9010 - acc: 0.0055 - val_loss: 7.0086 - val_acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 28us/step - loss: 7.8430 - acc: 0.0055 - val_loss: 6.9501 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 33us/step - loss: 7.7900 - acc: 0.0055 - val_loss: 6.8944 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 31us/step - loss: 7.7388 - acc: 0.0055 - val_loss: 6.8376 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 0s 37us/step - loss: 7.6848 - acc: 0.0055 - val_loss: 6.7777 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 43us/step - loss: 7.6302 - acc: 0.0055 - val_loss: 6.7228 - val_acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 33us/step - loss: 7.5783 - acc: 0.0083 - val_loss: 6.6687 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 27us/step - loss: 7.5374 - acc: 0.0083 - val_loss: 6.6191 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 0s 24us/step - loss: 7.4909 - acc: 0.0083 - val_loss: 6.5671 - val_acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 0s 29us/step - loss: 7.4546 - acc: 0.0083 - val_loss: 6.5167 - val_acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 0s 27us/step - loss: 7.4109 - acc: 0.0083 - val_loss: 6.4656 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 0s 20us/step - loss: 7.3725 - acc: 0.0055 - val_loss: 6.4157 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 0s 32us/step - loss: 7.3351 - acc: 0.0055 - val_loss: 6.3657 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 0s 22us/step - loss: 7.3022 - acc: 0.0055 - val_loss: 6.3181 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 0s 21us/step - loss: 7.2671 - acc: 0.0055 - val_loss: 6.2730 - val_acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 0s 32us/step - loss: 7.2421 - acc: 0.0055 - val_loss: 6.2295 - val_acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 0s 45us/step - loss: 7.2093 - acc: 0.0055 - val_loss: 6.1885 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 0s 45us/step - loss: 7.1868 - acc: 0.0028 - val_loss: 6.1475 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 0s 53us/step - loss: 7.1572 - acc: 0.0055 - val_loss: 6.1036 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 0s 22us/step - loss: 7.1284 - acc: 0.0028 - val_loss: 6.0628 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 0s 35us/step - loss: 7.1016 - acc: 0.0028 - val_loss: 6.0207 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 0s 21us/step - loss: 7.0752 - acc: 0.0000e+00 - val_loss: 5.9809 - val_acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 0s 25us/step - loss: 7.0487 - acc: 0.0000e+00 - val_loss: 5.9444 - val_acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 0s 21us/step - loss: 7.0276 - acc: 0.0000e+00 - val_loss: 5.9112 - val_acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 0s 33us/step - loss: 7.0054 - acc: 0.0000e+00 - val_loss: 5.8816 - val_acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 0s 38us/step - loss: 6.9843 - acc: 0.0000e+00 - val_loss: 5.8554 - val_acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 0s 23us/step - loss: 6.9661 - acc: 0.0000e+00 - val_loss: 5.8316 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 0s 26us/step - loss: 6.9452 - acc: 0.0000e+00 - val_loss: 5.8034 - val_acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 0s 40us/step - loss: 6.9232 - acc: 0.0055 - val_loss: 5.7792 - val_acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - ETA: 0s - loss: 8.5040 - acc: 0.0000e+0 - 0s 34us/step - loss: 6.9032 - acc: 0.0055 - val_loss: 5.7529 - val_acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 0s 21us/step - loss: 6.8862 - acc: 0.0055 - val_loss: 5.7274 - val_acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 0s 29us/step - loss: 6.8685 - acc: 0.0055 - val_loss: 5.7051 - val_acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 0s 29us/step - loss: 6.8522 - acc: 0.0055 - val_loss: 5.6837 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 0s 36us/step - loss: 6.8344 - acc: 0.0083 - val_loss: 5.6635 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 0s 40us/step - loss: 6.8170 - acc: 0.0083 - val_loss: 5.6391 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 0s 22us/step - loss: 6.8048 - acc: 0.0083 - val_loss: 5.6167 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 0s 31us/step - loss: 6.7906 - acc: 0.0083 - val_loss: 5.5984 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 0s 20us/step - loss: 6.7753 - acc: 0.0083 - val_loss: 5.5776 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 0s 24us/step - loss: 6.7632 - acc: 0.0083 - val_loss: 5.5552 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 0s 18us/step - loss: 6.7544 - acc: 0.0083 - val_loss: 5.5349 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 0s 26us/step - loss: 6.7406 - acc: 0.0083 - val_loss: 5.5149 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 0s 17us/step - loss: 6.7325 - acc: 0.0083 - val_loss: 5.4956 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 0s 35us/step - loss: 6.7205 - acc: 0.0138 - val_loss: 5.4777 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 0s 37us/step - loss: 6.7100 - acc: 0.0138 - val_loss: 5.4601 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 0s 23us/step - loss: 6.7014 - acc: 0.0138 - val_loss: 5.4455 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 0s 27us/step - loss: 6.6935 - acc: 0.0138 - val_loss: 5.4304 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbc5bb49898>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_model.fit(x_train, y_train, epochs=100, batch_size=64, verbose=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 363 samples, validate on 41 samples\n",
      "Epoch 1/100\n",
      "363/363 [==============================] - 0s 407us/step - loss: 19.9495 - acc: 0.0000e+00 - val_loss: 16.8427 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 46us/step - loss: 15.9285 - acc: 0.0000e+00 - val_loss: 12.1569 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 28us/step - loss: 11.5033 - acc: 0.0000e+00 - val_loss: 8.5518 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 27us/step - loss: 9.2861 - acc: 0.0055 - val_loss: 8.0599 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 42us/step - loss: 9.3891 - acc: 0.0055 - val_loss: 7.5297 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 49us/step - loss: 8.3678 - acc: 0.0055 - val_loss: 7.0186 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 20us/step - loss: 7.6683 - acc: 0.0055 - val_loss: 6.6296 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 42us/step - loss: 7.2375 - acc: 0.0000e+00 - val_loss: 5.9397 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 25us/step - loss: 6.7728 - acc: 0.0055 - val_loss: 5.3363 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 39us/step - loss: 6.4297 - acc: 0.0110 - val_loss: 5.0947 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 36us/step - loss: 6.2956 - acc: 0.0165 - val_loss: 5.0957 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 62us/step - loss: 6.1884 - acc: 0.0110 - val_loss: 4.6996 - val_acc: 0.0244\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 30us/step - loss: 6.1645 - acc: 0.0138 - val_loss: 4.9448 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 26us/step - loss: 6.1030 - acc: 0.0055 - val_loss: 4.8059 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 31us/step - loss: 6.0801 - acc: 0.0083 - val_loss: 4.7702 - val_acc: 0.0244\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 29us/step - loss: 6.0718 - acc: 0.0110 - val_loss: 4.7694 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 27us/step - loss: 6.0476 - acc: 0.0138 - val_loss: 4.9019 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 35us/step - loss: 6.0187 - acc: 0.0110 - val_loss: 4.6604 - val_acc: 0.0488\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 39us/step - loss: 6.0295 - acc: 0.0110 - val_loss: 4.7221 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 30us/step - loss: 6.0050 - acc: 0.0083 - val_loss: 4.9700 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 37us/step - loss: 6.0055 - acc: 0.0083 - val_loss: 4.6673 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 45us/step - loss: 5.9590 - acc: 0.0138 - val_loss: 4.8527 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 55us/step - loss: 5.9489 - acc: 0.0110 - val_loss: 4.7147 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 53us/step - loss: 5.9249 - acc: 0.0110 - val_loss: 4.7593 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 32us/step - loss: 5.9116 - acc: 0.0110 - val_loss: 4.7500 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 58us/step - loss: 5.8981 - acc: 0.0110 - val_loss: 4.7135 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 47us/step - loss: 5.9035 - acc: 0.0110 - val_loss: 4.7811 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 38us/step - loss: 5.8916 - acc: 0.0193 - val_loss: 4.4879 - val_acc: 0.0732\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 54us/step - loss: 5.8577 - acc: 0.0138 - val_loss: 4.8903 - val_acc: 0.0244\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 41us/step - loss: 5.8687 - acc: 0.0110 - val_loss: 4.6310 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 19us/step - loss: 5.8925 - acc: 0.0220 - val_loss: 4.6160 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 42us/step - loss: 5.8693 - acc: 0.0138 - val_loss: 4.7581 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 25us/step - loss: 5.8468 - acc: 0.0220 - val_loss: 4.5013 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 44us/step - loss: 5.8205 - acc: 0.0193 - val_loss: 4.8112 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 66us/step - loss: 5.8008 - acc: 0.0083 - val_loss: 4.5691 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 44us/step - loss: 5.8104 - acc: 0.0248 - val_loss: 4.6985 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 42us/step - loss: 5.9100 - acc: 0.0083 - val_loss: 4.6076 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 31us/step - loss: 5.8585 - acc: 0.0193 - val_loss: 4.5410 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 55us/step - loss: 5.8012 - acc: 0.0055 - val_loss: 4.8498 - val_acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 38us/step - loss: 5.7593 - acc: 0.0165 - val_loss: 4.4919 - val_acc: 0.0244\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 45us/step - loss: 5.7524 - acc: 0.0193 - val_loss: 4.7770 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 29us/step - loss: 5.7811 - acc: 0.0083 - val_loss: 4.6430 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 30us/step - loss: 5.7722 - acc: 0.0193 - val_loss: 4.5276 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 75us/step - loss: 5.6937 - acc: 0.0110 - val_loss: 4.7434 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 26us/step - loss: 5.6841 - acc: 0.0193 - val_loss: 4.4260 - val_acc: 0.0488\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 80us/step - loss: 5.7102 - acc: 0.0138 - val_loss: 4.7163 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 35us/step - loss: 5.6635 - acc: 0.0165 - val_loss: 4.5355 - val_acc: 0.0244\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 25us/step - loss: 5.6512 - acc: 0.0220 - val_loss: 4.6053 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 30us/step - loss: 5.6489 - acc: 0.0165 - val_loss: 4.5276 - val_acc: 0.0244\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 40us/step - loss: 5.6927 - acc: 0.0193 - val_loss: 4.5799 - val_acc: 0.0244\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 26us/step - loss: 5.6716 - acc: 0.0000e+00 - val_loss: 4.6750 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 54us/step - loss: 5.5929 - acc: 0.0193 - val_loss: 4.3291 - val_acc: 0.0488\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 23us/step - loss: 5.5845 - acc: 0.0193 - val_loss: 4.7695 - val_acc: 0.0244\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 30us/step - loss: 5.6849 - acc: 0.0055 - val_loss: 4.3436 - val_acc: 0.0488\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 31us/step - loss: 5.5978 - acc: 0.0220 - val_loss: 4.4941 - val_acc: 0.0244\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 30us/step - loss: 5.5503 - acc: 0.0193 - val_loss: 4.5840 - val_acc: 0.0244\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 43us/step - loss: 5.5560 - acc: 0.0138 - val_loss: 4.5262 - val_acc: 0.0244\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 27us/step - loss: 5.5326 - acc: 0.0193 - val_loss: 4.4806 - val_acc: 0.0244\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 34us/step - loss: 5.5259 - acc: 0.0138 - val_loss: 4.5110 - val_acc: 0.0244\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 0s 25us/step - loss: 5.4947 - acc: 0.0275 - val_loss: 4.4968 - val_acc: 0.0244\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 26us/step - loss: 5.4818 - acc: 0.0220 - val_loss: 4.5487 - val_acc: 0.0244\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 52us/step - loss: 5.4752 - acc: 0.0193 - val_loss: 4.5011 - val_acc: 0.0244\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 0s 28us/step - loss: 5.4971 - acc: 0.0138 - val_loss: 4.4383 - val_acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 0s 38us/step - loss: 5.4440 - acc: 0.0165 - val_loss: 4.4387 - val_acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 0s 28us/step - loss: 5.4226 - acc: 0.0220 - val_loss: 4.6875 - val_acc: 0.0488\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 0s 39us/step - loss: 5.4775 - acc: 0.0110 - val_loss: 4.3910 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 0s 30us/step - loss: 5.3884 - acc: 0.0165 - val_loss: 4.4619 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 0s 33us/step - loss: 5.3704 - acc: 0.0110 - val_loss: 4.5092 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 0s 26us/step - loss: 5.3864 - acc: 0.0193 - val_loss: 4.5842 - val_acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 0s 25us/step - loss: 5.4243 - acc: 0.0083 - val_loss: 4.3275 - val_acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 0s 43us/step - loss: 5.3964 - acc: 0.0165 - val_loss: 4.4379 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 0s 39us/step - loss: 5.2992 - acc: 0.0193 - val_loss: 4.6899 - val_acc: 0.0244\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 0s 34us/step - loss: 5.2722 - acc: 0.0193 - val_loss: 4.4088 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 0s 46us/step - loss: 5.2538 - acc: 0.0193 - val_loss: 4.5321 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 0s 48us/step - loss: 5.2398 - acc: 0.0110 - val_loss: 4.4552 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 0s 34us/step - loss: 5.2283 - acc: 0.0165 - val_loss: 4.6885 - val_acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 0s 30us/step - loss: 5.2508 - acc: 0.0138 - val_loss: 4.2195 - val_acc: 0.0488\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 0s 48us/step - loss: 5.2505 - acc: 0.0138 - val_loss: 4.7065 - val_acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 0s 23us/step - loss: 5.1663 - acc: 0.0138 - val_loss: 4.4060 - val_acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 0s 28us/step - loss: 5.1511 - acc: 0.0165 - val_loss: 4.4325 - val_acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 0s 34us/step - loss: 5.1563 - acc: 0.0193 - val_loss: 4.3474 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 0s 38us/step - loss: 5.1494 - acc: 0.0165 - val_loss: 4.6572 - val_acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 0s 25us/step - loss: 5.1354 - acc: 0.0055 - val_loss: 4.2876 - val_acc: 0.0488\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 0s 27us/step - loss: 5.1340 - acc: 0.0110 - val_loss: 4.7836 - val_acc: 0.0244\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 0s 44us/step - loss: 5.0569 - acc: 0.0138 - val_loss: 4.2312 - val_acc: 0.0488\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 0s 37us/step - loss: 5.0766 - acc: 0.0083 - val_loss: 4.8387 - val_acc: 0.0244\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 0s 39us/step - loss: 5.1433 - acc: 0.0110 - val_loss: 4.2648 - val_acc: 0.0488\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 0s 44us/step - loss: 5.0299 - acc: 0.0083 - val_loss: 4.6268 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 0s 45us/step - loss: 4.9745 - acc: 0.0083 - val_loss: 4.3620 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 0s 27us/step - loss: 5.0063 - acc: 0.0083 - val_loss: 4.5996 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 0s 41us/step - loss: 4.9671 - acc: 0.0165 - val_loss: 4.4371 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 0s 31us/step - loss: 4.9554 - acc: 0.0138 - val_loss: 4.5894 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 0s 43us/step - loss: 4.9673 - acc: 0.0138 - val_loss: 4.4871 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 0s 30us/step - loss: 4.8958 - acc: 0.0165 - val_loss: 4.4084 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 0s 27us/step - loss: 4.9560 - acc: 0.0138 - val_loss: 4.3956 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 0s 27us/step - loss: 4.9471 - acc: 0.0055 - val_loss: 4.5690 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 0s 48us/step - loss: 4.8828 - acc: 0.0138 - val_loss: 4.6644 - val_acc: 0.0244\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 0s 35us/step - loss: 4.8685 - acc: 0.0028 - val_loss: 4.4680 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 0s 51us/step - loss: 4.8789 - acc: 0.0138 - val_loss: 4.2091 - val_acc: 0.0488\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 0s 45us/step - loss: 4.8289 - acc: 0.0083 - val_loss: 4.8153 - val_acc: 0.0244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbc5bb49cf8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advanced_model.fit(x_train, y_train, epochs=100, batch_size=64, verbose=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model):\n",
    "    evaluation = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('loss on test dataset: %.2f ' % (evaluation[0]))\n",
    "    print('accuracy on test dataset: %.2f ' % (evaluation[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test basic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on test dataset: 7.08 \n",
      "accuracy on test dataset: 0.01 \n"
     ]
    }
   ],
   "source": [
    "test_model(basic_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test advanced_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on test dataset: 5.28 \n",
      "accuracy on test dataset: 0.01 \n"
     ]
    }
   ],
   "source": [
    "test_model(advanced_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 64)                896       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 3,009\n",
      "Trainable params: 3,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "improved_model =  Sequential()\n",
    "improved_model.add(Dense(units=64, input_dim = 13, kernel_initializer='truncated_normal', activation='relu'))\n",
    "improved_model.add(Dense(units=32, kernel_initializer='truncated_normal', activation='relu'))\n",
    "improved_model.add(Dense(units=1, kernel_initializer='truncated_normal'))\n",
    "improved_model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "improved_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 363 samples, validate on 41 samples\n",
      "Epoch 1/150\n",
      "363/363 [==============================] - 0s 510us/step - loss: 512.3928 - mean_absolute_error: 20.3985 - val_loss: 299.0138 - val_mean_absolute_error: 15.6096\n",
      "Epoch 2/150\n",
      "363/363 [==============================] - 0s 67us/step - loss: 261.6654 - mean_absolute_error: 13.0784 - val_loss: 102.9550 - val_mean_absolute_error: 8.6858\n",
      "Epoch 3/150\n",
      "363/363 [==============================] - 0s 86us/step - loss: 149.9675 - mean_absolute_error: 9.3276 - val_loss: 100.2686 - val_mean_absolute_error: 7.9100\n",
      "Epoch 4/150\n",
      "363/363 [==============================] - 0s 75us/step - loss: 129.2075 - mean_absolute_error: 8.5334 - val_loss: 67.7793 - val_mean_absolute_error: 7.0543\n",
      "Epoch 5/150\n",
      "363/363 [==============================] - 0s 69us/step - loss: 110.5709 - mean_absolute_error: 7.5988 - val_loss: 54.0448 - val_mean_absolute_error: 6.2639\n",
      "Epoch 6/150\n",
      "363/363 [==============================] - 0s 71us/step - loss: 95.8000 - mean_absolute_error: 6.9408 - val_loss: 43.0705 - val_mean_absolute_error: 5.4837\n",
      "Epoch 7/150\n",
      "363/363 [==============================] - 0s 55us/step - loss: 82.8125 - mean_absolute_error: 6.3660 - val_loss: 34.1066 - val_mean_absolute_error: 4.7978\n",
      "Epoch 8/150\n",
      "363/363 [==============================] - 0s 74us/step - loss: 75.3096 - mean_absolute_error: 5.8961 - val_loss: 28.6398 - val_mean_absolute_error: 4.2034\n",
      "Epoch 9/150\n",
      "363/363 [==============================] - 0s 83us/step - loss: 69.5586 - mean_absolute_error: 5.8359 - val_loss: 26.2835 - val_mean_absolute_error: 3.9647\n",
      "Epoch 10/150\n",
      "363/363 [==============================] - 0s 80us/step - loss: 67.0708 - mean_absolute_error: 5.6279 - val_loss: 25.6332 - val_mean_absolute_error: 3.9236\n",
      "Epoch 11/150\n",
      "363/363 [==============================] - 0s 47us/step - loss: 65.7430 - mean_absolute_error: 5.7009 - val_loss: 25.2271 - val_mean_absolute_error: 3.8872\n",
      "Epoch 12/150\n",
      "363/363 [==============================] - 0s 57us/step - loss: 64.9224 - mean_absolute_error: 5.7072 - val_loss: 24.5209 - val_mean_absolute_error: 3.8394\n",
      "Epoch 13/150\n",
      "363/363 [==============================] - 0s 115us/step - loss: 64.1507 - mean_absolute_error: 5.7324 - val_loss: 23.6669 - val_mean_absolute_error: 3.7708\n",
      "Epoch 14/150\n",
      "363/363 [==============================] - 0s 65us/step - loss: 63.1329 - mean_absolute_error: 5.5582 - val_loss: 23.1450 - val_mean_absolute_error: 3.7399\n",
      "Epoch 15/150\n",
      "363/363 [==============================] - 0s 101us/step - loss: 62.2813 - mean_absolute_error: 5.4540 - val_loss: 22.7475 - val_mean_absolute_error: 3.7254\n",
      "Epoch 16/150\n",
      "363/363 [==============================] - 0s 63us/step - loss: 61.4489 - mean_absolute_error: 5.5839 - val_loss: 21.9345 - val_mean_absolute_error: 3.6552\n",
      "Epoch 17/150\n",
      "363/363 [==============================] - 0s 61us/step - loss: 61.7776 - mean_absolute_error: 5.1682 - val_loss: 22.1448 - val_mean_absolute_error: 3.7152\n",
      "Epoch 18/150\n",
      "363/363 [==============================] - 0s 65us/step - loss: 60.7405 - mean_absolute_error: 5.6808 - val_loss: 20.7517 - val_mean_absolute_error: 3.5846\n",
      "Epoch 19/150\n",
      "363/363 [==============================] - 0s 77us/step - loss: 59.8050 - mean_absolute_error: 5.1556 - val_loss: 22.4977 - val_mean_absolute_error: 3.7850\n",
      "Epoch 20/150\n",
      "363/363 [==============================] - 0s 88us/step - loss: 58.0344 - mean_absolute_error: 5.3474 - val_loss: 19.6352 - val_mean_absolute_error: 3.5247\n",
      "Epoch 21/150\n",
      "363/363 [==============================] - 0s 92us/step - loss: 56.4102 - mean_absolute_error: 5.1935 - val_loss: 20.8445 - val_mean_absolute_error: 3.6684\n",
      "Epoch 22/150\n",
      "363/363 [==============================] - 0s 76us/step - loss: 56.2340 - mean_absolute_error: 5.3089 - val_loss: 19.1597 - val_mean_absolute_error: 3.4939\n",
      "Epoch 23/150\n",
      "363/363 [==============================] - 0s 109us/step - loss: 55.5230 - mean_absolute_error: 5.1750 - val_loss: 18.7924 - val_mean_absolute_error: 3.4666\n",
      "Epoch 24/150\n",
      "363/363 [==============================] - 0s 46us/step - loss: 54.6048 - mean_absolute_error: 5.0066 - val_loss: 18.6708 - val_mean_absolute_error: 3.4818\n",
      "Epoch 25/150\n",
      "363/363 [==============================] - 0s 76us/step - loss: 53.1246 - mean_absolute_error: 5.0136 - val_loss: 18.1914 - val_mean_absolute_error: 3.4304\n",
      "Epoch 26/150\n",
      "363/363 [==============================] - 0s 49us/step - loss: 54.8947 - mean_absolute_error: 5.4094 - val_loss: 19.0378 - val_mean_absolute_error: 3.4625\n",
      "Epoch 27/150\n",
      "363/363 [==============================] - 0s 50us/step - loss: 53.0141 - mean_absolute_error: 4.9766 - val_loss: 17.9939 - val_mean_absolute_error: 3.3979\n",
      "Epoch 28/150\n",
      "363/363 [==============================] - 0s 57us/step - loss: 51.1924 - mean_absolute_error: 4.8954 - val_loss: 17.4256 - val_mean_absolute_error: 3.3512\n",
      "Epoch 29/150\n",
      "363/363 [==============================] - 0s 71us/step - loss: 49.2811 - mean_absolute_error: 4.9278 - val_loss: 17.9024 - val_mean_absolute_error: 3.3745\n",
      "Epoch 30/150\n",
      "363/363 [==============================] - 0s 73us/step - loss: 48.3915 - mean_absolute_error: 4.7934 - val_loss: 17.5348 - val_mean_absolute_error: 3.3390\n",
      "Epoch 31/150\n",
      "363/363 [==============================] - 0s 79us/step - loss: 47.2612 - mean_absolute_error: 4.6843 - val_loss: 18.0101 - val_mean_absolute_error: 3.4070\n",
      "Epoch 32/150\n",
      "363/363 [==============================] - 0s 83us/step - loss: 46.3701 - mean_absolute_error: 4.6630 - val_loss: 17.1317 - val_mean_absolute_error: 3.3168\n",
      "Epoch 33/150\n",
      "363/363 [==============================] - 0s 98us/step - loss: 46.0775 - mean_absolute_error: 4.9272 - val_loss: 21.7285 - val_mean_absolute_error: 3.5478\n",
      "Epoch 34/150\n",
      "363/363 [==============================] - 0s 47us/step - loss: 46.2384 - mean_absolute_error: 4.4969 - val_loss: 29.7765 - val_mean_absolute_error: 4.5428\n",
      "Epoch 35/150\n",
      "363/363 [==============================] - 0s 45us/step - loss: 47.7144 - mean_absolute_error: 4.9057 - val_loss: 17.1297 - val_mean_absolute_error: 3.2189\n",
      "Epoch 36/150\n",
      "363/363 [==============================] - 0s 91us/step - loss: 43.5020 - mean_absolute_error: 4.6783 - val_loss: 17.2898 - val_mean_absolute_error: 3.2024\n",
      "Epoch 37/150\n",
      "363/363 [==============================] - 0s 88us/step - loss: 41.8167 - mean_absolute_error: 4.4649 - val_loss: 16.8141 - val_mean_absolute_error: 3.1958\n",
      "Epoch 38/150\n",
      "363/363 [==============================] - 0s 63us/step - loss: 40.1755 - mean_absolute_error: 4.3454 - val_loss: 16.9409 - val_mean_absolute_error: 3.1271\n",
      "Epoch 39/150\n",
      "363/363 [==============================] - 0s 68us/step - loss: 39.4881 - mean_absolute_error: 4.3492 - val_loss: 22.8208 - val_mean_absolute_error: 3.8039\n",
      "Epoch 40/150\n",
      "363/363 [==============================] - 0s 88us/step - loss: 39.2309 - mean_absolute_error: 4.3727 - val_loss: 18.0016 - val_mean_absolute_error: 3.2908\n",
      "Epoch 41/150\n",
      "363/363 [==============================] - 0s 85us/step - loss: 37.7732 - mean_absolute_error: 4.2245 - val_loss: 24.2254 - val_mean_absolute_error: 3.8823\n",
      "Epoch 42/150\n",
      "363/363 [==============================] - 0s 56us/step - loss: 41.7363 - mean_absolute_error: 4.4999 - val_loss: 24.1059 - val_mean_absolute_error: 3.8981\n",
      "Epoch 43/150\n",
      "363/363 [==============================] - 0s 53us/step - loss: 37.8506 - mean_absolute_error: 4.3798 - val_loss: 18.2449 - val_mean_absolute_error: 3.1841\n",
      "Epoch 44/150\n",
      "363/363 [==============================] - 0s 70us/step - loss: 38.1580 - mean_absolute_error: 4.4016 - val_loss: 18.2630 - val_mean_absolute_error: 3.0449\n",
      "Epoch 45/150\n",
      "363/363 [==============================] - 0s 50us/step - loss: 33.5813 - mean_absolute_error: 4.3243 - val_loss: 21.2290 - val_mean_absolute_error: 3.2699\n",
      "Epoch 46/150\n",
      "363/363 [==============================] - 0s 58us/step - loss: 35.2743 - mean_absolute_error: 4.1854 - val_loss: 19.1353 - val_mean_absolute_error: 3.1615\n",
      "Epoch 47/150\n",
      "363/363 [==============================] - 0s 73us/step - loss: 35.3463 - mean_absolute_error: 4.1820 - val_loss: 23.5299 - val_mean_absolute_error: 3.7022\n",
      "Epoch 48/150\n",
      "363/363 [==============================] - 0s 69us/step - loss: 32.3267 - mean_absolute_error: 3.9632 - val_loss: 22.1780 - val_mean_absolute_error: 3.5134\n",
      "Epoch 49/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 0s 63us/step - loss: 32.5283 - mean_absolute_error: 4.0772 - val_loss: 19.8869 - val_mean_absolute_error: 3.1947\n",
      "Epoch 50/150\n",
      "363/363 [==============================] - 0s 62us/step - loss: 30.2912 - mean_absolute_error: 4.0475 - val_loss: 20.2395 - val_mean_absolute_error: 3.1177\n",
      "Epoch 51/150\n",
      "363/363 [==============================] - 0s 62us/step - loss: 30.5440 - mean_absolute_error: 3.8862 - val_loss: 23.6539 - val_mean_absolute_error: 3.6223\n",
      "Epoch 52/150\n",
      "363/363 [==============================] - 0s 76us/step - loss: 30.1149 - mean_absolute_error: 4.0496 - val_loss: 20.3159 - val_mean_absolute_error: 3.2030\n",
      "Epoch 53/150\n",
      "363/363 [==============================] - 0s 80us/step - loss: 28.5634 - mean_absolute_error: 3.9044 - val_loss: 21.0737 - val_mean_absolute_error: 3.2622\n",
      "Epoch 54/150\n",
      "363/363 [==============================] - 0s 47us/step - loss: 28.8715 - mean_absolute_error: 3.9544 - val_loss: 21.2009 - val_mean_absolute_error: 3.1205\n",
      "Epoch 55/150\n",
      "363/363 [==============================] - 0s 62us/step - loss: 27.1759 - mean_absolute_error: 3.8618 - val_loss: 20.7273 - val_mean_absolute_error: 3.0783\n",
      "Epoch 56/150\n",
      "363/363 [==============================] - 0s 88us/step - loss: 26.9462 - mean_absolute_error: 3.8152 - val_loss: 20.8711 - val_mean_absolute_error: 3.1939\n",
      "Epoch 57/150\n",
      "363/363 [==============================] - 0s 47us/step - loss: 27.4119 - mean_absolute_error: 3.8170 - val_loss: 22.6630 - val_mean_absolute_error: 3.4114\n",
      "Epoch 58/150\n",
      "363/363 [==============================] - 0s 48us/step - loss: 25.7755 - mean_absolute_error: 3.8447 - val_loss: 22.1156 - val_mean_absolute_error: 3.1004\n",
      "Epoch 59/150\n",
      "363/363 [==============================] - 0s 63us/step - loss: 25.2646 - mean_absolute_error: 3.7517 - val_loss: 20.8681 - val_mean_absolute_error: 3.0834\n",
      "Epoch 60/150\n",
      "363/363 [==============================] - 0s 65us/step - loss: 24.1507 - mean_absolute_error: 3.6987 - val_loss: 23.0419 - val_mean_absolute_error: 3.1890\n",
      "Epoch 61/150\n",
      "363/363 [==============================] - 0s 68us/step - loss: 25.0010 - mean_absolute_error: 3.7670 - val_loss: 23.0981 - val_mean_absolute_error: 3.2635\n",
      "Epoch 62/150\n",
      "363/363 [==============================] - 0s 51us/step - loss: 24.2528 - mean_absolute_error: 3.6760 - val_loss: 22.3083 - val_mean_absolute_error: 3.1978\n",
      "Epoch 63/150\n",
      "363/363 [==============================] - 0s 53us/step - loss: 23.6230 - mean_absolute_error: 3.5987 - val_loss: 20.8615 - val_mean_absolute_error: 3.0966\n",
      "Epoch 64/150\n",
      "363/363 [==============================] - 0s 69us/step - loss: 25.0942 - mean_absolute_error: 3.7463 - val_loss: 21.2567 - val_mean_absolute_error: 3.2777\n",
      "Epoch 65/150\n",
      "363/363 [==============================] - 0s 78us/step - loss: 24.7555 - mean_absolute_error: 3.7180 - val_loss: 20.7205 - val_mean_absolute_error: 3.1490\n",
      "Epoch 66/150\n",
      "363/363 [==============================] - 0s 59us/step - loss: 23.0362 - mean_absolute_error: 3.6371 - val_loss: 21.3668 - val_mean_absolute_error: 3.3012\n",
      "Epoch 67/150\n",
      "363/363 [==============================] - 0s 87us/step - loss: 22.4564 - mean_absolute_error: 3.5594 - val_loss: 21.3260 - val_mean_absolute_error: 3.1333\n",
      "Epoch 68/150\n",
      "363/363 [==============================] - 0s 54us/step - loss: 21.8294 - mean_absolute_error: 3.4721 - val_loss: 20.5876 - val_mean_absolute_error: 3.0279\n",
      "Epoch 69/150\n",
      "363/363 [==============================] - 0s 45us/step - loss: 22.8992 - mean_absolute_error: 3.5810 - val_loss: 19.7181 - val_mean_absolute_error: 2.9957\n",
      "Epoch 70/150\n",
      "363/363 [==============================] - 0s 41us/step - loss: 20.5454 - mean_absolute_error: 3.4181 - val_loss: 20.6382 - val_mean_absolute_error: 3.0811\n",
      "Epoch 71/150\n",
      "363/363 [==============================] - 0s 62us/step - loss: 20.1443 - mean_absolute_error: 3.3435 - val_loss: 20.0809 - val_mean_absolute_error: 3.0167\n",
      "Epoch 72/150\n",
      "363/363 [==============================] - 0s 82us/step - loss: 19.9980 - mean_absolute_error: 3.3323 - val_loss: 19.7652 - val_mean_absolute_error: 2.9613\n",
      "Epoch 73/150\n",
      "363/363 [==============================] - 0s 57us/step - loss: 19.8174 - mean_absolute_error: 3.3341 - val_loss: 21.7626 - val_mean_absolute_error: 3.1819\n",
      "Epoch 74/150\n",
      "363/363 [==============================] - 0s 48us/step - loss: 19.5456 - mean_absolute_error: 3.2656 - val_loss: 20.1285 - val_mean_absolute_error: 3.1446\n",
      "Epoch 75/150\n",
      "363/363 [==============================] - 0s 74us/step - loss: 19.6868 - mean_absolute_error: 3.2611 - val_loss: 19.5028 - val_mean_absolute_error: 2.9461\n",
      "Epoch 76/150\n",
      "363/363 [==============================] - 0s 78us/step - loss: 18.8605 - mean_absolute_error: 3.2350 - val_loss: 19.8336 - val_mean_absolute_error: 3.0149\n",
      "Epoch 77/150\n",
      "363/363 [==============================] - 0s 58us/step - loss: 18.5631 - mean_absolute_error: 3.2051 - val_loss: 19.7972 - val_mean_absolute_error: 3.0306\n",
      "Epoch 78/150\n",
      "363/363 [==============================] - 0s 43us/step - loss: 18.2656 - mean_absolute_error: 3.1610 - val_loss: 19.8005 - val_mean_absolute_error: 3.0523\n",
      "Epoch 79/150\n",
      "363/363 [==============================] - 0s 63us/step - loss: 18.1530 - mean_absolute_error: 3.1855 - val_loss: 20.8088 - val_mean_absolute_error: 3.1171\n",
      "Epoch 80/150\n",
      "363/363 [==============================] - 0s 41us/step - loss: 21.4665 - mean_absolute_error: 3.3901 - val_loss: 19.9829 - val_mean_absolute_error: 3.0787\n",
      "Epoch 81/150\n",
      "363/363 [==============================] - 0s 83us/step - loss: 18.2940 - mean_absolute_error: 3.1629 - val_loss: 19.9013 - val_mean_absolute_error: 3.0834\n",
      "Epoch 82/150\n",
      "363/363 [==============================] - 0s 64us/step - loss: 18.3976 - mean_absolute_error: 3.1845 - val_loss: 18.7412 - val_mean_absolute_error: 3.0619\n",
      "Epoch 83/150\n",
      "363/363 [==============================] - 0s 61us/step - loss: 17.2149 - mean_absolute_error: 3.0662 - val_loss: 18.4372 - val_mean_absolute_error: 3.0072\n",
      "Epoch 84/150\n",
      "363/363 [==============================] - 0s 86us/step - loss: 17.8064 - mean_absolute_error: 3.1620 - val_loss: 19.1426 - val_mean_absolute_error: 3.0691\n",
      "Epoch 85/150\n",
      "363/363 [==============================] - 0s 62us/step - loss: 16.9547 - mean_absolute_error: 3.0296 - val_loss: 21.3633 - val_mean_absolute_error: 3.2355\n",
      "Epoch 86/150\n",
      "363/363 [==============================] - 0s 69us/step - loss: 16.9993 - mean_absolute_error: 3.0614 - val_loss: 19.8684 - val_mean_absolute_error: 3.0973\n",
      "Epoch 87/150\n",
      "363/363 [==============================] - 0s 50us/step - loss: 15.6753 - mean_absolute_error: 2.9316 - val_loss: 18.9032 - val_mean_absolute_error: 3.1815\n",
      "Epoch 88/150\n",
      "363/363 [==============================] - 0s 71us/step - loss: 17.4479 - mean_absolute_error: 3.1151 - val_loss: 19.1340 - val_mean_absolute_error: 3.1605\n",
      "Epoch 89/150\n",
      "363/363 [==============================] - 0s 63us/step - loss: 16.3402 - mean_absolute_error: 3.0106 - val_loss: 19.4836 - val_mean_absolute_error: 3.3497\n",
      "Epoch 90/150\n",
      "363/363 [==============================] - 0s 38us/step - loss: 22.5964 - mean_absolute_error: 3.3372 - val_loss: 22.0885 - val_mean_absolute_error: 3.6679\n",
      "Epoch 91/150\n",
      "363/363 [==============================] - 0s 54us/step - loss: 20.7785 - mean_absolute_error: 3.3243 - val_loss: 18.3132 - val_mean_absolute_error: 3.1650\n",
      "Epoch 92/150\n",
      "363/363 [==============================] - 0s 82us/step - loss: 18.8362 - mean_absolute_error: 3.1844 - val_loss: 17.9000 - val_mean_absolute_error: 3.0503\n",
      "Epoch 93/150\n",
      "363/363 [==============================] - 0s 58us/step - loss: 16.3441 - mean_absolute_error: 2.9721 - val_loss: 20.5090 - val_mean_absolute_error: 3.4610\n",
      "Epoch 94/150\n",
      "363/363 [==============================] - 0s 52us/step - loss: 17.3581 - mean_absolute_error: 3.0687 - val_loss: 17.6695 - val_mean_absolute_error: 2.9423\n",
      "Epoch 95/150\n",
      "363/363 [==============================] - 0s 59us/step - loss: 16.1076 - mean_absolute_error: 2.9390 - val_loss: 17.9440 - val_mean_absolute_error: 3.1576\n",
      "Epoch 96/150\n",
      "363/363 [==============================] - 0s 54us/step - loss: 16.5882 - mean_absolute_error: 3.0866 - val_loss: 17.6080 - val_mean_absolute_error: 2.9571\n",
      "Epoch 97/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 0s 94us/step - loss: 16.0956 - mean_absolute_error: 2.9553 - val_loss: 16.8236 - val_mean_absolute_error: 3.0798\n",
      "Epoch 98/150\n",
      "363/363 [==============================] - 0s 64us/step - loss: 15.5025 - mean_absolute_error: 2.9315 - val_loss: 19.1372 - val_mean_absolute_error: 3.1350\n",
      "Epoch 99/150\n",
      "363/363 [==============================] - 0s 56us/step - loss: 15.1052 - mean_absolute_error: 2.8875 - val_loss: 20.9897 - val_mean_absolute_error: 3.3247\n",
      "Epoch 100/150\n",
      "363/363 [==============================] - 0s 77us/step - loss: 15.6079 - mean_absolute_error: 3.0196 - val_loss: 20.2258 - val_mean_absolute_error: 3.2484\n",
      "Epoch 101/150\n",
      "363/363 [==============================] - 0s 76us/step - loss: 15.6788 - mean_absolute_error: 2.8922 - val_loss: 17.6967 - val_mean_absolute_error: 3.0425\n",
      "Epoch 102/150\n",
      "363/363 [==============================] - 0s 55us/step - loss: 15.3578 - mean_absolute_error: 2.8743 - val_loss: 16.8997 - val_mean_absolute_error: 2.9804\n",
      "Epoch 103/150\n",
      "363/363 [==============================] - 0s 51us/step - loss: 14.7400 - mean_absolute_error: 2.8709 - val_loss: 20.1078 - val_mean_absolute_error: 3.2336\n",
      "Epoch 104/150\n",
      "363/363 [==============================] - 0s 64us/step - loss: 14.7283 - mean_absolute_error: 2.8242 - val_loss: 17.2530 - val_mean_absolute_error: 2.9776\n",
      "Epoch 105/150\n",
      "363/363 [==============================] - 0s 57us/step - loss: 15.0796 - mean_absolute_error: 2.8739 - val_loss: 16.8454 - val_mean_absolute_error: 3.0022\n",
      "Epoch 106/150\n",
      "363/363 [==============================] - 0s 57us/step - loss: 14.7396 - mean_absolute_error: 2.8484 - val_loss: 20.6797 - val_mean_absolute_error: 3.3268\n",
      "Epoch 107/150\n",
      "363/363 [==============================] - 0s 89us/step - loss: 20.1207 - mean_absolute_error: 3.2736 - val_loss: 23.2751 - val_mean_absolute_error: 3.5814\n",
      "Epoch 108/150\n",
      "363/363 [==============================] - 0s 38us/step - loss: 17.1641 - mean_absolute_error: 3.0735 - val_loss: 18.9470 - val_mean_absolute_error: 3.1561\n",
      "Epoch 109/150\n",
      "363/363 [==============================] - 0s 64us/step - loss: 14.8913 - mean_absolute_error: 2.8533 - val_loss: 16.6839 - val_mean_absolute_error: 2.9183\n",
      "Epoch 110/150\n",
      "363/363 [==============================] - 0s 62us/step - loss: 14.4565 - mean_absolute_error: 2.7755 - val_loss: 19.0715 - val_mean_absolute_error: 3.1690\n",
      "Epoch 111/150\n",
      "363/363 [==============================] - 0s 52us/step - loss: 14.2457 - mean_absolute_error: 2.7769 - val_loss: 16.4308 - val_mean_absolute_error: 2.9901\n",
      "Epoch 112/150\n",
      "363/363 [==============================] - 0s 64us/step - loss: 14.6458 - mean_absolute_error: 2.8176 - val_loss: 16.4501 - val_mean_absolute_error: 3.0072\n",
      "Epoch 113/150\n",
      "363/363 [==============================] - 0s 65us/step - loss: 15.6703 - mean_absolute_error: 2.8358 - val_loss: 16.5304 - val_mean_absolute_error: 3.0920\n",
      "Epoch 114/150\n",
      "363/363 [==============================] - 0s 47us/step - loss: 14.7067 - mean_absolute_error: 2.8519 - val_loss: 17.1728 - val_mean_absolute_error: 3.2216\n",
      "Epoch 115/150\n",
      "363/363 [==============================] - 0s 60us/step - loss: 19.5413 - mean_absolute_error: 3.2756 - val_loss: 16.1707 - val_mean_absolute_error: 3.1558\n",
      "Epoch 116/150\n",
      "363/363 [==============================] - 0s 41us/step - loss: 17.1412 - mean_absolute_error: 3.1274 - val_loss: 17.5112 - val_mean_absolute_error: 3.0028\n",
      "Epoch 117/150\n",
      "363/363 [==============================] - 0s 41us/step - loss: 17.9953 - mean_absolute_error: 3.0914 - val_loss: 15.2371 - val_mean_absolute_error: 2.9021\n",
      "Epoch 118/150\n",
      "363/363 [==============================] - 0s 50us/step - loss: 15.1931 - mean_absolute_error: 2.9068 - val_loss: 18.7074 - val_mean_absolute_error: 3.1370\n",
      "Epoch 119/150\n",
      "363/363 [==============================] - 0s 65us/step - loss: 15.1749 - mean_absolute_error: 2.7847 - val_loss: 16.5275 - val_mean_absolute_error: 3.0500\n",
      "Epoch 120/150\n",
      "363/363 [==============================] - 0s 58us/step - loss: 14.0150 - mean_absolute_error: 2.7391 - val_loss: 16.9202 - val_mean_absolute_error: 2.9900\n",
      "Epoch 121/150\n",
      "363/363 [==============================] - 0s 62us/step - loss: 14.1863 - mean_absolute_error: 2.7735 - val_loss: 16.1690 - val_mean_absolute_error: 2.9492\n",
      "Epoch 122/150\n",
      "363/363 [==============================] - 0s 66us/step - loss: 14.8083 - mean_absolute_error: 2.8382 - val_loss: 16.4976 - val_mean_absolute_error: 2.9848\n",
      "Epoch 123/150\n",
      "363/363 [==============================] - 0s 76us/step - loss: 15.7383 - mean_absolute_error: 2.9354 - val_loss: 15.7163 - val_mean_absolute_error: 2.9449\n",
      "Epoch 124/150\n",
      "363/363 [==============================] - 0s 84us/step - loss: 17.3339 - mean_absolute_error: 2.9106 - val_loss: 16.4757 - val_mean_absolute_error: 3.1261\n",
      "Epoch 125/150\n",
      "363/363 [==============================] - 0s 52us/step - loss: 15.0496 - mean_absolute_error: 2.8341 - val_loss: 15.4898 - val_mean_absolute_error: 2.9286\n",
      "Epoch 126/150\n",
      "363/363 [==============================] - 0s 75us/step - loss: 13.7367 - mean_absolute_error: 2.6912 - val_loss: 15.9784 - val_mean_absolute_error: 2.9966\n",
      "Epoch 127/150\n",
      "363/363 [==============================] - 0s 65us/step - loss: 13.9171 - mean_absolute_error: 2.6945 - val_loss: 17.9364 - val_mean_absolute_error: 3.3674\n",
      "Epoch 128/150\n",
      "363/363 [==============================] - 0s 76us/step - loss: 19.0409 - mean_absolute_error: 3.0106 - val_loss: 16.2491 - val_mean_absolute_error: 3.1724\n",
      "Epoch 129/150\n",
      "363/363 [==============================] - 0s 82us/step - loss: 15.5188 - mean_absolute_error: 2.8327 - val_loss: 15.5498 - val_mean_absolute_error: 3.0087\n",
      "Epoch 130/150\n",
      "363/363 [==============================] - 0s 79us/step - loss: 19.7471 - mean_absolute_error: 3.1890 - val_loss: 15.4157 - val_mean_absolute_error: 3.1036\n",
      "Epoch 131/150\n",
      "363/363 [==============================] - 0s 56us/step - loss: 14.3881 - mean_absolute_error: 2.7988 - val_loss: 16.7203 - val_mean_absolute_error: 2.9988\n",
      "Epoch 132/150\n",
      "363/363 [==============================] - 0s 62us/step - loss: 13.9226 - mean_absolute_error: 2.7199 - val_loss: 15.6876 - val_mean_absolute_error: 2.9605\n",
      "Epoch 133/150\n",
      "363/363 [==============================] - 0s 65us/step - loss: 15.0107 - mean_absolute_error: 2.8437 - val_loss: 15.5536 - val_mean_absolute_error: 3.0296\n",
      "Epoch 134/150\n",
      "363/363 [==============================] - 0s 60us/step - loss: 14.1537 - mean_absolute_error: 2.7584 - val_loss: 14.3350 - val_mean_absolute_error: 2.8569\n",
      "Epoch 135/150\n",
      "363/363 [==============================] - 0s 70us/step - loss: 13.8007 - mean_absolute_error: 2.7388 - val_loss: 15.2714 - val_mean_absolute_error: 2.9660\n",
      "Epoch 136/150\n",
      "363/363 [==============================] - 0s 69us/step - loss: 13.7307 - mean_absolute_error: 2.6917 - val_loss: 14.5273 - val_mean_absolute_error: 2.9114\n",
      "Epoch 137/150\n",
      "363/363 [==============================] - 0s 44us/step - loss: 13.8811 - mean_absolute_error: 2.7150 - val_loss: 15.4219 - val_mean_absolute_error: 3.1063\n",
      "Epoch 138/150\n",
      "363/363 [==============================] - 0s 65us/step - loss: 14.8922 - mean_absolute_error: 2.9116 - val_loss: 15.5390 - val_mean_absolute_error: 2.9602\n",
      "Epoch 139/150\n",
      "363/363 [==============================] - 0s 48us/step - loss: 13.8135 - mean_absolute_error: 2.6936 - val_loss: 14.6377 - val_mean_absolute_error: 3.0061\n",
      "Epoch 140/150\n",
      "363/363 [==============================] - 0s 56us/step - loss: 14.1766 - mean_absolute_error: 2.7256 - val_loss: 15.1126 - val_mean_absolute_error: 2.8911\n",
      "Epoch 141/150\n",
      "363/363 [==============================] - 0s 100us/step - loss: 13.8709 - mean_absolute_error: 2.6944 - val_loss: 14.3647 - val_mean_absolute_error: 2.8269\n",
      "Epoch 142/150\n",
      "363/363 [==============================] - 0s 39us/step - loss: 14.2554 - mean_absolute_error: 2.8235 - val_loss: 16.1370 - val_mean_absolute_error: 2.9542\n",
      "Epoch 143/150\n",
      "363/363 [==============================] - 0s 61us/step - loss: 13.5743 - mean_absolute_error: 2.7121 - val_loss: 15.6179 - val_mean_absolute_error: 2.9290\n",
      "Epoch 144/150\n",
      "363/363 [==============================] - 0s 59us/step - loss: 14.3416 - mean_absolute_error: 2.8059 - val_loss: 19.0405 - val_mean_absolute_error: 3.2445\n",
      "Epoch 145/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 0s 50us/step - loss: 13.6061 - mean_absolute_error: 2.7219 - val_loss: 14.9227 - val_mean_absolute_error: 2.8878\n",
      "Epoch 146/150\n",
      "363/363 [==============================] - 0s 87us/step - loss: 13.1740 - mean_absolute_error: 2.6627 - val_loss: 15.1736 - val_mean_absolute_error: 2.8497\n",
      "Epoch 147/150\n",
      "363/363 [==============================] - 0s 67us/step - loss: 14.4785 - mean_absolute_error: 2.7832 - val_loss: 13.8844 - val_mean_absolute_error: 2.7954\n",
      "Epoch 148/150\n",
      "363/363 [==============================] - 0s 89us/step - loss: 14.3885 - mean_absolute_error: 2.8092 - val_loss: 14.5522 - val_mean_absolute_error: 2.8484\n",
      "Epoch 149/150\n",
      "363/363 [==============================] - 0s 57us/step - loss: 15.1931 - mean_absolute_error: 2.7902 - val_loss: 15.2005 - val_mean_absolute_error: 3.0960\n",
      "Epoch 150/150\n",
      "363/363 [==============================] - 0s 72us/step - loss: 15.7155 - mean_absolute_error: 2.8533 - val_loss: 19.5552 - val_mean_absolute_error: 3.5989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbc5bb49a58>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "improved_model.fit(x_train, y_train, epochs=150, batch_size=32, verbose=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on test dataset: 41.94 \n",
      "accuracy on test dataset: 4.71 \n"
     ]
    }
   ],
   "source": [
    "test_model(improved_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_prediction(model):\n",
    "    train_houses = [x_train[0:1], x_train[10:11], x_train[200:201]]\n",
    "    train_actual_prices = [y_train[0:1], y_train[10], y_train[200]]\n",
    "    print('\\n')\n",
    "    print('training set points:')\n",
    "    \n",
    "    for house, price in zip(train_houses, train_actual_prices):\n",
    "        prediction = model.predict(house)\n",
    "        print('predicted price:', prediction, 'actual price:', price)\n",
    "        \n",
    "    test_houses = [x_test[1:2], x_test[50:51], x_test[100:101]]\n",
    "    test_actual_prices = [y_test[1], y_test[50], y_test[100]]\n",
    "    print('\\n')\n",
    "    print('testing set points:')\n",
    "    \n",
    "    for house, price in zip(test_houses, test_actual_prices):\n",
    "        prediction = model.predict(house)\n",
    "        print('predicted price:', prediction, 'actual price:', price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "training set points:\n",
      "predicted price: [[19.843292]] actual price: [15.2]\n",
      "predicted price: [[16.705534]] actual price: 12.1\n",
      "predicted price: [[27.013702]] actual price: 23.9\n",
      "\n",
      "\n",
      "testing set points:\n",
      "predicted price: [[20.860035]] actual price: 18.8\n",
      "predicted price: [[35.63442]] actual price: 35.4\n",
      "predicted price: [[31.832033]] actual price: 26.7\n"
     ]
    }
   ],
   "source": [
    "check_prediction(improved_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
