{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_feature = pd.Series(['sunny', 'cloudy', 'snowy', 'foggy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = pd.get_dummies(categorical_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cloudy</th>\n",
       "      <th>foggy</th>\n",
       "      <th>snowy</th>\n",
       "      <th>sunny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cloudy  foggy  snowy  sunny\n",
       "0       0      0      0      1\n",
       "1       1      0      0      0\n",
       "2       0      0      1      0\n",
       "3       0      1      0      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "ohe = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = ['sunny', 'cloudy', 'snowy', 'rainy', 'foggy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_levels = le.fit_transform(levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features='all', dtype=<class 'numpy.float64'>,\n",
       "       handle_unknown='error', n_values='auto', sparse=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.fit([[fit_levels[0]], [fit_levels[1]], [fit_levels[2]], [fit_levels[3]], [fit_levels[4]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.transform([le.transform(['sunny'])]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.transform([le.transform(['cloudy'])]).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### working with text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['sci.med', 'sci.space']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty_sci_news = fetch_20newsgroups(categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['/home/alex/scikit_learn_data/20news_home/20news-bydate-train/sci.space/61116',\n",
       "       '/home/alex/scikit_learn_data/20news_home/20news-bydate-train/sci.med/58122',\n",
       "       '/home/alex/scikit_learn_data/20news_home/20news-bydate-train/sci.med/58903',\n",
       "       ...,\n",
       "       '/home/alex/scikit_learn_data/20news_home/20news-bydate-train/sci.space/60774',\n",
       "       '/home/alex/scikit_learn_data/20news_home/20news-bydate-train/sci.space/60954',\n",
       "       '/home/alex/scikit_learn_data/20news_home/20news-bydate-train/sci.med/58911'],\n",
       "      dtype='<U91')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_sci_news.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_sci_news.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sci.med', 'sci.space']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_sci_news.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "word_count = count_vect.fit_transform(twenty_sci_news.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1187, 25638)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 10778)\t1\n",
      "  (0, 23849)\t1\n",
      "  (0, 9796)\t1\n",
      "  (0, 12716)\t1\n",
      "  (0, 18586)\t1\n",
      "  (0, 13384)\t1\n",
      "  (0, 5134)\t1\n",
      "  (0, 10785)\t1\n",
      "  (0, 15246)\t1\n",
      "  (0, 11330)\t1\n",
      "  (0, 5148)\t1\n",
      "  (0, 13318)\t1\n",
      "  (0, 18744)\t1\n",
      "  (0, 20110)\t1\n",
      "  (0, 18642)\t1\n",
      "  (0, 3808)\t2\n",
      "  (0, 10188)\t1\n",
      "  (0, 6017)\t3\n",
      "  (0, 24930)\t1\n",
      "  (0, 18474)\t1\n",
      "  (0, 23241)\t1\n",
      "  (0, 23129)\t1\n",
      "  (0, 3191)\t1\n",
      "  (0, 12362)\t1\n",
      "  (0, 15968)\t1\n",
      "  :\t:\n",
      "  (0, 7646)\t1\n",
      "  (0, 24547)\t1\n",
      "  (0, 24415)\t1\n",
      "  (0, 13359)\t1\n",
      "  (0, 20909)\t1\n",
      "  (0, 17235)\t1\n",
      "  (0, 24151)\t1\n",
      "  (0, 13158)\t1\n",
      "  (0, 24626)\t1\n",
      "  (0, 17217)\t1\n",
      "  (0, 8438)\t1\n",
      "  (0, 21686)\t2\n",
      "  (0, 5650)\t3\n",
      "  (0, 10713)\t1\n",
      "  (0, 3233)\t1\n",
      "  (0, 21382)\t1\n",
      "  (0, 23137)\t7\n",
      "  (0, 24461)\t1\n",
      "  (0, 22345)\t1\n",
      "  (0, 23381)\t2\n",
      "  (0, 4762)\t2\n",
      "  (0, 10341)\t1\n",
      "  (0, 17170)\t1\n",
      "  (0, 10501)\t2\n",
      "  (0, 10827)\t2\n"
     ]
    }
   ],
   "source": [
    "print(word_count[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word \"fred\" appears 1 times\n",
      "word \"twilight\" appears 1 times\n",
      "word \"evening\" appears 1 times\n",
      "word \"in\" appears 1 times\n",
      "word \"presence\" appears 1 times\n",
      "word \"its\" appears 1 times\n",
      "word \"blare\" appears 1 times\n",
      "word \"freely\" appears 1 times\n",
      "word \"may\" appears 1 times\n",
      "word \"god\" appears 1 times\n",
      "word \"blessed\" appears 1 times\n",
      "word \"is\" appears 1 times\n",
      "word \"profiting\" appears 1 times\n",
      "word \"right\" appears 1 times\n",
      "word \"priesthood\" appears 1 times\n",
      "word \"and\" appears 2 times\n",
      "word \"farming\" appears 1 times\n",
      "word \"caste\" appears 3 times\n",
      "word \"warrior\" appears 1 times\n",
      "word \"practiced\" appears 1 times\n",
      "word \"those\" appears 1 times\n",
      "word \"than\" appears 1 times\n",
      "word \"activities\" appears 1 times\n",
      "word \"human\" appears 1 times\n",
      "word \"more\" appears 1 times\n",
      "word \"are\" appears 1 times\n",
      "word \"there\" appears 1 times\n",
      "word \"that\" appears 1 times\n",
      "word \"remember\" appears 1 times\n",
      "word \"to\" appears 1 times\n",
      "word \"try\" appears 1 times\n",
      "word \"please\" appears 1 times\n",
      "word \"age\" appears 1 times\n",
      "word \"bronze\" appears 1 times\n",
      "word \"isn\" appears 1 times\n",
      "word \"this\" appears 1 times\n",
      "word \"finally\" appears 1 times\n",
      "word \"usl\" appears 1 times\n",
      "word \"cacs\" appears 1 times\n",
      "word \"srl03\" appears 1 times\n",
      "word \"pgf\" appears 1 times\n",
      "word \"fraering\" appears 1 times\n",
      "word \"phil\" appears 1 times\n",
      "word \"12\" appears 1 times\n",
      "word \"lines\" appears 1 times\n",
      "word \"sci\" appears 1 times\n",
      "word \"distribution\" appears 1 times\n",
      "word \"edu\" appears 2 times\n",
      "word \"cmu\" appears 1 times\n",
      "word \"cs\" appears 1 times\n",
      "word \"venari\" appears 1 times\n",
      "word \"vacation\" appears 1 times\n",
      "word \"isu\" appears 1 times\n",
      "word \"sender\" appears 1 times\n",
      "word \"original\" appears 1 times\n",
      "word \"university\" appears 1 times\n",
      "word \"international\" appears 1 times\n",
      "word \"via\" appears 1 times\n",
      "word \"organization\" appears 1 times\n",
      "word \"digest\" appears 1 times\n",
      "word \"space\" appears 2 times\n",
      "word \"by\" appears 3 times\n",
      "word \"forwarded\" appears 1 times\n",
      "word \"added\" appears 1 times\n",
      "word \"sky\" appears 1 times\n",
      "word \"the\" appears 7 times\n",
      "word \"vandalizing\" appears 1 times\n",
      "word \"subject\" appears 1 times\n",
      "word \"tm\" appears 2 times\n",
      "word \"baube\" appears 2 times\n",
      "word \"fi\" appears 1 times\n",
      "word \"optiplan\" appears 1 times\n",
      "word \"flb\" appears 2 times\n",
      "word \"from\" appears 2 times\n"
     ]
    }
   ],
   "source": [
    "word_list = count_vect.get_feature_names()\n",
    "for n in word_count[0].indices:\n",
    "    print('word \"%s\" appears %i times' % (word_list[n], word_count[0, n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word \"fred\" has frequency 0.011\n",
      "word \"twilight\" has frequency 0.011\n",
      "word \"evening\" has frequency 0.011\n",
      "word \"in\" has frequency 0.011\n",
      "word \"presence\" has frequency 0.011\n",
      "word \"its\" has frequency 0.011\n",
      "word \"blare\" has frequency 0.011\n",
      "word \"freely\" has frequency 0.011\n",
      "word \"may\" has frequency 0.011\n",
      "word \"god\" has frequency 0.011\n",
      "word \"blessed\" has frequency 0.011\n",
      "word \"is\" has frequency 0.011\n",
      "word \"profiting\" has frequency 0.011\n",
      "word \"right\" has frequency 0.011\n",
      "word \"priesthood\" has frequency 0.011\n",
      "word \"and\" has frequency 0.022\n",
      "word \"farming\" has frequency 0.011\n",
      "word \"caste\" has frequency 0.033\n",
      "word \"warrior\" has frequency 0.011\n",
      "word \"practiced\" has frequency 0.011\n",
      "word \"those\" has frequency 0.011\n",
      "word \"than\" has frequency 0.011\n",
      "word \"activities\" has frequency 0.011\n",
      "word \"human\" has frequency 0.011\n",
      "word \"more\" has frequency 0.011\n",
      "word \"are\" has frequency 0.011\n",
      "word \"there\" has frequency 0.011\n",
      "word \"that\" has frequency 0.011\n",
      "word \"remember\" has frequency 0.011\n",
      "word \"to\" has frequency 0.011\n",
      "word \"try\" has frequency 0.011\n",
      "word \"please\" has frequency 0.011\n",
      "word \"age\" has frequency 0.011\n",
      "word \"bronze\" has frequency 0.011\n",
      "word \"isn\" has frequency 0.011\n",
      "word \"this\" has frequency 0.011\n",
      "word \"finally\" has frequency 0.011\n",
      "word \"usl\" has frequency 0.011\n",
      "word \"cacs\" has frequency 0.011\n",
      "word \"srl03\" has frequency 0.011\n",
      "word \"pgf\" has frequency 0.011\n",
      "word \"fraering\" has frequency 0.011\n",
      "word \"phil\" has frequency 0.011\n",
      "word \"12\" has frequency 0.011\n",
      "word \"lines\" has frequency 0.011\n",
      "word \"sci\" has frequency 0.011\n",
      "word \"distribution\" has frequency 0.011\n",
      "word \"edu\" has frequency 0.022\n",
      "word \"cmu\" has frequency 0.011\n",
      "word \"cs\" has frequency 0.011\n",
      "word \"venari\" has frequency 0.011\n",
      "word \"vacation\" has frequency 0.011\n",
      "word \"isu\" has frequency 0.011\n",
      "word \"sender\" has frequency 0.011\n",
      "word \"original\" has frequency 0.011\n",
      "word \"university\" has frequency 0.011\n",
      "word \"international\" has frequency 0.011\n",
      "word \"via\" has frequency 0.011\n",
      "word \"organization\" has frequency 0.011\n",
      "word \"digest\" has frequency 0.011\n",
      "word \"space\" has frequency 0.022\n",
      "word \"by\" has frequency 0.033\n",
      "word \"forwarded\" has frequency 0.011\n",
      "word \"added\" has frequency 0.011\n",
      "word \"sky\" has frequency 0.011\n",
      "word \"the\" has frequency 0.077\n",
      "word \"vandalizing\" has frequency 0.011\n",
      "word \"subject\" has frequency 0.011\n",
      "word \"tm\" has frequency 0.022\n",
      "word \"baube\" has frequency 0.022\n",
      "word \"fi\" has frequency 0.011\n",
      "word \"optiplan\" has frequency 0.011\n",
      "word \"flb\" has frequency 0.022\n",
      "word \"from\" has frequency 0.022\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf_vect = TfidfVectorizer(use_idf=False, norm='l1')\n",
    "word_freq = tf_vect.fit_transform(twenty_sci_news.data)\n",
    "word_list = tf_vect.get_feature_names()\n",
    "for n in word_freq[0].indices:\n",
    "    print('word \"%s\" has frequency %0.3f' % (word_list[n], word_freq[0, n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word \"fred\" has tf-idf 0.089\n",
      "word \"twilight\" has tf-idf 0.139\n",
      "word \"evening\" has tf-idf 0.113\n",
      "word \"in\" has tf-idf 0.024\n",
      "word \"presence\" has tf-idf 0.119\n",
      "word \"its\" has tf-idf 0.061\n",
      "word \"blare\" has tf-idf 0.150\n",
      "word \"freely\" has tf-idf 0.119\n",
      "word \"may\" has tf-idf 0.054\n",
      "word \"god\" has tf-idf 0.119\n",
      "word \"blessed\" has tf-idf 0.150\n",
      "word \"is\" has tf-idf 0.026\n",
      "word \"profiting\" has tf-idf 0.150\n",
      "word \"right\" has tf-idf 0.068\n",
      "word \"priesthood\" has tf-idf 0.144\n",
      "word \"and\" has tf-idf 0.049\n",
      "word \"farming\" has tf-idf 0.144\n",
      "word \"caste\" has tf-idf 0.433\n",
      "word \"warrior\" has tf-idf 0.144\n",
      "word \"practiced\" has tf-idf 0.132\n",
      "word \"those\" has tf-idf 0.060\n",
      "word \"than\" has tf-idf 0.052\n",
      "word \"activities\" has tf-idf 0.091\n",
      "word \"human\" has tf-idf 0.084\n",
      "word \"more\" has tf-idf 0.046\n",
      "word \"are\" has tf-idf 0.035\n",
      "word \"there\" has tf-idf 0.039\n",
      "word \"that\" has tf-idf 0.027\n",
      "word \"remember\" has tf-idf 0.077\n",
      "word \"to\" has tf-idf 0.023\n",
      "word \"try\" has tf-idf 0.073\n",
      "word \"please\" has tf-idf 0.071\n",
      "word \"age\" has tf-idf 0.092\n",
      "word \"bronze\" has tf-idf 0.144\n",
      "word \"isn\" has tf-idf 0.073\n",
      "word \"this\" has tf-idf 0.031\n",
      "word \"finally\" has tf-idf 0.097\n",
      "word \"usl\" has tf-idf 0.112\n",
      "word \"cacs\" has tf-idf 0.114\n",
      "word \"srl03\" has tf-idf 0.121\n",
      "word \"pgf\" has tf-idf 0.114\n",
      "word \"fraering\" has tf-idf 0.113\n",
      "word \"phil\" has tf-idf 0.102\n",
      "word \"12\" has tf-idf 0.076\n",
      "word \"lines\" has tf-idf 0.022\n",
      "word \"sci\" has tf-idf 0.067\n",
      "word \"distribution\" has tf-idf 0.053\n",
      "word \"edu\" has tf-idf 0.059\n",
      "word \"cmu\" has tf-idf 0.081\n",
      "word \"cs\" has tf-idf 0.055\n",
      "word \"venari\" has tf-idf 0.103\n",
      "word \"vacation\" has tf-idf 0.099\n",
      "word \"isu\" has tf-idf 0.099\n",
      "word \"sender\" has tf-idf 0.093\n",
      "word \"original\" has tf-idf 0.085\n",
      "word \"university\" has tf-idf 0.045\n",
      "word \"international\" has tf-idf 0.081\n",
      "word \"via\" has tf-idf 0.083\n",
      "word \"organization\" has tf-idf 0.022\n",
      "word \"digest\" has tf-idf 0.095\n",
      "word \"space\" has tf-idf 0.098\n",
      "word \"by\" has tf-idf 0.120\n",
      "word \"forwarded\" has tf-idf 0.096\n",
      "word \"added\" has tf-idf 0.088\n",
      "word \"sky\" has tf-idf 0.091\n",
      "word \"the\" has tf-idf 0.158\n",
      "word \"vandalizing\" has tf-idf 0.103\n",
      "word \"subject\" has tf-idf 0.022\n",
      "word \"tm\" has tf-idf 0.219\n",
      "word \"baube\" has tf-idf 0.264\n",
      "word \"fi\" has tf-idf 0.110\n",
      "word \"optiplan\" has tf-idf 0.132\n",
      "word \"flb\" has tf-idf 0.264\n",
      "word \"from\" has tf-idf 0.043\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "word_tfidf = tfidf_vect.fit_transform(twenty_sci_news.data)\n",
    "word_list = tfidf_vect.get_feature_names()\n",
    "for n in word_freq[0].indices:\n",
    "    print('word \"%s\" has tf-idf %0.3f' % (word_list[n], word_tfidf[0, n]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_1 = \"we love data science\"\n",
    "text_2 = \"data science is hard\"\n",
    "documents = [text_1, text_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['we love data science', 'data science is hard']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word list = ['data', 'hard', 'is', 'love', 'science', 'we']\n",
      "text_1 is described with ['science(1)', 'data(1)', 'love(1)', 'we(1)']\n"
     ]
    }
   ],
   "source": [
    "count_vect_1_grams = CountVectorizer(ngram_range=(1, 1), stop_words=[], min_df=1)\n",
    "word_count = count_vect_1_grams.fit_transform(documents)\n",
    "word_list = count_vect_1_grams.get_feature_names()\n",
    "print('word list =', word_list)\n",
    "print('text_1 is described with', [word_list[n] + '(' + str(word_count[0, n]) + ')' for n in word_count[0].indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word list = ['data science', 'is hard', 'love data', 'science is', 'we love']\n",
      "text_1 is described with ['data science(1)', 'love data(1)', 'we love(1)']\n"
     ]
    }
   ],
   "source": [
    "count_vect_2_grams = CountVectorizer(ngram_range=(2, 2))\n",
    "word_count = count_vect_2_grams.fit_transform(documents)\n",
    "word_list = count_vect_2_grams.get_feature_names()\n",
    "print('word list =', word_list)\n",
    "print('text_1 is described with', [word_list[n] + '(' + str(word_count[0, n]) + ')' for n in word_count[0].indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word list = ['data', 'data science', 'hard', 'is', 'is hard', 'love', 'love data', 'science', 'science is', 'we', 'we love']\n",
      "text_1 is described with ['data science(1)', 'love data(1)', 'we love(1)', 'science(1)', 'data(1)', 'love(1)', 'we(1)']\n"
     ]
    }
   ],
   "source": [
    "count_vect_12_grams = CountVectorizer(ngram_range=(1, 2))\n",
    "word_count = count_vect_12_grams.fit_transform(documents)\n",
    "word_list = count_vect_12_grams.get_feature_names()\n",
    "print('word list =', word_list)\n",
    "print('text_1 is described with', [word_list[n] + '(' + str(word_count[0, n]) + ')' for n in word_count[0].indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1187, 1000)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "hash_vect = HashingVectorizer(n_features=1000)\n",
    "word_hashed = hash_vect.fit_transform(twenty_sci_news.data)\n",
    "word_hashed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### scraping the web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/William_Shakespeare'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = urllib.request.Request(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = urllib.request.urlopen(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>William Shakespeare - Wikipedia</title>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category:Sonnets by William Shakespeare -> /wiki/Category:Sonnets_by_William_Shakespeare\n",
      "Category:William Shakespeare -> /wiki/Category:William_Shakespeare\n",
      "Category:1564 births -> /wiki/Category:1564_births\n",
      "Category:1616 deaths -> /wiki/Category:1616_deaths\n",
      "Category:16th-century English male actors -> /wiki/Category:16th-century_English_male_actors\n",
      "Category:English male stage actors -> /wiki/Category:English_male_stage_actors\n",
      "Category:16th-century English writers -> /wiki/Category:16th-century_English_writers\n",
      "Category:17th-century English writers -> /wiki/Category:17th-century_English_writers\n",
      "Category:16th-century dramatists and playwrights -> /wiki/Category:16th-century_dramatists_and_playwrights\n",
      "Category:17th-century English dramatists and playwrights -> /wiki/Category:17th-century_English_dramatists_and_playwrights\n",
      "Category:16th-century English poets -> /wiki/Category:16th-century_English_poets\n",
      "Category:Burials in Warwickshire -> /wiki/Category:Burials_in_Warwickshire\n",
      "Category:People from Warwickshire -> /wiki/Category:People_from_Warwickshire\n",
      "Category:17th-century English poets -> /wiki/Category:17th-century_English_poets\n",
      "Category:English Renaissance dramatists -> /wiki/Category:English_Renaissance_dramatists\n",
      "Category:English male writers -> /wiki/Category:English_male_writers\n",
      "Category:People educated at King Edward VI School, Stratford-upon-Avon -> /wiki/Category:People_educated_at_King_Edward_VI_School,_Stratford-upon-Avon\n",
      "Category:People from Stratford-upon-Avon -> /wiki/Category:People_from_Stratford-upon-Avon\n",
      "Category:People of the Elizabethan era -> /wiki/Category:People_of_the_Elizabethan_era\n",
      "Category:People of the Stuart period -> /wiki/Category:People_of_the_Stuart_period\n",
      "Category:Shakespeare family -> /wiki/Category:Shakespeare_family\n",
      "Category:Sonneteers -> /wiki/Category:Sonneteers\n",
      "Category:King's Men (playing company) -> /wiki/Category:King%27s_Men_(playing_company)\n",
      "Category:17th-century English male actors -> /wiki/Category:17th-century_English_male_actors\n",
      "Category:English male dramatists and playwrights -> /wiki/Category:English_male_dramatists_and_playwrights\n",
      "Category:English male poets -> /wiki/Category:English_male_poets\n"
     ]
    }
   ],
   "source": [
    "section = soup.find_all(id='mw-normal-catlinks')[0]\n",
    "for catlink in section.find_all('a')[1:]:\n",
    "    print(catlink.get('title'), '->', catlink.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
