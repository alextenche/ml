{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_length = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = np.random.standard_normal(size=time_series_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(10, batch_input_shape=(1, 1, 1), stateful=True))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (1, 10)                   480       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, 1)                    11        \n",
      "=================================================================\n",
      "Total params: 491\n",
      "Trainable params: 491\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.reshape(ts[:-1], (-1, 1, 1))\n",
    "y = np.reshape(ts[1:], (-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49671415]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[[[0.49671415]]]\n",
      "[[-0.1382643]]\n",
      "training for step = 0, loss = 0.0228892769664526\n",
      "1\n",
      "[[[-0.1382643]]]\n",
      "[[0.64768854]]\n",
      "training for step = 1, loss = 0.4214095175266266\n",
      "2\n",
      "[[[0.64768854]]]\n",
      "[[1.52302986]]\n",
      "training for step = 2, loss = 2.28518009185791\n",
      "3\n",
      "[[[1.52302986]]]\n",
      "[[-0.23415337]]\n",
      "training for step = 3, loss = 0.06810179352760315\n",
      "4\n",
      "[[[-0.23415337]]]\n",
      "[[-0.23413696]]\n",
      "training for step = 4, loss = 0.0531013049185276\n",
      "5\n",
      "[[[-0.23413696]]]\n",
      "[[1.57921282]]\n",
      "training for step = 5, loss = 2.579643726348877\n",
      "6\n",
      "[[[1.57921282]]]\n",
      "[[0.76743473]]\n",
      "training for step = 6, loss = 0.5874403119087219\n",
      "7\n",
      "[[[0.76743473]]]\n",
      "[[-0.46947439]]\n",
      "training for step = 7, loss = 0.2252785861492157\n",
      "8\n",
      "[[[-0.46947439]]]\n",
      "[[0.54256004]]\n",
      "training for step = 8, loss = 0.33423808217048645\n",
      "9\n",
      "[[[0.54256004]]]\n",
      "[[-0.46341769]]\n",
      "training for step = 9, loss = 0.19392457604408264\n",
      "10\n",
      "[[[-0.46341769]]]\n",
      "[[-0.46572975]]\n",
      "training for step = 10, loss = 0.17453229427337646\n",
      "11\n",
      "[[[-0.46572975]]]\n",
      "[[0.24196227]]\n",
      "training for step = 11, loss = 0.08890490233898163\n",
      "12\n",
      "[[[0.24196227]]]\n",
      "[[-1.91328024]]\n",
      "training for step = 12, loss = 3.5443034172058105\n",
      "13\n",
      "[[[-1.91328024]]]\n",
      "[[-1.72491783]]\n",
      "training for step = 13, loss = 2.6179118156433105\n",
      "14\n",
      "[[[-1.72491783]]]\n",
      "[[-0.56228753]]\n",
      "training for step = 14, loss = 0.19447414577007294\n",
      "15\n",
      "[[[-0.56228753]]]\n",
      "[[-1.01283112]]\n",
      "training for step = 15, loss = 0.8785551190376282\n",
      "16\n",
      "[[[-1.01283112]]]\n",
      "[[0.31424733]]\n",
      "training for step = 16, loss = 0.14654524624347687\n",
      "17\n",
      "[[[0.31424733]]]\n",
      "[[-0.90802408]]\n",
      "training for step = 17, loss = 0.8016810417175293\n",
      "18\n",
      "[[[-0.90802408]]]\n",
      "[[-1.4123037]]\n",
      "training for step = 18, loss = 1.9238529205322266\n",
      "19\n",
      "[[[-1.4123037]]]\n",
      "[[1.46564877]]\n",
      "training for step = 19, loss = 2.3175265789031982\n",
      "20\n",
      "[[[1.46564877]]]\n",
      "[[-0.2257763]]\n",
      "training for step = 20, loss = 0.05787017196416855\n",
      "21\n",
      "[[[-0.2257763]]]\n",
      "[[0.0675282]]\n",
      "training for step = 21, loss = 0.0026655804831534624\n",
      "22\n",
      "[[[0.0675282]]]\n",
      "[[-1.42474819]]\n",
      "training for step = 22, loss = 2.089580535888672\n",
      "23\n",
      "[[[-1.42474819]]]\n",
      "[[-0.54438272]]\n",
      "training for step = 23, loss = 0.24560652673244476\n",
      "24\n",
      "[[[-0.54438272]]]\n",
      "[[0.11092259]]\n",
      "training for step = 24, loss = 0.02263494022190571\n",
      "25\n",
      "[[[0.11092259]]]\n",
      "[[-1.15099358]]\n",
      "training for step = 25, loss = 1.3038818836212158\n",
      "26\n",
      "[[[-1.15099358]]]\n",
      "[[0.37569802]]\n",
      "training for step = 26, loss = 0.17951856553554535\n",
      "27\n",
      "[[[0.37569802]]]\n",
      "[[-0.60063869]]\n",
      "training for step = 27, loss = 0.35629764199256897\n",
      "28\n",
      "[[[-0.60063869]]]\n",
      "[[-0.29169375]]\n",
      "training for step = 28, loss = 0.07510340213775635\n",
      "29\n",
      "[[[-0.29169375]]]\n",
      "[[-0.60170661]]\n",
      "training for step = 29, loss = 0.34809771180152893\n",
      "30\n",
      "[[[-0.60170661]]]\n",
      "[[1.85227818]]\n",
      "training for step = 30, loss = 3.51294207572937\n",
      "31\n",
      "[[[1.85227818]]]\n",
      "[[-0.01349722]]\n",
      "training for step = 31, loss = 0.0017413606401532888\n",
      "32\n",
      "[[[-0.01349722]]]\n",
      "[[-1.05771093]]\n",
      "training for step = 32, loss = 1.166373610496521\n",
      "33\n",
      "[[[-1.05771093]]]\n",
      "[[0.82254491]]\n",
      "training for step = 33, loss = 0.7460330128669739\n",
      "34\n",
      "[[[0.82254491]]]\n",
      "[[-1.22084365]]\n",
      "training for step = 34, loss = 1.482747197151184\n",
      "35\n",
      "[[[-1.22084365]]]\n",
      "[[0.2088636]]\n",
      "training for step = 35, loss = 0.07521940767765045\n",
      "36\n",
      "[[[0.2088636]]]\n",
      "[[-1.95967012]]\n",
      "training for step = 36, loss = 3.7058520317077637\n",
      "37\n",
      "[[[-1.95967012]]]\n",
      "[[-1.32818605]]\n",
      "training for step = 37, loss = 1.4579453468322754\n",
      "38\n",
      "[[[-1.32818605]]]\n",
      "[[0.19686124]]\n",
      "training for step = 38, loss = 0.10186509042978287\n",
      "39\n",
      "[[[0.19686124]]]\n",
      "[[0.73846658]]\n",
      "training for step = 39, loss = 0.643226146697998\n",
      "40\n",
      "[[[0.73846658]]]\n",
      "[[0.17136828]]\n",
      "training for step = 40, loss = 0.035589154809713364\n",
      "41\n",
      "[[[0.17136828]]]\n",
      "[[-0.11564828]]\n",
      "training for step = 41, loss = 0.012869363650679588\n",
      "42\n",
      "[[[-0.11564828]]]\n",
      "[[-0.3011037]]\n",
      "training for step = 42, loss = 0.08709660917520523\n",
      "43\n",
      "[[[-0.3011037]]]\n",
      "[[-1.47852199]]\n",
      "training for step = 43, loss = 2.137214422225952\n",
      "44\n",
      "[[[-1.47852199]]]\n",
      "[[-0.71984421]]\n",
      "training for step = 44, loss = 0.40860846638679504\n",
      "45\n",
      "[[[-0.71984421]]]\n",
      "[[-0.46063877]]\n",
      "training for step = 45, loss = 0.1508500576019287\n",
      "46\n",
      "[[[-0.46063877]]]\n",
      "[[1.05712223]]\n",
      "training for step = 46, loss = 1.2397266626358032\n",
      "47\n",
      "[[[1.05712223]]]\n",
      "[[0.34361829]]\n",
      "training for step = 47, loss = 0.12075438350439072\n",
      "48\n",
      "[[[0.34361829]]]\n",
      "[[-1.76304016]]\n",
      "training for step = 48, loss = 3.146692991256714\n",
      "49\n",
      "[[[-1.76304016]]]\n",
      "[[0.32408397]]\n",
      "training for step = 49, loss = 0.16713637113571167\n",
      "50\n",
      "[[[0.32408397]]]\n",
      "[[-0.38508228]]\n",
      "training for step = 50, loss = 0.11849289387464523\n",
      "51\n",
      "[[[-0.38508228]]]\n",
      "[[-0.676922]]\n",
      "training for step = 51, loss = 0.399694561958313\n",
      "52\n",
      "[[[-0.676922]]]\n",
      "[[0.61167629]]\n",
      "training for step = 52, loss = 0.44800201058387756\n",
      "53\n",
      "[[[0.61167629]]]\n",
      "[[1.03099952]]\n",
      "training for step = 53, loss = 1.099744439125061\n",
      "54\n",
      "[[[1.03099952]]]\n",
      "[[0.93128012]]\n",
      "training for step = 54, loss = 0.8474694490432739\n",
      "55\n",
      "[[[0.93128012]]]\n",
      "[[-0.83921752]]\n",
      "training for step = 55, loss = 0.7433966994285583\n",
      "56\n",
      "[[[-0.83921752]]]\n",
      "[[-0.30921238]]\n",
      "training for step = 56, loss = 0.0743282288312912\n",
      "57\n",
      "[[[-0.30921238]]]\n",
      "[[0.33126343]]\n",
      "training for step = 57, loss = 0.14571216702461243\n",
      "58\n",
      "[[[0.33126343]]]\n",
      "[[0.97554513]]\n",
      "training for step = 58, loss = 1.0171681642532349\n",
      "59\n",
      "[[[0.97554513]]]\n",
      "[[-0.47917424]]\n",
      "training for step = 59, loss = 0.2218528687953949\n",
      "60\n",
      "[[[-0.47917424]]]\n",
      "[[-0.18565898]]\n",
      "training for step = 60, loss = 0.020960889756679535\n",
      "61\n",
      "[[[-0.18565898]]]\n",
      "[[-1.10633497]]\n",
      "training for step = 61, loss = 1.1189830303192139\n",
      "62\n",
      "[[[-1.10633497]]]\n",
      "[[-1.19620662]]\n",
      "training for step = 62, loss = 1.2176440954208374\n",
      "63\n",
      "[[[-1.19620662]]]\n",
      "[[0.81252582]]\n",
      "training for step = 63, loss = 0.8587952256202698\n",
      "64\n",
      "[[[0.81252582]]]\n",
      "[[1.35624003]]\n",
      "training for step = 64, loss = 1.9778422117233276\n",
      "65\n",
      "[[[1.35624003]]]\n",
      "[[-0.07201012]]\n",
      "training for step = 65, loss = 0.00372018339112401\n",
      "66\n",
      "[[[-0.07201012]]]\n",
      "[[1.0035329]]\n",
      "training for step = 66, loss = 1.0491372346878052\n",
      "67\n",
      "[[[1.0035329]]]\n",
      "[[0.36163603]]\n",
      "training for step = 67, loss = 0.13372810184955597\n",
      "68\n",
      "[[[0.36163603]]]\n",
      "[[-0.64511975]]\n",
      "training for step = 68, loss = 0.4042941629886627\n",
      "69\n",
      "[[[-0.64511975]]]\n",
      "[[0.36139561]]\n",
      "training for step = 69, loss = 0.1738840490579605\n",
      "70\n",
      "[[[0.36139561]]]\n",
      "[[1.53803657]]\n",
      "training for step = 70, loss = 2.4931015968322754\n",
      "71\n",
      "[[[1.53803657]]]\n",
      "[[-0.03582604]]\n",
      "training for step = 71, loss = 0.0006391894421540201\n",
      "72\n",
      "[[[-0.03582604]]]\n",
      "[[1.56464366]]\n",
      "training for step = 72, loss = 2.541677713394165\n",
      "73\n",
      "[[[1.56464366]]]\n",
      "[[-2.6197451]]\n",
      "training for step = 73, loss = 6.821579933166504\n",
      "74\n",
      "[[[-2.6197451]]]\n",
      "[[0.8219025]]\n",
      "training for step = 74, loss = 0.9782199859619141\n",
      "75\n",
      "[[[0.8219025]]]\n",
      "[[0.08704707]]\n",
      "training for step = 75, loss = 0.03493615612387657\n",
      "76\n",
      "[[[0.08704707]]]\n",
      "[[-0.29900735]]\n",
      "training for step = 76, loss = 0.0436180979013443\n",
      "77\n",
      "[[[-0.29900735]]]\n",
      "[[0.09176078]]\n",
      "training for step = 77, loss = 0.03380531072616577\n",
      "78\n",
      "[[[0.09176078]]]\n",
      "[[-1.98756891]]\n",
      "training for step = 78, loss = 3.664914846420288\n",
      "79\n",
      "[[[-1.98756891]]]\n",
      "[[-0.21967189]]\n",
      "training for step = 79, loss = 0.0046908860094845295\n",
      "80\n",
      "[[[-0.21967189]]]\n",
      "[[0.35711257]]\n",
      "training for step = 80, loss = 0.2106667160987854\n",
      "81\n",
      "[[[0.35711257]]]\n",
      "[[1.47789404]]\n",
      "training for step = 81, loss = 2.3632688522338867\n",
      "82\n",
      "[[[1.47789404]]]\n",
      "[[-0.51827022]]\n",
      "training for step = 82, loss = 0.24981427192687988\n",
      "83\n",
      "[[[-0.51827022]]]\n",
      "[[-0.8084936]]\n",
      "training for step = 83, loss = 0.5911641120910645\n",
      "84\n",
      "[[[-0.8084936]]]\n",
      "[[-0.50175704]]\n",
      "training for step = 84, loss = 0.18745578825473785\n",
      "85\n",
      "[[[-0.50175704]]]\n",
      "[[0.91540212]]\n",
      "training for step = 85, loss = 0.963200032711029\n",
      "86\n",
      "[[[0.91540212]]]\n",
      "[[0.32875111]]\n",
      "training for step = 86, loss = 0.12410309910774231\n",
      "87\n",
      "[[[0.32875111]]]\n",
      "[[-0.5297602]]\n",
      "training for step = 87, loss = 0.2664754390716553\n",
      "88\n",
      "[[[-0.5297602]]]\n",
      "[[0.51326743]]\n",
      "training for step = 88, loss = 0.3037266135215759\n",
      "89\n",
      "[[[0.51326743]]]\n",
      "[[0.09707755]]\n",
      "training for step = 89, loss = 0.013211105018854141\n",
      "90\n",
      "[[[0.09707755]]]\n",
      "[[0.96864499]]\n",
      "training for step = 90, loss = 0.9741776585578918\n",
      "91\n",
      "[[[0.96864499]]]\n",
      "[[-0.70205309]]\n",
      "training for step = 91, loss = 0.49021637439727783\n",
      "92\n",
      "[[[-0.70205309]]]\n",
      "[[-0.32766215]]\n",
      "training for step = 92, loss = 0.08198392391204834\n",
      "93\n",
      "[[[-0.32766215]]]\n",
      "[[-0.39210815]]\n",
      "training for step = 93, loss = 0.1182255819439888\n",
      "94\n",
      "[[[-0.39210815]]]\n",
      "[[-1.46351495]]\n",
      "training for step = 94, loss = 1.9960849285125732\n",
      "95\n",
      "[[[-1.46351495]]]\n",
      "[[0.29612028]]\n",
      "training for step = 95, loss = 0.1518777310848236\n",
      "96\n",
      "[[[0.29612028]]]\n",
      "[[0.26105527]]\n",
      "training for step = 96, loss = 0.09223785251379013\n",
      "97\n",
      "[[[0.26105527]]]\n",
      "[[0.00511346]]\n",
      "training for step = 97, loss = 0.0006110997055657208\n",
      "98\n",
      "[[[0.00511346]]]\n",
      "[[-0.23458713]]\n",
      "training for step = 98, loss = 0.04908011108636856\n",
      "99\n",
      "[[[-0.23458713]]]\n",
      "[[-1.41537074]]\n",
      "training for step = 99, loss = 1.9554327726364136\n",
      "100\n",
      "[[[-1.41537074]]]\n",
      "[[-0.42064532]]\n",
      "training for step = 100, loss = 0.1244826540350914\n",
      "101\n",
      "[[[-0.42064532]]]\n",
      "[[-0.34271452]]\n",
      "training for step = 101, loss = 0.08823077380657196\n",
      "102\n",
      "[[[-0.34271452]]]\n",
      "[[-0.80227727]]\n",
      "training for step = 102, loss = 0.5946235060691833\n",
      "103\n",
      "[[[-0.80227727]]]\n",
      "[[-0.16128571]]\n",
      "training for step = 103, loss = 0.015088142827153206\n",
      "104\n",
      "[[[-0.16128571]]]\n",
      "[[0.40405086]]\n",
      "training for step = 104, loss = 0.17651133239269257\n",
      "105\n",
      "[[[0.40405086]]]\n",
      "[[1.8861859]]\n",
      "training for step = 105, loss = 3.5210018157958984\n",
      "106\n",
      "[[[1.8861859]]]\n",
      "[[0.17457781]]\n",
      "training for step = 106, loss = 0.021242529153823853\n",
      "107\n",
      "[[[0.17457781]]]\n",
      "[[0.25755039]]\n",
      "training for step = 107, loss = 0.056625477969646454\n",
      "108\n",
      "[[[0.25755039]]]\n",
      "[[-0.07444592]]\n",
      "training for step = 108, loss = 0.005918014328926802\n",
      "109\n",
      "[[[-0.07444592]]]\n",
      "[[-1.91877122]]\n",
      "training for step = 109, loss = 3.6102328300476074\n",
      "110\n",
      "[[[-1.91877122]]]\n",
      "[[-0.02651388]]\n",
      "training for step = 110, loss = 0.007756291888654232\n",
      "111\n",
      "[[[-0.02651388]]]\n",
      "[[0.06023021]]\n",
      "training for step = 111, loss = 0.017665943130850792\n",
      "112\n",
      "[[[0.06023021]]]\n",
      "[[2.46324211]]\n",
      "training for step = 112, loss = 6.320976257324219\n",
      "113\n",
      "[[[2.46324211]]]\n",
      "[[-0.19236096]]\n",
      "training for step = 113, loss = 0.029397740960121155\n",
      "114\n",
      "[[[-0.19236096]]]\n",
      "[[0.30154734]]\n",
      "training for step = 114, loss = 0.11244289577007294\n",
      "115\n",
      "[[[0.30154734]]]\n",
      "[[-0.03471177]]\n",
      "training for step = 115, loss = 1.7453276086598635e-05\n",
      "116\n",
      "[[[-0.03471177]]]\n",
      "[[-1.16867804]]\n",
      "training for step = 116, loss = 1.2519912719726562\n",
      "117\n",
      "[[[-1.16867804]]]\n",
      "[[1.14282281]]\n",
      "training for step = 117, loss = 1.541687250137329\n",
      "118\n",
      "[[[1.14282281]]]\n",
      "[[0.75193303]]\n",
      "training for step = 118, loss = 0.6409511566162109\n",
      "119\n",
      "[[[0.75193303]]]\n",
      "[[0.79103195]]\n",
      "training for step = 119, loss = 0.6784719824790955\n",
      "120\n",
      "[[[0.79103195]]]\n",
      "[[-0.90938745]]\n",
      "training for step = 120, loss = 0.7817936539649963\n",
      "121\n",
      "[[[-0.90938745]]]\n",
      "[[1.40279431]]\n",
      "training for step = 121, loss = 2.1857500076293945\n",
      "122\n",
      "[[[1.40279431]]]\n",
      "[[-1.40185106]]\n",
      "training for step = 122, loss = 1.8504970073699951\n",
      "123\n",
      "[[[-1.40185106]]]\n",
      "[[0.58685709]]\n",
      "training for step = 123, loss = 0.48092561960220337\n",
      "124\n",
      "[[[0.58685709]]]\n",
      "[[2.19045563]]\n",
      "training for step = 124, loss = 5.100930213928223\n",
      "125\n",
      "[[[2.19045563]]]\n",
      "[[-0.99053633]]\n",
      "training for step = 125, loss = 0.8997128009796143\n",
      "126\n",
      "[[[-0.99053633]]]\n",
      "[[-0.56629773]]\n",
      "training for step = 126, loss = 0.22918209433555603\n",
      "127\n",
      "[[[-0.56629773]]]\n",
      "[[0.09965137]]\n",
      "training for step = 127, loss = 0.039361126720905304\n",
      "128\n",
      "[[[0.09965137]]]\n",
      "[[-0.50347565]]\n",
      "training for step = 128, loss = 0.18317733705043793\n",
      "129\n",
      "[[[-0.50347565]]]\n",
      "[[-1.55066343]]\n",
      "training for step = 129, loss = 2.1740596294403076\n",
      "130\n",
      "[[[-1.55066343]]]\n",
      "[[0.06856297]]\n",
      "training for step = 130, loss = 0.03176719322800636\n",
      "131\n",
      "[[[0.06856297]]]\n",
      "[[-1.06230371]]\n",
      "training for step = 131, loss = 1.0098857879638672\n",
      "132\n",
      "[[[-1.06230371]]]\n",
      "[[0.47359243]]\n",
      "training for step = 132, loss = 0.2924729883670807\n",
      "133\n",
      "[[[0.47359243]]]\n",
      "[[-0.91942423]]\n",
      "training for step = 133, loss = 0.8094284534454346\n",
      "134\n",
      "[[[-0.91942423]]]\n",
      "[[1.54993441]]\n",
      "training for step = 134, loss = 2.5163393020629883\n",
      "135\n",
      "[[[1.54993441]]]\n",
      "[[-0.78325329]]\n",
      "training for step = 135, loss = 0.6173145771026611\n",
      "136\n",
      "[[[-0.78325329]]]\n",
      "[[-0.32206152]]\n",
      "training for step = 136, loss = 0.08830771595239639\n",
      "137\n",
      "[[[-0.32206152]]]\n",
      "[[0.81351722]]\n",
      "training for step = 137, loss = 0.7057691216468811\n",
      "138\n",
      "[[[0.81351722]]]\n",
      "[[-1.23086432]]\n",
      "training for step = 138, loss = 1.5047857761383057\n",
      "139\n",
      "[[[-1.23086432]]]\n",
      "[[0.22745993]]\n",
      "training for step = 139, loss = 0.07721907645463943\n",
      "140\n",
      "[[[0.22745993]]]\n",
      "[[1.30714275]]\n",
      "training for step = 140, loss = 1.7717745304107666\n",
      "141\n",
      "[[[1.30714275]]]\n",
      "[[-1.60748323]]\n",
      "training for step = 141, loss = 2.566615581512451\n",
      "142\n",
      "[[[-1.60748323]]]\n",
      "[[0.18463386]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training for step = 142, loss = 0.06494761258363724\n",
      "143\n",
      "[[[0.18463386]]]\n",
      "[[0.25988279]]\n",
      "training for step = 143, loss = 0.09068401157855988\n",
      "144\n",
      "[[[0.25988279]]]\n",
      "[[0.78182287]]\n",
      "training for step = 144, loss = 0.6554084420204163\n",
      "145\n",
      "[[[0.78182287]]]\n",
      "[[-1.23695071]]\n",
      "training for step = 145, loss = 1.4897994995117188\n",
      "146\n",
      "[[[-1.23695071]]]\n",
      "[[-1.32045661]]\n",
      "training for step = 146, loss = 1.5888949632644653\n",
      "147\n",
      "[[[-1.32045661]]]\n",
      "[[0.52194157]]\n",
      "training for step = 147, loss = 0.35729146003723145\n",
      "148\n",
      "[[[0.52194157]]]\n",
      "[[0.29698467]]\n",
      "training for step = 148, loss = 0.10604710876941681\n",
      "149\n",
      "[[[0.29698467]]]\n",
      "[[0.25049285]]\n",
      "training for step = 149, loss = 0.07006518542766571\n",
      "150\n",
      "[[[0.25049285]]]\n",
      "[[0.34644821]]\n",
      "training for step = 150, loss = 0.12647347152233124\n",
      "151\n",
      "[[[0.34644821]]]\n",
      "[[-0.68002472]]\n",
      "training for step = 151, loss = 0.45121780037879944\n",
      "152\n",
      "[[[-0.68002472]]]\n",
      "[[0.2322537]]\n",
      "training for step = 152, loss = 0.06903169304132462\n",
      "153\n",
      "[[[0.2322537]]]\n",
      "[[0.29307247]]\n",
      "training for step = 153, loss = 0.09690244495868683\n",
      "154\n",
      "[[[0.29307247]]]\n",
      "[[-0.71435142]]\n",
      "training for step = 154, loss = 0.4911724328994751\n",
      "155\n",
      "[[[-0.71435142]]]\n",
      "[[1.86577451]]\n",
      "training for step = 155, loss = 3.6029534339904785\n",
      "156\n",
      "[[[1.86577451]]]\n",
      "[[0.47383292]]\n",
      "training for step = 156, loss = 0.2440241277217865\n",
      "157\n",
      "[[[0.47383292]]]\n",
      "[[-1.1913035]]\n",
      "training for step = 157, loss = 1.3576421737670898\n",
      "158\n",
      "[[[-1.1913035]]]\n",
      "[[0.65655361]]\n",
      "training for step = 158, loss = 0.5316563248634338\n",
      "159\n",
      "[[[0.65655361]]]\n",
      "[[-0.97468167]]\n",
      "training for step = 159, loss = 0.8544299006462097\n",
      "160\n",
      "[[[-0.97468167]]]\n",
      "[[0.7870846]]\n",
      "training for step = 160, loss = 0.7350966334342957\n",
      "161\n",
      "[[[0.7870846]]]\n",
      "[[1.15859558]]\n",
      "training for step = 161, loss = 1.4429032802581787\n",
      "162\n",
      "[[[1.15859558]]]\n",
      "[[-0.82068232]]\n",
      "training for step = 162, loss = 0.6131811141967773\n",
      "163\n",
      "[[[-0.82068232]]]\n",
      "[[0.96337613]]\n",
      "training for step = 163, loss = 1.0542843341827393\n",
      "164\n",
      "[[[0.96337613]]]\n",
      "[[0.41278093]]\n",
      "training for step = 164, loss = 0.2144944965839386\n",
      "165\n",
      "[[[0.41278093]]]\n",
      "[[0.82206016]]\n",
      "training for step = 165, loss = 0.7639082074165344\n",
      "166\n",
      "[[[0.82206016]]]\n",
      "[[1.89679298]]\n",
      "training for step = 166, loss = 3.8050692081451416\n",
      "167\n",
      "[[[1.89679298]]]\n",
      "[[-0.24538812]]\n",
      "training for step = 167, loss = 0.03437143936753273\n",
      "168\n",
      "[[[-0.24538812]]]\n",
      "[[-0.75373616]]\n",
      "training for step = 168, loss = 0.4517301917076111\n",
      "169\n",
      "[[[-0.75373616]]]\n",
      "[[-0.88951443]]\n",
      "training for step = 169, loss = 0.6173257231712341\n",
      "170\n",
      "[[[-0.88951443]]]\n",
      "[[-0.81581028]]\n",
      "training for step = 170, loss = 0.5121045112609863\n",
      "171\n",
      "[[[-0.81581028]]]\n",
      "[[-0.07710171]]\n",
      "training for step = 171, loss = 1.0045092722066329e-06\n",
      "172\n",
      "[[[-0.07710171]]]\n",
      "[[0.34115197]]\n",
      "training for step = 172, loss = 0.14592155814170837\n",
      "173\n",
      "[[[0.34115197]]]\n",
      "[[0.2766908]]\n",
      "training for step = 173, loss = 0.08570968359708786\n",
      "174\n",
      "[[[0.2766908]]]\n",
      "[[0.82718325]]\n",
      "training for step = 174, loss = 0.6938788890838623\n",
      "175\n",
      "[[[0.82718325]]]\n",
      "[[0.01300189]]\n",
      "training for step = 175, loss = 0.0002558530541136861\n",
      "176\n",
      "[[[0.01300189]]]\n",
      "[[1.45353408]]\n",
      "training for step = 176, loss = 2.149122714996338\n",
      "177\n",
      "[[[1.45353408]]]\n",
      "[[-0.26465683]]\n",
      "training for step = 177, loss = 0.06077565625309944\n",
      "178\n",
      "[[[-0.26465683]]]\n",
      "[[2.72016917]]\n",
      "training for step = 178, loss = 7.603269577026367\n",
      "179\n",
      "[[[2.72016917]]]\n",
      "[[0.62566735]]\n",
      "training for step = 179, loss = 0.45717498660087585\n",
      "180\n",
      "[[[0.62566735]]]\n",
      "[[-0.85715756]]\n",
      "training for step = 180, loss = 0.6415855288505554\n",
      "181\n",
      "[[[-0.85715756]]]\n",
      "[[-1.0708925]]\n",
      "training for step = 181, loss = 0.9480238556861877\n",
      "182\n",
      "[[[-1.0708925]]]\n",
      "[[0.48247242]]\n",
      "training for step = 182, loss = 0.3517591953277588\n",
      "183\n",
      "[[[0.48247242]]]\n",
      "[[-0.22346279]]\n",
      "training for step = 183, loss = 0.02293744869530201\n",
      "184\n",
      "[[[-0.22346279]]]\n",
      "[[0.71400049]]\n",
      "training for step = 184, loss = 0.5991951823234558\n",
      "185\n",
      "[[[0.71400049]]]\n",
      "[[0.47323762]]\n",
      "training for step = 185, loss = 0.26193001866340637\n",
      "186\n",
      "[[[0.47323762]]]\n",
      "[[-0.07282891]]\n",
      "training for step = 186, loss = 0.001716471160762012\n",
      "187\n",
      "[[[-0.07282891]]]\n",
      "[[-0.84679372]]\n",
      "training for step = 187, loss = 0.6606261134147644\n",
      "188\n",
      "[[[-0.84679372]]]\n",
      "[[-1.51484722]]\n",
      "training for step = 188, loss = 2.158088445663452\n",
      "189\n",
      "[[[-1.51484722]]]\n",
      "[[-0.44651495]]\n",
      "training for step = 189, loss = 0.15104272961616516\n",
      "190\n",
      "[[[-0.44651495]]]\n",
      "[[0.85639879]]\n",
      "training for step = 190, loss = 0.7631202936172485\n",
      "191\n",
      "[[[0.85639879]]]\n",
      "[[0.21409374]]\n",
      "training for step = 191, loss = 0.039681050926446915\n",
      "192\n",
      "[[[0.21409374]]]\n",
      "[[-1.24573878]]\n",
      "training for step = 192, loss = 1.603179931640625\n",
      "193\n",
      "[[[-1.24573878]]]\n",
      "[[0.17318093]]\n",
      "training for step = 193, loss = 0.03385127708315849\n",
      "194\n",
      "[[[0.17318093]]]\n",
      "[[0.38531738]]\n",
      "training for step = 194, loss = 0.1371413618326187\n",
      "195\n",
      "[[[0.38531738]]]\n",
      "[[-0.88385744]]\n",
      "training for step = 195, loss = 0.8251015543937683\n",
      "196\n",
      "[[[-0.88385744]]]\n",
      "[[0.15372511]]\n",
      "training for step = 196, loss = 0.022485118359327316\n",
      "197\n",
      "[[[0.15372511]]]\n",
      "[[0.05820872]]\n",
      "training for step = 197, loss = 0.0014232404064387083\n",
      "198\n",
      "[[[0.05820872]]]\n",
      "[[-1.1429703]]\n",
      "training for step = 198, loss = 1.3621039390563965\n",
      "199\n",
      "[[[-1.1429703]]]\n",
      "[[0.35778736]]\n",
      "training for step = 199, loss = 0.12944333255290985\n",
      "200\n",
      "[[[0.35778736]]]\n",
      "[[0.56078453]]\n",
      "training for step = 200, loss = 0.28756463527679443\n",
      "201\n",
      "[[[0.56078453]]]\n",
      "[[1.08305124]]\n",
      "training for step = 201, loss = 1.1088513135910034\n",
      "202\n",
      "[[[1.08305124]]]\n",
      "[[1.05380205]]\n",
      "training for step = 202, loss = 1.0602176189422607\n",
      "203\n",
      "[[[1.05380205]]]\n",
      "[[-1.37766937]]\n",
      "training for step = 203, loss = 1.9288989305496216\n",
      "204\n",
      "[[[-1.37766937]]]\n",
      "[[-0.93782504]]\n",
      "training for step = 204, loss = 0.7957368493080139\n",
      "205\n",
      "[[[-0.93782504]]]\n",
      "[[0.51503527]]\n",
      "training for step = 205, loss = 0.3202904760837555\n",
      "206\n",
      "[[[0.51503527]]]\n",
      "[[0.51378595]]\n",
      "training for step = 206, loss = 0.282581627368927\n",
      "207\n",
      "[[[0.51378595]]]\n",
      "[[0.51504769]]\n",
      "training for step = 207, loss = 0.27311691641807556\n",
      "208\n",
      "[[[0.51504769]]]\n",
      "[[3.85273149]]\n",
      "training for step = 208, loss = 14.89136028289795\n",
      "209\n",
      "[[[3.85273149]]]\n",
      "[[0.57089051]]\n",
      "training for step = 209, loss = 0.3756280839443207\n",
      "210\n",
      "[[[0.57089051]]]\n",
      "[[1.13556564]]\n",
      "training for step = 210, loss = 1.38043212890625\n",
      "211\n",
      "[[[1.13556564]]]\n",
      "[[0.95400176]]\n",
      "training for step = 211, loss = 1.0167052745819092\n",
      "212\n",
      "[[[0.95400176]]]\n",
      "[[0.65139125]]\n",
      "training for step = 212, loss = 0.510482907295227\n",
      "213\n",
      "[[[0.65139125]]]\n",
      "[[-0.31526924]]\n",
      "training for step = 213, loss = 0.05895324796438217\n",
      "214\n",
      "[[[-0.31526924]]]\n",
      "[[0.75896922]]\n",
      "training for step = 214, loss = 0.7316562533378601\n",
      "215\n",
      "[[[0.75896922]]]\n",
      "[[-0.77282521]]\n",
      "training for step = 215, loss = 0.4807978868484497\n",
      "216\n",
      "[[[-0.77282521]]]\n",
      "[[-0.23681861]]\n",
      "training for step = 216, loss = 0.019029200077056885\n",
      "217\n",
      "[[[-0.23681861]]]\n",
      "[[-0.48536355]]\n",
      "training for step = 217, loss = 0.16491469740867615\n",
      "218\n",
      "[[[-0.48536355]]]\n",
      "[[0.08187414]]\n",
      "training for step = 218, loss = 0.02143229730427265\n",
      "219\n",
      "[[[0.08187414]]]\n",
      "[[2.31465857]]\n",
      "training for step = 219, loss = 5.514331340789795\n",
      "220\n",
      "[[[2.31465857]]]\n",
      "[[-1.86726519]]\n",
      "training for step = 220, loss = 3.4368841648101807\n",
      "221\n",
      "[[[-1.86726519]]]\n",
      "[[0.68626019]]\n",
      "training for step = 221, loss = 0.5807887315750122\n",
      "222\n",
      "[[[0.68626019]]]\n",
      "[[-1.61271587]]\n",
      "training for step = 222, loss = 2.4837729930877686\n",
      "223\n",
      "[[[-1.61271587]]]\n",
      "[[-0.47193187]]\n",
      "training for step = 223, loss = 0.15677087008953094\n",
      "224\n",
      "[[[-0.47193187]]]\n",
      "[[1.0889506]]\n",
      "training for step = 224, loss = 1.2753467559814453\n",
      "225\n",
      "[[[1.0889506]]]\n",
      "[[0.06428002]]\n",
      "training for step = 225, loss = 0.00429352605715394\n",
      "226\n",
      "[[[0.06428002]]]\n",
      "[[-1.07774478]]\n",
      "training for step = 226, loss = 1.1727429628372192\n",
      "227\n",
      "[[[-1.07774478]]]\n",
      "[[-0.71530371]]\n",
      "training for step = 227, loss = 0.4836365282535553\n",
      "228\n",
      "[[[-0.71530371]]]\n",
      "[[0.67959775]]\n",
      "training for step = 228, loss = 0.4745340049266815\n",
      "229\n",
      "[[[0.67959775]]]\n",
      "[[-0.73036663]]\n",
      "training for step = 229, loss = 0.5708382725715637\n",
      "230\n",
      "[[[-0.73036663]]]\n",
      "[[0.21645859]]\n",
      "training for step = 230, loss = 0.041410624980926514\n",
      "231\n",
      "[[[0.21645859]]]\n",
      "[[0.04557184]]\n",
      "training for step = 231, loss = 0.00017770592239685357\n",
      "232\n",
      "[[[0.04557184]]]\n",
      "[[-0.65160035]]\n",
      "training for step = 232, loss = 0.4737626612186432\n",
      "233\n",
      "[[[-0.65160035]]]\n",
      "[[2.14394409]]\n",
      "training for step = 233, loss = 4.495797634124756\n",
      "234\n",
      "[[[2.14394409]]]\n",
      "[[0.63391902]]\n",
      "training for step = 234, loss = 0.36325791478157043\n",
      "235\n",
      "[[[0.63391902]]]\n",
      "[[-2.02514259]]\n",
      "training for step = 235, loss = 4.21254301071167\n",
      "236\n",
      "[[[-2.02514259]]]\n",
      "[[0.18645431]]\n",
      "training for step = 236, loss = 0.05917707830667496\n",
      "237\n",
      "[[[0.18645431]]]\n",
      "[[-0.66178646]]\n",
      "training for step = 237, loss = 0.412607342004776\n",
      "238\n",
      "[[[-0.66178646]]]\n",
      "[[0.85243333]]\n",
      "training for step = 238, loss = 0.7591596841812134\n",
      "239\n",
      "[[[0.85243333]]]\n",
      "[[-0.79252074]]\n",
      "training for step = 239, loss = 0.6421962976455688\n",
      "240\n",
      "[[[-0.79252074]]]\n",
      "[[-0.11473644]]\n",
      "training for step = 240, loss = 0.012027091346681118\n",
      "241\n",
      "[[[-0.11473644]]]\n",
      "[[0.50498728]]\n",
      "training for step = 241, loss = 0.24398896098136902\n",
      "242\n",
      "[[[0.50498728]]]\n",
      "[[0.86575519]]\n",
      "training for step = 242, loss = 0.706299364566803\n",
      "243\n",
      "[[[0.86575519]]]\n",
      "[[-1.20029641]]\n",
      "training for step = 243, loss = 1.5060549974441528\n",
      "244\n",
      "[[[-1.20029641]]]\n",
      "[[-0.33450124]]\n",
      "training for step = 244, loss = 0.1055694967508316\n",
      "245\n",
      "[[[-0.33450124]]]\n",
      "[[-0.47494531]]\n",
      "training for step = 245, loss = 0.23028971254825592\n",
      "246\n",
      "[[[-0.47494531]]]\n",
      "[[-0.65332923]]\n",
      "training for step = 246, loss = 0.4458651542663574\n",
      "247\n",
      "[[[-0.65332923]]]\n",
      "[[1.76545424]]\n",
      "training for step = 247, loss = 3.0370571613311768\n",
      "248\n",
      "[[[1.76545424]]]\n",
      "[[0.40498171]]\n",
      "training for step = 248, loss = 0.13734057545661926\n",
      "249\n",
      "[[[0.40498171]]]\n",
      "[[-1.26088395]]\n",
      "training for step = 249, loss = 1.661678433418274\n",
      "250\n",
      "[[[-1.26088395]]]\n",
      "[[0.91786195]]\n",
      "training for step = 250, loss = 0.8637469410896301\n",
      "251\n",
      "[[[0.91786195]]]\n",
      "[[2.1221562]]\n",
      "training for step = 251, loss = 4.468893527984619\n",
      "252\n",
      "[[[2.1221562]]]\n",
      "[[1.03246526]]\n",
      "training for step = 252, loss = 1.0752862691879272\n",
      "253\n",
      "[[[1.03246526]]]\n",
      "[[-1.51936997]]\n",
      "training for step = 253, loss = 2.2682461738586426\n",
      "254\n",
      "[[[-1.51936997]]]\n",
      "[[-0.48423407]]\n",
      "training for step = 254, loss = 0.1707334667444229\n",
      "255\n",
      "[[[-0.48423407]]]\n",
      "[[1.26691115]]\n",
      "training for step = 255, loss = 1.7534453868865967\n",
      "256\n",
      "[[[1.26691115]]]\n",
      "[[-0.70766947]]\n",
      "training for step = 256, loss = 0.4529840052127838\n",
      "257\n",
      "[[[-0.70766947]]]\n",
      "[[0.44381943]]\n",
      "training for step = 257, loss = 0.23699308931827545\n",
      "258\n",
      "[[[0.44381943]]]\n",
      "[[0.77463405]]\n",
      "training for step = 258, loss = 0.6373009085655212\n",
      "259\n",
      "[[[0.77463405]]]\n",
      "[[-0.92693047]]\n",
      "training for step = 259, loss = 0.8286104202270508\n",
      "260\n",
      "[[[-0.92693047]]]\n",
      "[[-0.05952536]]\n",
      "training for step = 260, loss = 0.0007500188075937331\n",
      "261\n",
      "[[[-0.05952536]]]\n",
      "[[-3.24126734]]\n",
      "training for step = 261, loss = 10.43150806427002\n",
      "262\n",
      "[[[-3.24126734]]]\n",
      "[[-1.02438764]]\n",
      "training for step = 262, loss = 0.8922839760780334\n",
      "263\n",
      "[[[-1.02438764]]]\n",
      "[[-0.25256815]]\n",
      "training for step = 263, loss = 0.061077289283275604\n",
      "264\n",
      "[[[-0.25256815]]]\n",
      "[[-1.24778318]]\n",
      "training for step = 264, loss = 1.6673702001571655\n",
      "265\n",
      "[[[-1.24778318]]]\n",
      "[[1.6324113]]\n",
      "training for step = 265, loss = 2.508476972579956\n",
      "266\n",
      "[[[1.6324113]]]\n",
      "[[-1.43014138]]\n",
      "training for step = 266, loss = 2.2533340454101562\n",
      "267\n",
      "[[[-1.43014138]]]\n",
      "[[-0.44004449]]\n",
      "training for step = 267, loss = 0.22885876893997192\n",
      "268\n",
      "[[[-0.44004449]]]\n",
      "[[0.13074058]]\n",
      "training for step = 268, loss = 0.005903209559619427\n",
      "269\n",
      "[[[0.13074058]]]\n",
      "[[1.44127329]]\n",
      "training for step = 269, loss = 1.8877779245376587\n",
      "270\n",
      "[[[1.44127329]]]\n",
      "[[-1.43586215]]\n",
      "training for step = 270, loss = 2.225497007369995\n",
      "271\n",
      "[[[-1.43586215]]]\n",
      "[[1.16316375]]\n",
      "training for step = 271, loss = 1.3264923095703125\n",
      "272\n",
      "[[[1.16316375]]]\n",
      "[[0.01023306]]\n",
      "training for step = 272, loss = 0.00011851814633700997\n",
      "273\n",
      "[[[0.01023306]]]\n",
      "[[-0.98150865]]\n",
      "training for step = 273, loss = 0.9835220575332642\n",
      "274\n",
      "[[[-0.98150865]]]\n",
      "[[0.46210347]]\n",
      "training for step = 274, loss = 0.22206774353981018\n",
      "275\n",
      "[[[0.46210347]]]\n",
      "[[0.1990597]]\n",
      "training for step = 275, loss = 0.03578602150082588\n",
      "276\n",
      "[[[0.1990597]]]\n",
      "[[-0.60021688]]\n",
      "training for step = 276, loss = 0.37372440099716187\n",
      "277\n",
      "[[[-0.60021688]]]\n",
      "[[0.06980208]]\n",
      "training for step = 277, loss = 0.004219286143779755\n",
      "278\n",
      "[[[0.06980208]]]\n",
      "[[-0.3853136]]\n",
      "training for step = 278, loss = 0.16199296712875366\n",
      "279\n",
      "[[[-0.3853136]]]\n",
      "[[0.11351735]]\n",
      "training for step = 279, loss = 0.008748486638069153\n",
      "280\n",
      "[[[0.11351735]]]\n",
      "[[0.66213067]]\n",
      "training for step = 280, loss = 0.3997834026813507\n",
      "281\n",
      "[[[0.66213067]]]\n",
      "[[1.58601682]]\n",
      "training for step = 281, loss = 2.425764322280884\n",
      "282\n",
      "[[[1.58601682]]]\n",
      "[[-1.2378155]]\n",
      "training for step = 282, loss = 1.5495408773422241\n",
      "283\n",
      "[[[-1.2378155]]]\n",
      "[[2.13303337]]\n",
      "training for step = 283, loss = 4.668233394622803\n",
      "284\n",
      "[[[2.13303337]]]\n",
      "[[-1.9520878]]\n",
      "training for step = 284, loss = 3.6702635288238525\n",
      "285\n",
      "[[[-1.9520878]]]\n",
      "[[-0.1517851]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training for step = 285, loss = 0.005202234257012606\n",
      "286\n",
      "[[[-0.1517851]]]\n",
      "[[0.58831721]]\n",
      "training for step = 286, loss = 0.4015943706035614\n",
      "287\n",
      "[[[0.58831721]]]\n",
      "[[0.28099187]]\n",
      "training for step = 287, loss = 0.09573765099048615\n",
      "288\n",
      "[[[0.28099187]]]\n",
      "[[-0.62269952]]\n",
      "training for step = 288, loss = 0.35863232612609863\n",
      "289\n",
      "[[[-0.62269952]]]\n",
      "[[-0.20812225]]\n",
      "training for step = 289, loss = 0.0345798060297966\n",
      "290\n",
      "[[[-0.20812225]]]\n",
      "[[-0.49300093]]\n",
      "training for step = 290, loss = 0.2387131154537201\n",
      "291\n",
      "[[[-0.49300093]]]\n",
      "[[-0.58936476]]\n",
      "training for step = 291, loss = 0.35958030819892883\n",
      "292\n",
      "[[[-0.58936476]]]\n",
      "[[0.8496021]]\n",
      "training for step = 292, loss = 0.6751369833946228\n",
      "293\n",
      "[[[0.8496021]]]\n",
      "[[0.35701549]]\n",
      "training for step = 293, loss = 0.10272224992513657\n",
      "294\n",
      "[[[0.35701549]]]\n",
      "[[-0.6929096]]\n",
      "training for step = 294, loss = 0.5205464959144592\n",
      "295\n",
      "[[[-0.6929096]]]\n",
      "[[0.89959988]]\n",
      "training for step = 295, loss = 0.7740866541862488\n",
      "296\n",
      "[[[0.89959988]]]\n",
      "[[0.30729952]]\n",
      "training for step = 296, loss = 0.08476608246564865\n",
      "297\n",
      "[[[0.30729952]]]\n",
      "[[0.81286212]]\n",
      "training for step = 297, loss = 0.6519947648048401\n",
      "298\n",
      "[[[0.81286212]]]\n",
      "[[0.62962884]]\n",
      "training for step = 298, loss = 0.41135844588279724\n",
      "299\n",
      "[[[0.62962884]]]\n",
      "[[-0.82899501]]\n",
      "training for step = 299, loss = 0.6412721872329712\n",
      "300\n",
      "[[[-0.82899501]]]\n",
      "[[-0.56018104]]\n",
      "training for step = 300, loss = 0.2703129053115845\n",
      "301\n",
      "[[[-0.56018104]]]\n",
      "[[0.74729361]]\n",
      "training for step = 301, loss = 0.5958595871925354\n",
      "302\n",
      "[[[0.74729361]]]\n",
      "[[0.61037027]]\n",
      "training for step = 302, loss = 0.38754239678382874\n",
      "303\n",
      "[[[0.61037027]]]\n",
      "[[-0.02090159]]\n",
      "training for step = 303, loss = 2.3686568965786137e-05\n",
      "304\n",
      "[[[-0.02090159]]]\n",
      "[[0.11732738]]\n",
      "training for step = 304, loss = 0.018608102574944496\n",
      "305\n",
      "[[[0.11732738]]]\n",
      "[[1.2776649]]\n",
      "training for step = 305, loss = 1.678670048713684\n",
      "306\n",
      "[[[1.2776649]]]\n",
      "[[-0.59157139]]\n",
      "training for step = 306, loss = 0.31328025460243225\n",
      "307\n",
      "[[[-0.59157139]]]\n",
      "[[0.54709738]]\n",
      "training for step = 307, loss = 0.34179672598838806\n",
      "308\n",
      "[[[0.54709738]]]\n",
      "[[-0.20219265]]\n",
      "training for step = 308, loss = 0.028061972931027412\n",
      "309\n",
      "[[[-0.20219265]]]\n",
      "[[-0.2176812]]\n",
      "training for step = 309, loss = 0.035020727664232254\n",
      "310\n",
      "[[[-0.2176812]]]\n",
      "[[1.09877685]]\n",
      "training for step = 310, loss = 1.248803734779358\n",
      "311\n",
      "[[[1.09877685]]]\n",
      "[[0.82541635]]\n",
      "training for step = 311, loss = 0.7176070213317871\n",
      "312\n",
      "[[[0.82541635]]]\n",
      "[[0.81350964]]\n",
      "training for step = 312, loss = 0.716331422328949\n",
      "313\n",
      "[[[0.81350964]]]\n",
      "[[1.30547881]]\n",
      "training for step = 313, loss = 1.8301085233688354\n",
      "314\n",
      "[[[1.30547881]]]\n",
      "[[0.02100384]]\n",
      "training for step = 314, loss = 0.007473262958228588\n",
      "315\n",
      "[[[0.02100384]]]\n",
      "[[0.68195297]]\n",
      "training for step = 315, loss = 0.5743658542633057\n",
      "316\n",
      "[[[0.68195297]]]\n",
      "[[-0.31026676]]\n",
      "training for step = 316, loss = 0.0528402253985405\n",
      "317\n",
      "[[[-0.31026676]]]\n",
      "[[0.32416635]]\n",
      "training for step = 317, loss = 0.16198337078094482\n",
      "318\n",
      "[[[0.32416635]]]\n",
      "[[-0.13014305]]\n",
      "training for step = 318, loss = 0.0042944252490997314\n",
      "319\n",
      "[[[-0.13014305]]]\n",
      "[[0.09699596]]\n",
      "training for step = 319, loss = 0.021626930683851242\n",
      "320\n",
      "[[[0.09699596]]]\n",
      "[[0.59515703]]\n",
      "training for step = 320, loss = 0.39395779371261597\n",
      "321\n",
      "[[[0.59515703]]]\n",
      "[[-0.81822068]]\n",
      "training for step = 321, loss = 0.6319607496261597\n",
      "322\n",
      "[[[-0.81822068]]]\n",
      "[[2.09238728]]\n",
      "training for step = 322, loss = 4.448299407958984\n",
      "323\n",
      "[[[2.09238728]]]\n",
      "[[-1.00601738]]\n",
      "training for step = 323, loss = 0.9542127251625061\n",
      "324\n",
      "[[[-1.00601738]]]\n",
      "[[-1.21418861]]\n",
      "training for step = 324, loss = 1.4007593393325806\n",
      "325\n",
      "[[[-1.21418861]]]\n",
      "[[1.15811087]]\n",
      "training for step = 325, loss = 1.3831318616867065\n",
      "326\n",
      "[[[1.15811087]]]\n",
      "[[0.79166269]]\n",
      "training for step = 326, loss = 0.6245719194412231\n",
      "327\n",
      "[[[0.79166269]]]\n",
      "[[0.62411982]]\n",
      "training for step = 327, loss = 0.3954535722732544\n",
      "328\n",
      "[[[0.62411982]]]\n",
      "[[0.62834551]]\n",
      "training for step = 328, loss = 0.4133046865463257\n",
      "329\n",
      "[[[0.62834551]]]\n",
      "[[-0.01224677]]\n",
      "training for step = 329, loss = 0.00016888418758753687\n",
      "330\n",
      "[[[-0.01224677]]]\n",
      "[[-0.89725437]]\n",
      "training for step = 330, loss = 0.7537639737129211\n",
      "331\n",
      "[[[-0.89725437]]]\n",
      "[[0.07580456]]\n",
      "training for step = 331, loss = 0.010005684569478035\n",
      "332\n",
      "[[[0.07580456]]]\n",
      "[[-0.67716171]]\n",
      "training for step = 332, loss = 0.4610971212387085\n",
      "333\n",
      "[[[-0.67716171]]]\n",
      "[[0.97511973]]\n",
      "training for step = 333, loss = 0.9121570587158203\n",
      "334\n",
      "[[[0.97511973]]]\n",
      "[[-0.14705738]]\n",
      "training for step = 334, loss = 0.030596759170293808\n",
      "335\n",
      "[[[-0.14705738]]]\n",
      "[[-0.8254972]]\n",
      "training for step = 335, loss = 0.7327226400375366\n",
      "336\n",
      "[[[-0.8254972]]]\n",
      "[[-0.32138584]]\n",
      "training for step = 336, loss = 0.12798486649990082\n",
      "337\n",
      "[[[-0.32138584]]]\n",
      "[[0.41293145]]\n",
      "training for step = 337, loss = 0.12564434111118317\n",
      "338\n",
      "[[[0.41293145]]]\n",
      "[[-0.56372455]]\n",
      "training for step = 338, loss = 0.3975854516029358\n",
      "339\n",
      "[[[-0.56372455]]]\n",
      "[[-0.8222204]]\n",
      "training for step = 339, loss = 0.7936673760414124\n",
      "340\n",
      "[[[-0.8222204]]]\n",
      "[[0.24368721]]\n",
      "training for step = 340, loss = 0.027439234778285027\n",
      "341\n",
      "[[[0.24368721]]]\n",
      "[[0.24496657]]\n",
      "training for step = 341, loss = 0.023025430738925934\n",
      "342\n",
      "[[[0.24496657]]]\n",
      "[[-0.50694318]]\n",
      "training for step = 342, loss = 0.35497719049453735\n",
      "343\n",
      "[[[-0.50694318]]]\n",
      "[[-0.47103831]]\n",
      "training for step = 343, loss = 0.307979553937912\n",
      "344\n",
      "[[[-0.47103831]]]\n",
      "[[0.23204994]]\n",
      "training for step = 344, loss = 0.02054334618151188\n",
      "345\n",
      "[[[0.23204994]]]\n",
      "[[-1.44808434]]\n",
      "training for step = 345, loss = 2.3720009326934814\n",
      "346\n",
      "[[[-1.44808434]]]\n",
      "[[-1.40746377]]\n",
      "training for step = 346, loss = 2.2029294967651367\n",
      "347\n",
      "[[[-1.40746377]]]\n",
      "[[-0.71844422]]\n",
      "training for step = 347, loss = 0.6546257138252258\n",
      "348\n",
      "[[[-0.71844422]]]\n",
      "[[-0.21344715]]\n",
      "training for step = 348, loss = 0.11383481323719025\n",
      "349\n",
      "[[[-0.21344715]]]\n",
      "[[0.31090757]]\n",
      "training for step = 349, loss = 0.028089411556720734\n",
      "350\n",
      "[[[0.31090757]]]\n",
      "[[1.47535622]]\n",
      "training for step = 350, loss = 1.7801231145858765\n",
      "351\n",
      "[[[1.47535622]]]\n",
      "[[0.85765962]]\n",
      "training for step = 351, loss = 0.5773853659629822\n",
      "352\n",
      "[[[0.85765962]]]\n",
      "[[-0.15993853]]\n",
      "training for step = 352, loss = 0.04915768653154373\n",
      "353\n",
      "[[[-0.15993853]]]\n",
      "[[-0.01901621]]\n",
      "training for step = 353, loss = 0.0030522863380610943\n",
      "354\n",
      "[[[-0.01901621]]]\n",
      "[[-1.00252936]]\n",
      "training for step = 354, loss = 1.0501091480255127\n",
      "355\n",
      "[[[-1.00252936]]]\n",
      "[[-0.01851314]]\n",
      "training for step = 355, loss = 0.001046523917466402\n",
      "356\n",
      "[[[-0.01851314]]]\n",
      "[[-0.28865864]]\n",
      "training for step = 356, loss = 0.10419982671737671\n",
      "357\n",
      "[[[-0.28865864]]]\n",
      "[[0.32271856]]\n",
      "training for step = 357, loss = 0.07795695960521698\n",
      "358\n",
      "[[[0.32271856]]]\n",
      "[[-0.82723094]]\n",
      "training for step = 358, loss = 0.7697756290435791\n",
      "359\n",
      "[[[-0.82723094]]]\n",
      "[[0.51934651]]\n",
      "training for step = 359, loss = 0.22426822781562805\n",
      "360\n",
      "[[[0.51934651]]]\n",
      "[[1.53273891]]\n",
      "training for step = 360, loss = 2.18281626701355\n",
      "361\n",
      "[[[1.53273891]]]\n",
      "[[-0.10876015]]\n",
      "training for step = 361, loss = 0.018818167969584465\n",
      "362\n",
      "[[[-0.10876015]]]\n",
      "[[0.40171172]]\n",
      "training for step = 362, loss = 0.14930163323879242\n",
      "363\n",
      "[[[0.40171172]]]\n",
      "[[0.69014399]]\n",
      "training for step = 363, loss = 0.47105175256729126\n",
      "364\n",
      "[[[0.69014399]]]\n",
      "[[-0.40122047]]\n",
      "training for step = 364, loss = 0.15506041049957275\n",
      "365\n",
      "[[[-0.40122047]]]\n",
      "[[0.22409248]]\n",
      "training for step = 365, loss = 0.05689980834722519\n",
      "366\n",
      "[[[0.22409248]]]\n",
      "[[0.0125924]]\n",
      "training for step = 366, loss = 0.0004593416815623641\n",
      "367\n",
      "[[[0.0125924]]]\n",
      "[[0.0976761]]\n",
      "training for step = 367, loss = 0.01026705838739872\n",
      "368\n",
      "[[[0.0976761]]]\n",
      "[[-0.77300978]]\n",
      "training for step = 368, loss = 0.6020527482032776\n",
      "369\n",
      "[[[-0.77300978]]]\n",
      "[[0.02451017]]\n",
      "training for step = 369, loss = 0.0003159226616844535\n",
      "370\n",
      "[[[0.02451017]]]\n",
      "[[0.49799829]]\n",
      "training for step = 370, loss = 0.22140832245349884\n",
      "371\n",
      "[[[0.49799829]]]\n",
      "[[1.45114361]]\n",
      "training for step = 371, loss = 2.010518789291382\n",
      "372\n",
      "[[[1.45114361]]]\n",
      "[[0.95927083]]\n",
      "training for step = 372, loss = 0.8955379128456116\n",
      "373\n",
      "[[[0.95927083]]]\n",
      "[[2.15318246]]\n",
      "training for step = 373, loss = 4.655244827270508\n",
      "374\n",
      "[[[2.15318246]]]\n",
      "[[-0.76734756]]\n",
      "training for step = 374, loss = 0.5378985404968262\n",
      "375\n",
      "[[[-0.76734756]]]\n",
      "[[0.87232064]]\n",
      "training for step = 375, loss = 0.8567140698432922\n",
      "376\n",
      "[[[0.87232064]]]\n",
      "[[0.18334201]]\n",
      "training for step = 376, loss = 0.05783018842339516\n",
      "377\n",
      "[[[0.18334201]]]\n",
      "[[2.18980293]]\n",
      "training for step = 377, loss = 5.048176288604736\n",
      "378\n",
      "[[[2.18980293]]]\n",
      "[[-0.80829829]]\n",
      "training for step = 378, loss = 0.5526915788650513\n",
      "379\n",
      "[[[-0.80829829]]]\n",
      "[[-0.83972184]]\n",
      "training for step = 379, loss = 0.5869787931442261\n",
      "380\n",
      "[[[-0.83972184]]]\n",
      "[[-0.59939265]]\n",
      "training for step = 380, loss = 0.28439417481422424\n",
      "381\n",
      "[[[-0.59939265]]]\n",
      "[[-2.12389572]]\n",
      "training for step = 381, loss = 4.360925197601318\n",
      "382\n",
      "[[[-2.12389572]]]\n",
      "[[-0.52575502]]\n",
      "training for step = 382, loss = 0.23468661308288574\n",
      "383\n",
      "[[[-0.52575502]]]\n",
      "[[-0.75913266]]\n",
      "training for step = 383, loss = 0.6125644445419312\n",
      "384\n",
      "[[[-0.75913266]]]\n",
      "[[0.15039379]]\n",
      "training for step = 384, loss = 0.009762023575603962\n",
      "385\n",
      "[[[0.15039379]]]\n",
      "[[0.34175598]]\n",
      "training for step = 385, loss = 0.06676795333623886\n",
      "386\n",
      "[[[0.34175598]]]\n",
      "[[1.87617084]]\n",
      "training for step = 386, loss = 3.186422348022461\n",
      "387\n",
      "[[[1.87617084]]]\n",
      "[[0.95042384]]\n",
      "training for step = 387, loss = 0.7886248826980591\n",
      "388\n",
      "[[[0.95042384]]]\n",
      "[[-0.57690366]]\n",
      "training for step = 388, loss = 0.38775941729545593\n",
      "389\n",
      "[[[-0.57690366]]]\n",
      "[[-0.89841467]]\n",
      "training for step = 389, loss = 0.8453468680381775\n",
      "390\n",
      "[[[-0.89841467]]]\n",
      "[[0.49191917]]\n",
      "training for step = 390, loss = 0.23733891546726227\n",
      "391\n",
      "[[[0.49191917]]]\n",
      "[[-1.32023321]]\n",
      "training for step = 391, loss = 1.8067256212234497\n",
      "392\n",
      "[[[-1.32023321]]]\n",
      "[[1.83145877]]\n",
      "training for step = 392, loss = 3.3415446281433105\n",
      "393\n",
      "[[[1.83145877]]]\n",
      "[[1.17944012]]\n",
      "training for step = 393, loss = 1.3454309701919556\n",
      "394\n",
      "[[[1.17944012]]]\n",
      "[[-0.46917565]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training for step = 394, loss = 0.2314346581697464\n",
      "395\n",
      "[[[-0.46917565]]]\n",
      "[[-1.71313453]]\n",
      "training for step = 395, loss = 2.9262173175811768\n",
      "396\n",
      "[[[-1.71313453]]]\n",
      "[[1.35387237]]\n",
      "training for step = 396, loss = 1.932242751121521\n",
      "397\n",
      "[[[1.35387237]]]\n",
      "[[-0.11453985]]\n",
      "training for step = 397, loss = 0.013020753860473633\n",
      "398\n",
      "[[[-0.11453985]]]\n",
      "[[1.23781631]]\n",
      "training for step = 398, loss = 1.5242670774459839\n",
      "399\n",
      "[[[1.23781631]]]\n",
      "[[-1.59442766]]\n",
      "training for step = 399, loss = 2.5509870052337646\n",
      "400\n",
      "[[[-1.59442766]]]\n",
      "[[-0.59937502]]\n",
      "training for step = 400, loss = 0.3270171880722046\n",
      "401\n",
      "[[[-0.59937502]]]\n",
      "[[0.0052437]]\n",
      "training for step = 401, loss = 3.523156192386523e-05\n",
      "402\n",
      "[[[0.0052437]]]\n",
      "[[0.04698059]]\n",
      "training for step = 402, loss = 0.000362686172593385\n",
      "403\n",
      "[[[0.04698059]]]\n",
      "[[-0.45006547]]\n",
      "training for step = 403, loss = 0.24342568218708038\n",
      "404\n",
      "[[[-0.45006547]]]\n",
      "[[0.62284993]]\n",
      "training for step = 404, loss = 0.3296046555042267\n",
      "405\n",
      "[[[0.62284993]]]\n",
      "[[-1.06762043]]\n",
      "training for step = 405, loss = 1.268471121788025\n",
      "406\n",
      "[[[-1.06762043]]]\n",
      "[[-0.14237949]]\n",
      "training for step = 406, loss = 0.03429697826504707\n",
      "407\n",
      "[[[-0.14237949]]]\n",
      "[[0.12029563]]\n",
      "training for step = 407, loss = 0.003389940829947591\n",
      "408\n",
      "[[[0.12029563]]]\n",
      "[[0.51443883]]\n",
      "training for step = 408, loss = 0.19666080176830292\n",
      "409\n",
      "[[[0.51443883]]]\n",
      "[[0.71161488]]\n",
      "training for step = 409, loss = 0.41273507475852966\n",
      "410\n",
      "[[[0.71161488]]]\n",
      "[[-1.12464209]]\n",
      "training for step = 410, loss = 1.3949840068817139\n",
      "411\n",
      "[[[-1.12464209]]]\n",
      "[[-1.53411417]]\n",
      "training for step = 411, loss = 2.4518001079559326\n",
      "412\n",
      "[[[-1.53411417]]]\n",
      "[[1.27767682]]\n",
      "training for step = 412, loss = 1.5784010887145996\n",
      "413\n",
      "[[[1.27767682]]]\n",
      "[[0.33231401]]\n",
      "training for step = 413, loss = 0.07903378456830978\n",
      "414\n",
      "[[[0.33231401]]]\n",
      "[[-0.74848654]]\n",
      "training for step = 414, loss = 0.6329190135002136\n",
      "415\n",
      "[[[-0.74848654]]]\n",
      "[[1.55115198]]\n",
      "training for step = 415, loss = 2.295182943344116\n",
      "416\n",
      "[[[1.55115198]]]\n",
      "[[0.11567463]]\n",
      "training for step = 416, loss = 0.0076610916294157505\n",
      "417\n",
      "[[[0.11567463]]]\n",
      "[[1.17929718]]\n",
      "training for step = 417, loss = 1.346487045288086\n",
      "418\n",
      "[[[1.17929718]]]\n",
      "[[0.06751848]]\n",
      "training for step = 418, loss = 0.004415714181959629\n",
      "419\n",
      "[[[0.06751848]]]\n",
      "[[2.06074792]]\n",
      "training for step = 419, loss = 4.286653995513916\n",
      "420\n",
      "[[[2.06074792]]]\n",
      "[[1.75534084]]\n",
      "training for step = 420, loss = 3.1981637477874756\n",
      "421\n",
      "[[[1.75534084]]]\n",
      "[[-0.24896415]]\n",
      "training for step = 421, loss = 0.041707348078489304\n",
      "422\n",
      "[[[-0.24896415]]]\n",
      "[[0.97157095]]\n",
      "training for step = 422, loss = 1.0685536861419678\n",
      "423\n",
      "[[[0.97157095]]]\n",
      "[[0.64537595]]\n",
      "training for step = 423, loss = 0.5071911215782166\n",
      "424\n",
      "[[[0.64537595]]]\n",
      "[[1.36863156]]\n",
      "training for step = 424, loss = 2.0601425170898438\n",
      "425\n",
      "[[[1.36863156]]]\n",
      "[[-0.96492346]]\n",
      "training for step = 425, loss = 0.8097328543663025\n",
      "426\n",
      "[[[-0.96492346]]]\n",
      "[[0.68605146]]\n",
      "training for step = 426, loss = 0.5838964581489563\n",
      "427\n",
      "[[[0.68605146]]]\n",
      "[[1.05842449]]\n",
      "training for step = 427, loss = 1.2439870834350586\n",
      "428\n",
      "[[[1.05842449]]]\n",
      "[[-1.75873949]]\n",
      "training for step = 428, loss = 2.9329681396484375\n",
      "429\n",
      "[[[-1.75873949]]]\n",
      "[[-1.18325851]]\n",
      "training for step = 429, loss = 1.2478854656219482\n",
      "430\n",
      "[[[-1.18325851]]]\n",
      "[[-2.03923218]]\n",
      "training for step = 430, loss = 4.02263879776001\n",
      "431\n",
      "[[[-2.03923218]]]\n",
      "[[-0.26940683]]\n",
      "training for step = 431, loss = 0.06138576939702034\n",
      "432\n",
      "[[[-0.26940683]]]\n",
      "[[0.71754226]]\n",
      "training for step = 432, loss = 0.4489266872406006\n",
      "433\n",
      "[[[0.71754226]]]\n",
      "[[1.50235705]]\n",
      "training for step = 433, loss = 2.0322189331054688\n",
      "434\n",
      "[[[1.50235705]]]\n",
      "[[0.07409478]]\n",
      "training for step = 434, loss = 6.71439483994618e-05\n",
      "435\n",
      "[[[0.07409478]]]\n",
      "[[1.62861555]]\n",
      "training for step = 435, loss = 2.464026689529419\n",
      "436\n",
      "[[[1.62861555]]]\n",
      "[[-1.38010146]]\n",
      "training for step = 436, loss = 2.0058465003967285\n",
      "437\n",
      "[[[-1.38010146]]]\n",
      "[[-1.70338244]]\n",
      "training for step = 437, loss = 2.910999298095703\n",
      "438\n",
      "[[[-1.70338244]]]\n",
      "[[-0.0555477]]\n",
      "training for step = 438, loss = 0.001462144311517477\n",
      "439\n",
      "[[[-0.0555477]]]\n",
      "[[0.38406545]]\n",
      "training for step = 439, loss = 0.12294761836528778\n",
      "440\n",
      "[[[0.38406545]]]\n",
      "[[-0.03269475]]\n",
      "training for step = 440, loss = 0.007850532419979572\n",
      "441\n",
      "[[[-0.03269475]]]\n",
      "[[-2.0674421]]\n",
      "training for step = 441, loss = 4.534818649291992\n",
      "442\n",
      "[[[-2.0674421]]]\n",
      "[[-0.08912004]]\n",
      "training for step = 442, loss = 0.010117038153111935\n",
      "443\n",
      "[[[-0.08912004]]]\n",
      "[[-1.3044695]]\n",
      "training for step = 443, loss = 1.8755617141723633\n",
      "444\n",
      "[[[-1.3044695]]]\n",
      "[[0.66967255]]\n",
      "training for step = 444, loss = 0.3772903382778168\n",
      "445\n",
      "[[[0.66967255]]]\n",
      "[[0.36659825]]\n",
      "training for step = 445, loss = 0.0733242928981781\n",
      "446\n",
      "[[[0.36659825]]]\n",
      "[[-0.93987979]]\n",
      "training for step = 446, loss = 1.0750385522842407\n",
      "447\n",
      "[[[-0.93987979]]]\n",
      "[[-0.51386692]]\n",
      "training for step = 447, loss = 0.34481802582740784\n",
      "448\n",
      "[[[-0.51386692]]]\n",
      "[[-1.05921352]]\n",
      "training for step = 448, loss = 1.2965693473815918\n",
      "449\n",
      "[[[-1.05921352]]]\n",
      "[[-0.0626791]]\n",
      "training for step = 449, loss = 0.017655640840530396\n",
      "450\n",
      "[[[-0.0626791]]]\n",
      "[[0.95514232]]\n",
      "training for step = 450, loss = 0.7359366416931152\n",
      "451\n",
      "[[[0.95514232]]]\n",
      "[[-0.98572605]]\n",
      "training for step = 451, loss = 1.1832525730133057\n",
      "452\n",
      "[[[-0.98572605]]]\n",
      "[[0.50404652]]\n",
      "training for step = 452, loss = 0.1870889663696289\n",
      "453\n",
      "[[[0.50404652]]]\n",
      "[[-0.53025762]]\n",
      "training for step = 453, loss = 0.3755562901496887\n",
      "454\n",
      "[[[-0.53025762]]]\n",
      "[[-0.79287283]]\n",
      "training for step = 454, loss = 0.7410904169082642\n",
      "455\n",
      "[[[-0.79287283]]]\n",
      "[[-0.10703036]]\n",
      "training for step = 455, loss = 0.027492394670844078\n",
      "456\n",
      "[[[-0.10703036]]]\n",
      "[[-1.03524232]]\n",
      "training for step = 456, loss = 1.2325021028518677\n",
      "457\n",
      "[[[-1.03524232]]]\n",
      "[[-0.55364931]]\n",
      "training for step = 457, loss = 0.3758012652397156\n",
      "458\n",
      "[[[-0.55364931]]]\n",
      "[[-1.19787789]]\n",
      "training for step = 458, loss = 1.6193567514419556\n",
      "459\n",
      "[[[-1.19787789]]]\n",
      "[[1.96472513]]\n",
      "training for step = 459, loss = 3.617347240447998\n",
      "460\n",
      "[[[1.96472513]]]\n",
      "[[0.03526355]]\n",
      "training for step = 460, loss = 0.0020803920924663544\n",
      "461\n",
      "[[[0.03526355]]]\n",
      "[[-0.69972551]]\n",
      "training for step = 461, loss = 0.5939788222312927\n",
      "462\n",
      "[[[-0.69972551]]]\n",
      "[[0.21397991]]\n",
      "training for step = 462, loss = 0.02783423848450184\n",
      "463\n",
      "[[[0.21397991]]]\n",
      "[[-0.11232805]]\n",
      "training for step = 463, loss = 0.02768036164343357\n",
      "464\n",
      "[[[-0.11232805]]]\n",
      "[[-0.2209696]]\n",
      "training for step = 464, loss = 0.07360541075468063\n",
      "465\n",
      "[[[-0.2209696]]]\n",
      "[[0.6141667]]\n",
      "training for step = 465, loss = 0.32059603929519653\n",
      "466\n",
      "[[[0.6141667]]]\n",
      "[[0.75750771]]\n",
      "training for step = 466, loss = 0.497679203748703\n",
      "467\n",
      "[[[0.75750771]]]\n",
      "[[-0.53050115]]\n",
      "training for step = 467, loss = 0.33076250553131104\n",
      "468\n",
      "[[[-0.53050115]]]\n",
      "[[-0.57581824]]\n",
      "training for step = 468, loss = 0.3615417778491974\n",
      "469\n",
      "[[[-0.57581824]]]\n",
      "[[-0.2750517]]\n",
      "training for step = 469, loss = 0.08684778958559036\n",
      "470\n",
      "[[[-0.2750517]]]\n",
      "[[-2.30192116]]\n",
      "training for step = 470, loss = 5.438882350921631\n",
      "471\n",
      "[[[-2.30192116]]]\n",
      "[[-1.51519106]]\n",
      "training for step = 471, loss = 2.212533473968506\n",
      "472\n",
      "[[[-1.51519106]]]\n",
      "[[1.36687427]]\n",
      "training for step = 472, loss = 1.8694243431091309\n",
      "473\n",
      "[[[1.36687427]]]\n",
      "[[1.64496771]]\n",
      "training for step = 473, loss = 2.5325865745544434\n",
      "474\n",
      "[[[1.64496771]]]\n",
      "[[-0.24903604]]\n",
      "training for step = 474, loss = 0.08545707166194916\n",
      "475\n",
      "[[[-0.24903604]]]\n",
      "[[0.57655696]]\n",
      "training for step = 475, loss = 0.2971130609512329\n",
      "476\n",
      "[[[0.57655696]]]\n",
      "[[0.31125015]]\n",
      "training for step = 476, loss = 0.08285113424062729\n",
      "477\n",
      "[[[0.31125015]]]\n",
      "[[3.07888081]]\n",
      "training for step = 477, loss = 9.3849458694458\n",
      "478\n",
      "[[[3.07888081]]]\n",
      "[[1.11957491]]\n",
      "training for step = 478, loss = 1.2929413318634033\n",
      "479\n",
      "[[[1.11957491]]]\n",
      "[[-0.12791759]]\n",
      "training for step = 479, loss = 0.01337255910038948\n",
      "480\n",
      "[[[-0.12791759]]]\n",
      "[[-0.95554044]]\n",
      "training for step = 480, loss = 0.843515932559967\n",
      "481\n",
      "[[[-0.95554044]]]\n",
      "[[-1.60644632]]\n",
      "training for step = 481, loss = 2.3627371788024902\n",
      "482\n",
      "[[[-1.60644632]]]\n",
      "[[0.20346364]]\n",
      "training for step = 482, loss = 0.08630289137363434\n",
      "483\n",
      "[[[0.20346364]]]\n",
      "[[-0.75635075]]\n",
      "training for step = 483, loss = 0.5242791771888733\n",
      "484\n",
      "[[[-0.75635075]]]\n",
      "[[-1.42225371]]\n",
      "training for step = 484, loss = 1.959221601486206\n",
      "485\n",
      "[[[-1.42225371]]]\n",
      "[[-0.64657288]]\n",
      "training for step = 485, loss = 0.38483700156211853\n",
      "486\n",
      "[[[-0.64657288]]]\n",
      "[[-1.081548]]\n",
      "training for step = 486, loss = 1.1984846591949463\n",
      "487\n",
      "[[[-1.081548]]]\n",
      "[[1.68714164]]\n",
      "training for step = 487, loss = 2.7736167907714844\n",
      "488\n",
      "[[[1.68714164]]]\n",
      "[[0.88163976]]\n",
      "training for step = 488, loss = 0.6761247515678406\n",
      "489\n",
      "[[[0.88163976]]]\n",
      "[[-0.00797264]]\n",
      "training for step = 489, loss = 0.004627998918294907\n",
      "490\n",
      "[[[-0.00797264]]]\n",
      "[[1.47994414]]\n",
      "training for step = 490, loss = 2.0590872764587402\n",
      "491\n",
      "[[[1.47994414]]]\n",
      "[[0.07736831]]\n",
      "training for step = 491, loss = 0.0017752336570993066\n",
      "492\n",
      "[[[0.07736831]]]\n",
      "[[-0.8612842]]\n",
      "training for step = 492, loss = 0.7769460082054138\n",
      "493\n",
      "[[[-0.8612842]]]\n",
      "[[1.52312408]]\n",
      "training for step = 493, loss = 2.368507146835327\n",
      "494\n",
      "[[[1.52312408]]]\n",
      "[[0.53891004]]\n",
      "training for step = 494, loss = 0.28810274600982666\n",
      "495\n",
      "[[[0.53891004]]]\n",
      "[[-1.03724615]]\n",
      "training for step = 495, loss = 1.0782395601272583\n",
      "496\n",
      "[[[-1.03724615]]]\n",
      "[[-0.19033868]]\n",
      "training for step = 496, loss = 0.023564506322145462\n",
      "497\n",
      "[[[-0.19033868]]]\n",
      "[[-0.87561825]]\n",
      "training for step = 497, loss = 0.7299045324325562\n",
      "498\n",
      "[[[-0.87561825]]]\n",
      "[[-1.38279973]]\n",
      "training for step = 498, loss = 1.8422714471817017\n",
      "499\n",
      "[[[-1.38279973]]]\n",
      "[[0.92617755]]\n",
      "training for step = 499, loss = 0.9197098016738892\n",
      "500\n",
      "[[[0.92617755]]]\n",
      "[[1.90941664]]\n",
      "training for step = 500, loss = 3.5508460998535156\n",
      "501\n",
      "[[[1.90941664]]]\n",
      "[[-1.39856757]]\n",
      "training for step = 501, loss = 2.0368711948394775\n",
      "502\n",
      "[[[-1.39856757]]]\n",
      "[[0.56296924]]\n",
      "training for step = 502, loss = 0.3368884325027466\n",
      "503\n",
      "[[[0.56296924]]]\n",
      "[[-0.65064257]]\n",
      "training for step = 503, loss = 0.4304812550544739\n",
      "504\n",
      "[[[-0.65064257]]]\n",
      "[[-0.48712538]]\n",
      "training for step = 504, loss = 0.2303484082221985\n",
      "505\n",
      "[[[-0.48712538]]]\n",
      "[[-0.59239392]]\n",
      "training for step = 505, loss = 0.3508833348751068\n",
      "506\n",
      "[[[-0.59239392]]]\n",
      "[[-0.86399077]]\n",
      "training for step = 506, loss = 0.7610601186752319\n",
      "507\n",
      "[[[-0.86399077]]]\n",
      "[[0.04852163]]\n",
      "training for step = 507, loss = 0.0013000242179259658\n",
      "508\n",
      "[[[0.04852163]]]\n",
      "[[-0.83095012]]\n",
      "training for step = 508, loss = 0.7681846618652344\n",
      "509\n",
      "[[[-0.83095012]]]\n",
      "[[0.27045683]]\n",
      "training for step = 509, loss = 0.05399657413363457\n",
      "510\n",
      "[[[0.27045683]]]\n",
      "[[-0.05023811]]\n",
      "training for step = 510, loss = 0.013307674787938595\n",
      "511\n",
      "[[[-0.05023811]]]\n",
      "[[-0.23894805]]\n",
      "training for step = 511, loss = 0.09361743181943893\n",
      "512\n",
      "[[[-0.23894805]]]\n",
      "[[-0.90756366]]\n",
      "training for step = 512, loss = 0.9410472512245178\n",
      "513\n",
      "[[[-0.90756366]]]\n",
      "[[-0.57677133]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training for step = 513, loss = 0.3823847770690918\n",
      "514\n",
      "[[[-0.57677133]]]\n",
      "[[0.75539123]]\n",
      "training for step = 514, loss = 0.5000484585762024\n",
      "515\n",
      "[[[0.75539123]]]\n",
      "[[0.50091719]]\n",
      "training for step = 515, loss = 0.18420322239398956\n",
      "516\n",
      "[[[0.50091719]]]\n",
      "[[-0.97755524]]\n",
      "training for step = 516, loss = 1.0955227613449097\n",
      "517\n",
      "[[[-0.97755524]]]\n",
      "[[0.09933231]]\n",
      "training for step = 517, loss = 0.004706318490207195\n",
      "518\n",
      "[[[0.09933231]]]\n",
      "[[0.75138712]]\n",
      "training for step = 518, loss = 0.5015077590942383\n",
      "519\n",
      "[[[0.75138712]]]\n",
      "[[-1.66940528]]\n",
      "training for step = 519, loss = 2.954383134841919\n",
      "520\n",
      "[[[-1.66940528]]]\n",
      "[[0.54336019]]\n",
      "training for step = 520, loss = 0.31032904982566833\n",
      "521\n",
      "[[[0.54336019]]]\n",
      "[[-0.66262376]]\n",
      "training for step = 521, loss = 0.4727906584739685\n",
      "522\n",
      "[[[-0.66262376]]]\n",
      "[[0.57059867]]\n",
      "training for step = 522, loss = 0.31065741181373596\n",
      "523\n",
      "[[[0.57059867]]]\n",
      "[[-0.76325916]]\n",
      "training for step = 523, loss = 0.6351593732833862\n",
      "524\n",
      "[[[-0.76325916]]]\n",
      "[[-1.8048821]]\n",
      "training for step = 524, loss = 3.312277317047119\n",
      "525\n",
      "[[[-1.8048821]]]\n",
      "[[-1.62754244]]\n",
      "training for step = 525, loss = 2.561828851699829\n",
      "526\n",
      "[[[-1.62754244]]]\n",
      "[[0.04808495]]\n",
      "training for step = 526, loss = 0.00496351532638073\n",
      "527\n",
      "[[[0.04808495]]]\n",
      "[[0.2597225]]\n",
      "training for step = 527, loss = 0.04854850098490715\n",
      "528\n",
      "[[[0.2597225]]]\n",
      "[[-0.90431663]]\n",
      "training for step = 528, loss = 0.9351099729537964\n",
      "529\n",
      "[[[-0.90431663]]]\n",
      "[[0.63859246]]\n",
      "training for step = 529, loss = 0.35333481431007385\n",
      "530\n",
      "[[[0.63859246]]]\n",
      "[[-1.66152006]]\n",
      "training for step = 530, loss = 2.986717939376831\n",
      "531\n",
      "[[[-1.66152006]]]\n",
      "[[-0.0660798]]\n",
      "training for step = 531, loss = 0.0053208074532449245\n",
      "532\n",
      "[[[-0.0660798]]]\n",
      "[[-1.2110162]]\n",
      "training for step = 532, loss = 1.5631721019744873\n",
      "533\n",
      "[[[-1.2110162]]]\n",
      "[[-0.65183611]]\n",
      "training for step = 533, loss = 0.44403505325317383\n",
      "534\n",
      "[[[-0.65183611]]]\n",
      "[[0.04739867]]\n",
      "training for step = 534, loss = 0.00027361270622350276\n",
      "535\n",
      "[[[0.04739867]]]\n",
      "[[-0.86041337]]\n",
      "training for step = 535, loss = 0.8382164239883423\n",
      "536\n",
      "[[[-0.86041337]]]\n",
      "[[-0.38455554]]\n",
      "training for step = 536, loss = 0.17900800704956055\n",
      "537\n",
      "[[[-0.38455554]]]\n",
      "[[1.00629281]]\n",
      "training for step = 537, loss = 0.9185901284217834\n",
      "538\n",
      "[[[1.00629281]]]\n",
      "[[-0.57689187]]\n",
      "training for step = 538, loss = 0.41071340441703796\n",
      "539\n",
      "[[[-0.57689187]]]\n",
      "[[0.83569211]]\n",
      "training for step = 539, loss = 0.6338204145431519\n",
      "540\n",
      "[[[0.83569211]]]\n",
      "[[-1.12970685]]\n",
      "training for step = 540, loss = 1.3779594898223877\n",
      "541\n",
      "[[[-1.12970685]]]\n",
      "[[0.52980418]]\n",
      "training for step = 541, loss = 0.2819439172744751\n",
      "542\n",
      "[[[0.52980418]]]\n",
      "[[1.44156862]]\n",
      "training for step = 542, loss = 2.0274128913879395\n",
      "543\n",
      "[[[1.44156862]]]\n",
      "[[-2.4716445]]\n",
      "training for step = 543, loss = 6.196009159088135\n",
      "544\n",
      "[[[-2.4716445]]]\n",
      "[[-0.79689526]]\n",
      "training for step = 544, loss = 0.502239465713501\n",
      "545\n",
      "[[[-0.79689526]]]\n",
      "[[0.57707213]]\n",
      "training for step = 545, loss = 0.4088970124721527\n",
      "546\n",
      "[[[0.57707213]]]\n",
      "[[-0.20304539]]\n",
      "training for step = 546, loss = 0.03314230218529701\n",
      "547\n",
      "[[[-0.20304539]]]\n",
      "[[0.37114587]]\n",
      "training for step = 547, loss = 0.14974749088287354\n",
      "548\n",
      "[[[0.37114587]]]\n",
      "[[-0.60398519]]\n",
      "training for step = 548, loss = 0.36195045709609985\n",
      "549\n",
      "[[[-0.60398519]]]\n",
      "[[0.08658979]]\n",
      "training for step = 549, loss = 0.010197620838880539\n",
      "550\n",
      "[[[0.08658979]]]\n",
      "[[-0.15567724]]\n",
      "training for step = 550, loss = 0.023671919479966164\n",
      "551\n",
      "[[[-0.15567724]]]\n",
      "[[1.16778206]]\n",
      "training for step = 551, loss = 1.3641724586486816\n",
      "552\n",
      "[[[1.16778206]]]\n",
      "[[0.25442084]]\n",
      "training for step = 552, loss = 0.06104802340269089\n",
      "553\n",
      "[[[0.25442084]]]\n",
      "[[0.33760266]]\n",
      "training for step = 553, loss = 0.11381480097770691\n",
      "554\n",
      "[[[0.33760266]]]\n",
      "[[-0.41187697]]\n",
      "training for step = 554, loss = 0.16309377551078796\n",
      "555\n",
      "[[[-0.41187697]]]\n",
      "[[-0.48760622]]\n",
      "training for step = 555, loss = 0.2141966074705124\n",
      "556\n",
      "[[[-0.48760622]]]\n",
      "[[-0.43255819]]\n",
      "training for step = 556, loss = 0.16164949536323547\n",
      "557\n",
      "[[[-0.43255819]]]\n",
      "[[0.39445214]]\n",
      "training for step = 557, loss = 0.17603638768196106\n",
      "558\n",
      "[[[0.39445214]]]\n",
      "[[-0.42098448]]\n",
      "training for step = 558, loss = 0.17281916737556458\n",
      "559\n",
      "[[[-0.42098448]]]\n",
      "[[0.28977486]]\n",
      "training for step = 559, loss = 0.08976448327302933\n",
      "560\n",
      "[[[0.28977486]]]\n",
      "[[2.0754008]]\n",
      "training for step = 560, loss = 4.298714637756348\n",
      "561\n",
      "[[[2.0754008]]]\n",
      "[[0.8711247]]\n",
      "training for step = 561, loss = 0.7711402773857117\n",
      "562\n",
      "[[[0.8711247]]]\n",
      "[[-0.32602353]]\n",
      "training for step = 562, loss = 0.09895206242799759\n",
      "563\n",
      "[[[-0.32602353]]]\n",
      "[[1.20121392]]\n",
      "training for step = 563, loss = 1.5348438024520874\n",
      "564\n",
      "[[[1.20121392]]]\n",
      "[[-0.40807537]]\n",
      "training for step = 564, loss = 0.13611429929733276\n",
      "565\n",
      "[[[-0.40807537]]]\n",
      "[[-2.03812454]]\n",
      "training for step = 565, loss = 3.9255316257476807\n",
      "566\n",
      "[[[-2.03812454]]]\n",
      "[[-1.00808631]]\n",
      "training for step = 566, loss = 0.7894765734672546\n",
      "567\n",
      "[[[-1.00808631]]]\n",
      "[[-1.87079192]]\n",
      "training for step = 567, loss = 3.1806323528289795\n",
      "568\n",
      "[[[-1.87079192]]]\n",
      "[[-0.35151348]]\n",
      "training for step = 568, loss = 0.06451188772916794\n",
      "569\n",
      "[[[-0.35151348]]]\n",
      "[[0.01841838]]\n",
      "training for step = 569, loss = 0.00263486267067492\n",
      "570\n",
      "[[[0.01841838]]]\n",
      "[[1.67643731]]\n",
      "training for step = 570, loss = 2.798276424407959\n",
      "571\n",
      "[[[1.67643731]]]\n",
      "[[0.32692737]]\n",
      "training for step = 571, loss = 0.09570983797311783\n",
      "572\n",
      "[[[0.32692737]]]\n",
      "[[-0.21910053]]\n",
      "training for step = 572, loss = 0.05588168650865555\n",
      "573\n",
      "[[[-0.21910053]]]\n",
      "[[0.82940558]]\n",
      "training for step = 573, loss = 0.6883915066719055\n",
      "574\n",
      "[[[0.82940558]]]\n",
      "[[-2.21113531]]\n",
      "training for step = 574, loss = 4.8892693519592285\n",
      "575\n",
      "[[[-2.21113531]]]\n",
      "[[0.23561456]]\n",
      "training for step = 575, loss = 0.1070762574672699\n",
      "576\n",
      "[[[0.23561456]]]\n",
      "[[0.77086519]]\n",
      "training for step = 576, loss = 0.6584603190422058\n",
      "577\n",
      "[[[0.77086519]]]\n",
      "[[-1.47858625]]\n",
      "training for step = 577, loss = 2.127558946609497\n",
      "578\n",
      "[[[-1.47858625]]]\n",
      "[[1.14375404]]\n",
      "training for step = 578, loss = 1.460845708847046\n",
      "579\n",
      "[[[1.14375404]]]\n",
      "[[0.33849641]]\n",
      "training for step = 579, loss = 0.13146191835403442\n",
      "580\n",
      "[[[0.33849641]]]\n",
      "[[-0.41528791]]\n",
      "training for step = 580, loss = 0.15595920383930206\n",
      "581\n",
      "[[[-0.41528791]]]\n",
      "[[0.63278187]]\n",
      "training for step = 581, loss = 0.44226402044296265\n",
      "582\n",
      "[[[0.63278187]]]\n",
      "[[2.27069286]]\n",
      "training for step = 582, loss = 5.249405860900879\n",
      "583\n",
      "[[[2.27069286]]]\n",
      "[[0.18186626]]\n",
      "training for step = 583, loss = 0.04543177783489227\n",
      "584\n",
      "[[[0.18186626]]]\n",
      "[[0.24822059]]\n",
      "training for step = 584, loss = 0.08180620521306992\n",
      "585\n",
      "[[[0.24822059]]]\n",
      "[[-0.4593609]]\n",
      "training for step = 585, loss = 0.16586484014987946\n",
      "586\n",
      "[[[-0.4593609]]]\n",
      "[[-0.84984437]]\n",
      "training for step = 586, loss = 0.6092380285263062\n",
      "587\n",
      "[[[-0.84984437]]]\n",
      "[[0.83033582]]\n",
      "training for step = 587, loss = 0.828592836856842\n",
      "588\n",
      "[[[0.83033582]]]\n",
      "[[-0.85608383]]\n",
      "training for step = 588, loss = 0.6579883098602295\n",
      "589\n",
      "[[[-0.85608383]]]\n",
      "[[0.07156624]]\n",
      "training for step = 589, loss = 0.016854124143719673\n",
      "590\n",
      "[[[0.07156624]]]\n",
      "[[-0.47765745]]\n",
      "training for step = 590, loss = 0.19732773303985596\n",
      "591\n",
      "[[[-0.47765745]]]\n",
      "[[0.47897983]]\n",
      "training for step = 591, loss = 0.25824427604675293\n",
      "592\n",
      "[[[0.47897983]]]\n",
      "[[0.33366211]]\n",
      "training for step = 592, loss = 0.11577108502388\n",
      "593\n",
      "[[[0.33366211]]]\n",
      "[[1.03753994]]\n",
      "training for step = 593, loss = 1.0783393383026123\n",
      "594\n",
      "[[[1.03753994]]]\n",
      "[[-0.5100164]]\n",
      "training for step = 594, loss = 0.2585744261741638\n",
      "595\n",
      "[[[-0.5100164]]]\n",
      "[[-0.26987494]]\n",
      "training for step = 595, loss = 0.061853185296058655\n",
      "596\n",
      "[[[-0.26987494]]]\n",
      "[[-0.97876372]]\n",
      "training for step = 596, loss = 0.9104751944541931\n",
      "597\n",
      "[[[-0.97876372]]]\n",
      "[[-0.44429326]]\n",
      "training for step = 597, loss = 0.1642468273639679\n",
      "598\n",
      "[[[-0.44429326]]]\n",
      "[[0.37730049]]\n",
      "training for step = 598, loss = 0.15682263672351837\n",
      "599\n",
      "[[[0.37730049]]]\n",
      "[[0.75698862]]\n",
      "training for step = 599, loss = 0.5615760684013367\n",
      "600\n",
      "[[[0.75698862]]]\n",
      "[[-0.92216532]]\n",
      "training for step = 600, loss = 0.87852543592453\n",
      "601\n",
      "[[[-0.92216532]]]\n",
      "[[0.86960592]]\n",
      "training for step = 601, loss = 0.7763317227363586\n",
      "602\n",
      "[[[0.86960592]]]\n",
      "[[1.35563786]]\n",
      "training for step = 602, loss = 1.8247261047363281\n",
      "603\n",
      "[[[1.35563786]]]\n",
      "[[0.4134349]]\n",
      "training for step = 603, loss = 0.17255674302577972\n",
      "604\n",
      "[[[0.4134349]]]\n",
      "[[1.87679581]]\n",
      "training for step = 604, loss = 3.5718841552734375\n",
      "605\n",
      "[[[1.87679581]]]\n",
      "[[-0.7737892]]\n",
      "training for step = 605, loss = 0.5543228983879089\n",
      "606\n",
      "[[[-0.7737892]]]\n",
      "[[-1.2446547]]\n",
      "training for step = 606, loss = 1.4033019542694092\n",
      "607\n",
      "[[[-1.2446547]]]\n",
      "[[-1.77872025]]\n",
      "training for step = 607, loss = 2.836303234100342\n",
      "608\n",
      "[[[-1.77872025]]]\n",
      "[[1.49604431]]\n",
      "training for step = 608, loss = 2.5959596633911133\n",
      "609\n",
      "[[[1.49604431]]]\n",
      "[[0.65436566]]\n",
      "training for step = 609, loss = 0.49049368500709534\n",
      "610\n",
      "[[[0.65436566]]]\n",
      "[[-0.05558467]]\n",
      "training for step = 610, loss = 0.00047603441635146737\n",
      "611\n",
      "[[[-0.05558467]]]\n",
      "[[0.27996863]]\n",
      "training for step = 611, loss = 0.09927333146333694\n",
      "612\n",
      "[[[0.27996863]]]\n",
      "[[-1.12548905]]\n",
      "training for step = 612, loss = 1.2009904384613037\n",
      "613\n",
      "[[[-1.12548905]]]\n",
      "[[2.44575198]]\n",
      "training for step = 613, loss = 6.251819133758545\n",
      "614\n",
      "[[[2.44575198]]]\n",
      "[[0.12922118]]\n",
      "training for step = 614, loss = 0.028620589524507523\n",
      "615\n",
      "[[[0.12922118]]]\n",
      "[[0.10939479]]\n",
      "training for step = 615, loss = 0.02262241393327713\n",
      "616\n",
      "[[[0.10939479]]]\n",
      "[[0.72576662]]\n",
      "training for step = 616, loss = 0.5988934636116028\n",
      "617\n",
      "[[[0.72576662]]]\n",
      "[[0.48100923]]\n",
      "training for step = 617, loss = 0.27648669481277466\n",
      "618\n",
      "[[[0.48100923]]]\n",
      "[[0.22388402]]\n",
      "training for step = 618, loss = 0.07256557047367096\n",
      "619\n",
      "[[[0.22388402]]]\n",
      "[[-0.79047446]]\n",
      "training for step = 619, loss = 0.551068902015686\n",
      "620\n",
      "[[[-0.79047446]]]\n",
      "[[0.47146836]]\n",
      "training for step = 620, loss = 0.2863031029701233\n",
      "621\n",
      "[[[0.47146836]]]\n",
      "[[1.8820245]]\n",
      "training for step = 621, loss = 3.690793037414551\n",
      "622\n",
      "[[[1.8820245]]]\n",
      "[[1.34542005]]\n",
      "training for step = 622, loss = 1.9107091426849365\n",
      "623\n",
      "[[[1.34542005]]]\n",
      "[[1.59318663]]\n",
      "training for step = 623, loss = 2.660581111907959\n",
      "624\n",
      "[[[1.59318663]]]\n",
      "[[-0.51121568]]\n",
      "training for step = 624, loss = 0.21783989667892456\n",
      "625\n",
      "[[[-0.51121568]]]\n",
      "[[-0.98960482]]\n",
      "training for step = 625, loss = 0.8404419422149658\n",
      "626\n",
      "[[[-0.98960482]]]\n",
      "[[-0.12578692]]\n",
      "training for step = 626, loss = 0.0006593880825676024\n",
      "627\n",
      "[[[-0.12578692]]]\n",
      "[[0.05572491]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training for step = 627, loss = 0.016659153625369072\n",
      "628\n",
      "[[[0.05572491]]]\n",
      "[[1.09419152]]\n",
      "training for step = 628, loss = 1.3057351112365723\n",
      "629\n",
      "[[[1.09419152]]]\n",
      "[[-1.69246463]]\n",
      "training for step = 629, loss = 2.7741453647613525\n",
      "630\n",
      "[[[-1.69246463]]]\n",
      "[[1.52955032]]\n",
      "training for step = 630, loss = 2.5634725093841553\n",
      "631\n",
      "[[[1.52955032]]]\n",
      "[[-0.1580079]]\n",
      "training for step = 631, loss = 0.016404427587985992\n",
      "632\n",
      "[[[-0.1580079]]]\n",
      "[[-0.42688107]]\n",
      "training for step = 632, loss = 0.1581546813249588\n",
      "633\n",
      "[[[-0.42688107]]]\n",
      "[[-1.01210438]]\n",
      "training for step = 633, loss = 0.9659178853034973\n",
      "634\n",
      "[[[-1.01210438]]]\n",
      "[[-1.65485667]]\n",
      "training for step = 634, loss = 2.6285223960876465\n",
      "635\n",
      "[[[-1.65485667]]]\n",
      "[[0.82317058]]\n",
      "training for step = 635, loss = 0.7498197555541992\n",
      "636\n",
      "[[[0.82317058]]]\n",
      "[[0.07331797]]\n",
      "training for step = 636, loss = 0.002862259978428483\n",
      "637\n",
      "[[[0.07331797]]]\n",
      "[[-1.2899609]]\n",
      "training for step = 637, loss = 1.7428902387619019\n",
      "638\n",
      "[[[-1.2899609]]]\n",
      "[[-1.29507877]]\n",
      "training for step = 638, loss = 1.6896334886550903\n",
      "639\n",
      "[[[-1.29507877]]]\n",
      "[[-0.3357847]]\n",
      "training for step = 639, loss = 0.11637365072965622\n",
      "640\n",
      "[[[-0.3357847]]]\n",
      "[[1.66902153]]\n",
      "training for step = 640, loss = 2.6399214267730713\n",
      "641\n",
      "[[[1.66902153]]]\n",
      "[[-0.25959135]]\n",
      "training for step = 641, loss = 0.10020176321268082\n",
      "642\n",
      "[[[-0.25959135]]]\n",
      "[[-1.50314295]]\n",
      "training for step = 642, loss = 2.3974416255950928\n",
      "643\n",
      "[[[-1.50314295]]]\n",
      "[[-0.24574306]]\n",
      "training for step = 643, loss = 0.05965443700551987\n",
      "644\n",
      "[[[-0.24574306]]]\n",
      "[[-0.27272357]]\n",
      "training for step = 644, loss = 0.08998845517635345\n",
      "645\n",
      "[[[-0.27272357]]]\n",
      "[[-2.69688664]]\n",
      "training for step = 645, loss = 7.483969211578369\n",
      "646\n",
      "[[[-2.69688664]]]\n",
      "[[-0.05429487]]\n",
      "training for step = 646, loss = 3.6046742025064304e-05\n",
      "647\n",
      "[[[-0.05429487]]]\n",
      "[[-0.23093453]]\n",
      "training for step = 647, loss = 0.06747091561555862\n",
      "648\n",
      "[[[-0.23093453]]]\n",
      "[[0.69620636]]\n",
      "training for step = 648, loss = 0.4197179973125458\n",
      "649\n",
      "[[[0.69620636]]]\n",
      "[[1.84895609]]\n",
      "training for step = 649, loss = 3.186657190322876\n",
      "650\n",
      "[[[1.84895609]]]\n",
      "[[1.12656503]]\n",
      "training for step = 650, loss = 1.1693804264068604\n",
      "651\n",
      "[[[1.12656503]]]\n",
      "[[-0.26888869]]\n",
      "training for step = 651, loss = 0.08979035913944244\n",
      "652\n",
      "[[[-0.26888869]]]\n",
      "[[-1.10652591]]\n",
      "training for step = 652, loss = 1.2225812673568726\n",
      "653\n",
      "[[[-1.10652591]]]\n",
      "[[2.5733598]]\n",
      "training for step = 653, loss = 6.84906005859375\n",
      "654\n",
      "[[[2.5733598]]]\n",
      "[[0.05921843]]\n",
      "training for step = 654, loss = 0.008213228546082973\n",
      "655\n",
      "[[[0.05921843]]]\n",
      "[[0.01392929]]\n",
      "training for step = 655, loss = 0.0027910745702683926\n",
      "656\n",
      "[[[0.01392929]]]\n",
      "[[-0.02412509]]\n",
      "training for step = 656, loss = 0.0006156844319775701\n",
      "657\n",
      "[[[-0.02412509]]]\n",
      "[[0.19808476]]\n",
      "training for step = 657, loss = 0.06101788207888603\n",
      "658\n",
      "[[[0.19808476]]]\n",
      "[[-0.14436041]]\n",
      "training for step = 658, loss = 0.010950838215649128\n",
      "659\n",
      "[[[-0.14436041]]]\n",
      "[[-0.57366201]]\n",
      "training for step = 659, loss = 0.2891511023044586\n",
      "660\n",
      "[[[-0.57366201]]]\n",
      "[[-0.54685894]]\n",
      "training for step = 660, loss = 0.2616170644760132\n",
      "661\n",
      "[[[-0.54685894]]]\n",
      "[[-0.03275327]]\n",
      "training for step = 661, loss = 9.446952026337385e-05\n",
      "662\n",
      "[[[-0.03275327]]]\n",
      "[[-0.54342477]]\n",
      "training for step = 662, loss = 0.29702305793762207\n",
      "663\n",
      "[[[-0.54342477]]]\n",
      "[[-0.71284578]]\n",
      "training for step = 663, loss = 0.5172431468963623\n",
      "664\n",
      "[[[-0.71284578]]]\n",
      "[[0.10643023]]\n",
      "training for step = 664, loss = 0.008952919393777847\n",
      "665\n",
      "[[[0.10643023]]]\n",
      "[[-0.25497722]]\n",
      "training for step = 665, loss = 0.08521972596645355\n",
      "666\n",
      "[[[-0.25497722]]]\n",
      "[[1.50399299]]\n",
      "training for step = 666, loss = 2.142651081085205\n",
      "667\n",
      "[[[1.50399299]]]\n",
      "[[-2.65096981]]\n",
      "training for step = 667, loss = 7.2633585929870605\n",
      "668\n",
      "[[[-2.65096981]]]\n",
      "[[1.09150685]]\n",
      "training for step = 668, loss = 1.3284610509872437\n",
      "669\n",
      "[[[1.09150685]]]\n",
      "[[1.24608519]]\n",
      "training for step = 669, loss = 1.566118597984314\n",
      "670\n",
      "[[[1.24608519]]]\n",
      "[[-2.07339023]]\n",
      "training for step = 670, loss = 4.282399654388428\n",
      "671\n",
      "[[[-2.07339023]]]\n",
      "[[-0.34268759]]\n",
      "training for step = 671, loss = 0.07286661863327026\n",
      "672\n",
      "[[[-0.34268759]]]\n",
      "[[-0.37144087]]\n",
      "training for step = 672, loss = 0.11253391951322556\n",
      "673\n",
      "[[[-0.37144087]]]\n",
      "[[-1.40751169]]\n",
      "training for step = 673, loss = 1.938437581062317\n",
      "674\n",
      "[[[-1.40751169]]]\n",
      "[[-0.77781669]]\n",
      "training for step = 674, loss = 0.5683542490005493\n",
      "675\n",
      "[[[-0.77781669]]]\n",
      "[[-1.11057585]]\n",
      "training for step = 675, loss = 1.2525763511657715\n",
      "676\n",
      "[[[-1.11057585]]]\n",
      "[[1.75227044]]\n",
      "training for step = 676, loss = 3.0004327297210693\n",
      "677\n",
      "[[[1.75227044]]]\n",
      "[[0.93567839]]\n",
      "training for step = 677, loss = 0.7889894247055054\n",
      "678\n",
      "[[[0.93567839]]]\n",
      "[[1.27155509]]\n",
      "training for step = 678, loss = 1.5204299688339233\n",
      "679\n",
      "[[[1.27155509]]]\n",
      "[[0.72167206]]\n",
      "training for step = 679, loss = 0.49682337045669556\n",
      "680\n",
      "[[[0.72167206]]]\n",
      "[[-1.12905177]]\n",
      "training for step = 680, loss = 1.2684061527252197\n",
      "681\n",
      "[[[-1.12905177]]]\n",
      "[[-0.52452027]]\n",
      "training for step = 681, loss = 0.2264586240053177\n",
      "682\n",
      "[[[-0.52452027]]]\n",
      "[[0.48937456]]\n",
      "training for step = 682, loss = 0.28638824820518494\n",
      "683\n",
      "[[[0.48937456]]]\n",
      "[[-1.22212781]]\n",
      "training for step = 683, loss = 1.4362263679504395\n",
      "684\n",
      "[[[-1.22212781]]]\n",
      "[[0.71299843]]\n",
      "training for step = 684, loss = 0.5700722336769104\n",
      "685\n",
      "[[[0.71299843]]]\n",
      "[[-0.2403254]]\n",
      "training for step = 685, loss = 0.053910091519355774\n",
      "686\n",
      "[[[-0.2403254]]]\n",
      "[[-0.37482081]]\n",
      "training for step = 686, loss = 0.13568635284900665\n",
      "687\n",
      "[[[-0.37482081]]]\n",
      "[[0.71095997]]\n",
      "training for step = 687, loss = 0.5093347430229187\n",
      "688\n",
      "[[[0.71095997]]]\n",
      "[[0.44426331]]\n",
      "training for step = 688, loss = 0.18868809938430786\n",
      "689\n",
      "[[[0.44426331]]]\n",
      "[[-0.36096617]]\n",
      "training for step = 689, loss = 0.13545380532741547\n",
      "690\n",
      "[[[-0.36096617]]]\n",
      "[[1.1593298]]\n",
      "training for step = 690, loss = 1.3559188842773438\n",
      "691\n",
      "[[[1.1593298]]]\n",
      "[[-1.08106333]]\n",
      "training for step = 691, loss = 1.1594136953353882\n",
      "692\n",
      "[[[-1.08106333]]]\n",
      "[[0.61593561]]\n",
      "training for step = 692, loss = 0.4201662242412567\n",
      "693\n",
      "[[[0.61593561]]]\n",
      "[[0.59310126]]\n",
      "training for step = 693, loss = 0.3702048659324646\n",
      "694\n",
      "[[[0.59310126]]]\n",
      "[[-0.30954644]]\n",
      "training for step = 694, loss = 0.08697128295898438\n",
      "695\n",
      "[[[-0.30954644]]]\n",
      "[[0.32613302]]\n",
      "training for step = 695, loss = 0.12214600294828415\n",
      "696\n",
      "[[[0.32613302]]]\n",
      "[[-1.25111358]]\n",
      "training for step = 696, loss = 1.5210644006729126\n",
      "697\n",
      "[[[-1.25111358]]]\n",
      "[[0.92402702]]\n",
      "training for step = 697, loss = 0.9240296483039856\n",
      "698\n",
      "[[[0.92402702]]]\n",
      "[[-0.18490214]]\n",
      "training for step = 698, loss = 0.030839066952466965\n",
      "699\n",
      "[[[-0.18490214]]]\n",
      "[[-0.52272302]]\n",
      "training for step = 699, loss = 0.2633930742740631\n",
      "700\n",
      "[[[-0.52272302]]]\n",
      "[[1.04900923]]\n",
      "training for step = 700, loss = 1.1189472675323486\n",
      "701\n",
      "[[[1.04900923]]]\n",
      "[[-0.70434369]]\n",
      "training for step = 701, loss = 0.49716684222221375\n",
      "702\n",
      "[[[-0.70434369]]]\n",
      "[[-1.4084613]]\n",
      "training for step = 702, loss = 1.9526548385620117\n",
      "703\n",
      "[[[-1.4084613]]]\n",
      "[[-1.55662917]]\n",
      "training for step = 703, loss = 2.353274345397949\n",
      "704\n",
      "[[[-1.55662917]]]\n",
      "[[0.60600995]]\n",
      "training for step = 704, loss = 0.3809970021247864\n",
      "705\n",
      "[[[0.60600995]]]\n",
      "[[-1.28042935]]\n",
      "training for step = 705, loss = 1.7428511381149292\n",
      "706\n",
      "[[[-1.28042935]]]\n",
      "[[1.75479418]]\n",
      "training for step = 706, loss = 2.9883663654327393\n",
      "707\n",
      "[[[1.75479418]]]\n",
      "[[-2.08192941]]\n",
      "training for step = 707, loss = 4.4881696701049805\n",
      "708\n",
      "[[[-2.08192941]]]\n",
      "[[1.69645637]]\n",
      "training for step = 708, loss = 2.936842203140259\n",
      "709\n",
      "[[[1.69645637]]]\n",
      "[[0.21101747]]\n",
      "training for step = 709, loss = 0.04406926780939102\n",
      "710\n",
      "[[[0.21101747]]]\n",
      "[[-0.09671311]]\n",
      "training for step = 710, loss = 0.0077432552352547646\n",
      "711\n",
      "[[[-0.09671311]]]\n",
      "[[-0.54491909]]\n",
      "training for step = 711, loss = 0.27690550684928894\n",
      "712\n",
      "[[[-0.54491909]]]\n",
      "[[0.39913611]]\n",
      "training for step = 712, loss = 0.1771227866411209\n",
      "713\n",
      "[[[0.39913611]]]\n",
      "[[-0.0376347]]\n",
      "training for step = 713, loss = 0.000691763183567673\n",
      "714\n",
      "[[[-0.0376347]]]\n",
      "[[1.10330188]]\n",
      "training for step = 714, loss = 1.2392910718917847\n",
      "715\n",
      "[[[1.10330188]]]\n",
      "[[0.11422765]]\n",
      "training for step = 715, loss = 0.017353061586618423\n",
      "716\n",
      "[[[0.11422765]]]\n",
      "[[0.15030176]]\n",
      "training for step = 716, loss = 0.031312495470047\n",
      "717\n",
      "[[[0.15030176]]]\n",
      "[[-0.36361221]]\n",
      "training for step = 717, loss = 0.10947628319263458\n",
      "718\n",
      "[[[-0.36361221]]]\n",
      "[[-0.05694562]]\n",
      "training for step = 718, loss = 0.0005586831248365343\n",
      "719\n",
      "[[[-0.05694562]]]\n",
      "[[0.30780177]]\n",
      "training for step = 719, loss = 0.10927286744117737\n",
      "720\n",
      "[[[0.30780177]]]\n",
      "[[-1.71016839]]\n",
      "training for step = 720, loss = 2.872440814971924\n",
      "721\n",
      "[[[-1.71016839]]]\n",
      "[[-1.34818542]]\n",
      "training for step = 721, loss = 1.7428436279296875\n",
      "722\n",
      "[[[-1.34818542]]]\n",
      "[[0.74326409]]\n",
      "training for step = 722, loss = 0.5458738803863525\n",
      "723\n",
      "[[[0.74326409]]]\n",
      "[[0.17086544]]\n",
      "training for step = 723, loss = 0.017371580004692078\n",
      "724\n",
      "[[[0.17086544]]]\n",
      "[[-0.18398334]]\n",
      "training for step = 724, loss = 0.05012975260615349\n",
      "725\n",
      "[[[-0.18398334]]]\n",
      "[[0.01843393]]\n",
      "training for step = 725, loss = 0.0003420939901843667\n",
      "726\n",
      "[[[0.01843393]]]\n",
      "[[0.34758171]]\n",
      "training for step = 726, loss = 0.09768190234899521\n",
      "727\n",
      "[[[0.34758171]]]\n",
      "[[-0.53975968]]\n",
      "training for step = 727, loss = 0.3222866952419281\n",
      "728\n",
      "[[[-0.53975968]]]\n",
      "[[-0.77830473]]\n",
      "training for step = 728, loss = 0.6383190155029297\n",
      "729\n",
      "[[[-0.77830473]]]\n",
      "[[0.19584526]]\n",
      "training for step = 729, loss = 0.029340431094169617\n",
      "730\n",
      "[[[0.19584526]]]\n",
      "[[-0.97837278]]\n",
      "training for step = 730, loss = 1.0332213640213013\n",
      "731\n",
      "[[[-0.97837278]]]\n",
      "[[0.40825276]]\n",
      "training for step = 731, loss = 0.1386764943599701\n",
      "732\n",
      "[[[0.40825276]]]\n",
      "[[-1.7025836]]\n",
      "training for step = 732, loss = 3.065319776535034\n",
      "733\n",
      "[[[-1.7025836]]]\n",
      "[[1.02915564]]\n",
      "training for step = 733, loss = 1.0032817125320435\n",
      "734\n",
      "[[[1.02915564]]]\n",
      "[[0.47259748]]\n",
      "training for step = 734, loss = 0.18366090953350067\n",
      "735\n",
      "[[[0.47259748]]]\n",
      "[[0.25602973]]\n",
      "training for step = 735, loss = 0.05154135823249817\n",
      "736\n",
      "[[[0.25602973]]]\n",
      "[[0.98269098]]\n",
      "training for step = 736, loss = 0.9418351650238037\n",
      "737\n",
      "[[[0.98269098]]]\n",
      "[[1.66547444]]\n",
      "training for step = 737, loss = 2.8147785663604736\n",
      "738\n",
      "[[[1.66547444]]]\n",
      "[[1.01437007]]\n",
      "training for step = 738, loss = 1.1198251247406006\n",
      "739\n",
      "[[[1.01437007]]]\n",
      "[[-1.84087423]]\n",
      "training for step = 739, loss = 3.15193772315979\n",
      "740\n",
      "[[[-1.84087423]]]\n",
      "[[-1.27957697]]\n",
      "training for step = 740, loss = 1.3708655834197998\n",
      "741\n",
      "[[[-1.27957697]]]\n",
      "[[-0.62481858]]\n",
      "training for step = 741, loss = 0.29205557703971863\n",
      "742\n",
      "[[[-0.62481858]]]\n",
      "[[0.02609105]]\n",
      "training for step = 742, loss = 0.003931017592549324\n",
      "743\n",
      "[[[0.02609105]]]\n",
      "[[0.51765902]]\n",
      "training for step = 743, loss = 0.27034035325050354\n",
      "744\n",
      "[[[0.51765902]]]\n",
      "[[-0.72574381]]\n",
      "training for step = 744, loss = 0.537498414516449\n",
      "745\n",
      "[[[-0.72574381]]]\n",
      "[[0.18676676]]\n",
      "training for step = 745, loss = 0.03149740770459175\n",
      "746\n",
      "[[[0.18676676]]]\n",
      "[[-0.75538293]]\n",
      "training for step = 746, loss = 0.6013554930686951\n",
      "747\n",
      "[[[-0.75538293]]]\n",
      "[[-0.6115178]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training for step = 747, loss = 0.40115663409233093\n",
      "748\n",
      "[[[-0.6115178]]]\n",
      "[[-1.4066611]]\n",
      "training for step = 748, loss = 2.082409143447876\n",
      "749\n",
      "[[[-1.4066611]]]\n",
      "[[-0.92323325]]\n",
      "training for step = 749, loss = 0.9299814701080322\n",
      "750\n",
      "[[[-0.92323325]]]\n",
      "[[-1.35168461]]\n",
      "training for step = 750, loss = 2.0234344005584717\n",
      "751\n",
      "[[[-1.35168461]]]\n",
      "[[-0.97587325]]\n",
      "training for step = 751, loss = 1.1188706159591675\n",
      "752\n",
      "[[[-0.97587325]]]\n",
      "[[1.0536418]]\n",
      "training for step = 752, loss = 0.8998178839683533\n",
      "753\n",
      "[[[1.0536418]]]\n",
      "[[-0.94939889]]\n",
      "training for step = 753, loss = 1.1254181861877441\n",
      "754\n",
      "[[[-0.94939889]]]\n",
      "[[2.63238206]]\n",
      "training for step = 754, loss = 6.47794771194458\n",
      "755\n",
      "[[[2.63238206]]]\n",
      "[[0.4933179]]\n",
      "training for step = 755, loss = 0.2093997448682785\n",
      "756\n",
      "[[[0.4933179]]]\n",
      "[[0.18483612]]\n",
      "training for step = 756, loss = 0.029770074412226677\n",
      "757\n",
      "[[[0.18483612]]]\n",
      "[[-0.85835778]]\n",
      "training for step = 757, loss = 0.7039352059364319\n",
      "758\n",
      "[[[-0.85835778]]]\n",
      "[[0.70030988]]\n",
      "training for step = 758, loss = 0.5536713600158691\n",
      "759\n",
      "[[[0.70030988]]]\n",
      "[[-0.57563783]]\n",
      "training for step = 759, loss = 0.2877405285835266\n",
      "760\n",
      "[[[-0.57563783]]]\n",
      "[[0.12200981]]\n",
      "training for step = 760, loss = 0.027725104242563248\n",
      "761\n",
      "[[[0.12200981]]]\n",
      "[[2.56008454]]\n",
      "training for step = 761, loss = 6.728208065032959\n",
      "762\n",
      "[[[2.56008454]]]\n",
      "[[-0.0960599]]\n",
      "training for step = 762, loss = 0.0015083858743309975\n",
      "763\n",
      "[[[-0.0960599]]]\n",
      "[[1.14927333]]\n",
      "training for step = 763, loss = 1.4821505546569824\n",
      "764\n",
      "[[[1.14927333]]]\n",
      "[[-0.70317643]]\n",
      "training for step = 764, loss = 0.38628849387168884\n",
      "765\n",
      "[[[-0.70317643]]]\n",
      "[[-0.03498849]]\n",
      "training for step = 765, loss = 0.004006729461252689\n",
      "766\n",
      "[[[-0.03498849]]]\n",
      "[[1.77080064]]\n",
      "training for step = 766, loss = 3.4531023502349854\n",
      "767\n",
      "[[[1.77080064]]]\n",
      "[[-0.62696706]]\n",
      "training for step = 767, loss = 0.2927679419517517\n",
      "768\n",
      "[[[-0.62696706]]]\n",
      "[[1.81244856]]\n",
      "training for step = 768, loss = 3.6323115825653076\n",
      "769\n",
      "[[[1.81244856]]]\n",
      "[[0.70775194]]\n",
      "training for step = 769, loss = 0.6421017050743103\n",
      "770\n",
      "[[[0.70775194]]]\n",
      "[[-0.56246678]]\n",
      "training for step = 770, loss = 0.21627120673656464\n",
      "771\n",
      "[[[-0.56246678]]]\n",
      "[[0.63240774]]\n",
      "training for step = 771, loss = 0.5496200323104858\n",
      "772\n",
      "[[[0.63240774]]]\n",
      "[[0.97255445]]\n",
      "training for step = 772, loss = 1.1442114114761353\n",
      "773\n",
      "[[[0.97255445]]]\n",
      "[[0.62180996]]\n",
      "training for step = 773, loss = 0.5099367499351501\n",
      "774\n",
      "[[[0.62180996]]]\n",
      "[[-1.57022472]]\n",
      "training for step = 774, loss = 2.1858601570129395\n",
      "775\n",
      "[[[-1.57022472]]]\n",
      "[[-0.72713718]]\n",
      "training for step = 775, loss = 0.3807828426361084\n",
      "776\n",
      "[[[-0.72713718]]]\n",
      "[[-0.24751864]]\n",
      "training for step = 776, loss = 0.030350307002663612\n",
      "777\n",
      "[[[-0.24751864]]]\n",
      "[[-0.07443343]]\n",
      "training for step = 777, loss = 0.001484473585151136\n",
      "778\n",
      "[[[-0.07443343]]]\n",
      "[[0.6206721]]\n",
      "training for step = 778, loss = 0.39791804552078247\n",
      "779\n",
      "[[[0.6206721]]]\n",
      "[[0.177701]]\n",
      "training for step = 779, loss = 0.03160715103149414\n",
      "780\n",
      "[[[0.177701]]]\n",
      "[[-1.33534436]]\n",
      "training for step = 780, loss = 1.7836519479751587\n",
      "781\n",
      "[[[-1.33534436]]]\n",
      "[[0.38019785]]\n",
      "training for step = 781, loss = 0.1536906510591507\n",
      "782\n",
      "[[[0.38019785]]]\n",
      "[[0.61058575]]\n",
      "training for step = 782, loss = 0.35898059606552124\n",
      "783\n",
      "[[[0.61058575]]]\n",
      "[[0.55979045]]\n",
      "training for step = 783, loss = 0.3023710548877716\n",
      "784\n",
      "[[[0.55979045]]]\n",
      "[[1.08078073]]\n",
      "training for step = 784, loss = 1.1673355102539062\n",
      "785\n",
      "[[[1.08078073]]]\n",
      "[[0.83392215]]\n",
      "training for step = 785, loss = 0.7248441576957703\n",
      "786\n",
      "[[[0.83392215]]]\n",
      "[[0.45918008]]\n",
      "training for step = 786, loss = 0.2429240643978119\n",
      "787\n",
      "[[[0.45918008]]]\n",
      "[[-0.07016571]]\n",
      "training for step = 787, loss = 0.0004809396923519671\n",
      "788\n",
      "[[[-0.07016571]]]\n",
      "[[-1.66096093]]\n",
      "training for step = 788, loss = 2.5687496662139893\n",
      "789\n",
      "[[[-1.66096093]]]\n",
      "[[0.42961822]]\n",
      "training for step = 789, loss = 0.25601258873939514\n",
      "790\n",
      "[[[0.42961822]]]\n",
      "[[0.20768769]]\n",
      "training for step = 790, loss = 0.05968040972948074\n",
      "791\n",
      "[[[0.20768769]]]\n",
      "[[0.27157884]]\n",
      "training for step = 791, loss = 0.0868055522441864\n",
      "792\n",
      "[[[0.27157884]]]\n",
      "[[-1.27674858]]\n",
      "training for step = 792, loss = 1.5897579193115234\n",
      "793\n",
      "[[[-1.27674858]]]\n",
      "[[-1.08105654]]\n",
      "training for step = 793, loss = 1.12071692943573\n",
      "794\n",
      "[[[-1.08105654]]]\n",
      "[[1.05315285]]\n",
      "training for step = 794, loss = 1.1094846725463867\n",
      "795\n",
      "[[[1.05315285]]]\n",
      "[[-0.03955515]]\n",
      "training for step = 795, loss = 0.003778130281716585\n",
      "796\n",
      "[[[-0.03955515]]]\n",
      "[[0.6815007]]\n",
      "training for step = 796, loss = 0.4353521466255188\n",
      "797\n",
      "[[[0.6815007]]]\n",
      "[[0.02831838]]\n",
      "training for step = 797, loss = 0.00018614111468195915\n",
      "798\n",
      "[[[0.02831838]]]\n",
      "[[0.02975614]]\n",
      "training for step = 798, loss = 0.0005612397799268365\n",
      "799\n",
      "[[[0.02975614]]]\n",
      "[[0.93828381]]\n",
      "training for step = 799, loss = 0.8786712288856506\n",
      "800\n",
      "[[[0.93828381]]]\n",
      "[[-0.51604473]]\n",
      "training for step = 800, loss = 0.25825801491737366\n",
      "801\n",
      "[[[-0.51604473]]]\n",
      "[[0.09612078]]\n",
      "training for step = 801, loss = 0.01300331111997366\n",
      "802\n",
      "[[[0.09612078]]]\n",
      "[[-0.46227529]]\n",
      "training for step = 802, loss = 0.20154868066310883\n",
      "803\n",
      "[[[-0.46227529]]]\n",
      "[[-0.43449623]]\n",
      "training for step = 803, loss = 0.18055756390094757\n",
      "804\n",
      "[[[-0.43449623]]]\n",
      "[[-0.30917212]]\n",
      "training for step = 804, loss = 0.09759415686130524\n",
      "805\n",
      "[[[-0.30917212]]]\n",
      "[[0.22213377]]\n",
      "training for step = 805, loss = 0.041354287415742874\n",
      "806\n",
      "[[[0.22213377]]]\n",
      "[[-0.47874862]]\n",
      "training for step = 806, loss = 0.25853458046913147\n",
      "807\n",
      "[[[-0.47874862]]]\n",
      "[[1.25575613]]\n",
      "training for step = 807, loss = 1.4997729063034058\n",
      "808\n",
      "[[[1.25575613]]]\n",
      "[[-0.8946073]]\n",
      "training for step = 808, loss = 0.8423351049423218\n",
      "809\n",
      "[[[-0.8946073]]]\n",
      "[[-0.18687164]]\n",
      "training for step = 809, loss = 0.038396064192056656\n",
      "810\n",
      "[[[-0.18687164]]]\n",
      "[[-0.43973106]]\n",
      "training for step = 810, loss = 0.2087610960006714\n",
      "811\n",
      "[[[-0.43973106]]]\n",
      "[[1.44697788]]\n",
      "training for step = 811, loss = 2.02632737159729\n",
      "812\n",
      "[[[1.44697788]]]\n",
      "[[0.19655478]]\n",
      "training for step = 812, loss = 0.03329218178987503\n",
      "813\n",
      "[[[0.19655478]]]\n",
      "[[1.03184454]]\n",
      "training for step = 813, loss = 1.058782935142517\n",
      "814\n",
      "[[[1.03184454]]]\n",
      "[[-1.48556037]]\n",
      "training for step = 814, loss = 2.160118341445923\n",
      "815\n",
      "[[[-1.48556037]]]\n",
      "[[0.26705027]]\n",
      "training for step = 815, loss = 0.09599188715219498\n",
      "816\n",
      "[[[0.26705027]]]\n",
      "[[0.8896308]]\n",
      "training for step = 816, loss = 0.8294270634651184\n",
      "817\n",
      "[[[0.8896308]]]\n",
      "[[0.08228399]]\n",
      "training for step = 817, loss = 0.010848023928701878\n",
      "818\n",
      "[[[0.08228399]]]\n",
      "[[1.06548038]]\n",
      "training for step = 818, loss = 1.189685344696045\n",
      "819\n",
      "[[[1.06548038]]]\n",
      "[[-0.51728845]]\n",
      "training for step = 819, loss = 0.2326822727918625\n",
      "820\n",
      "[[[-0.51728845]]]\n",
      "[[1.40934744]]\n",
      "training for step = 820, loss = 2.106260061264038\n",
      "821\n",
      "[[[1.40934744]]]\n",
      "[[2.29889812]]\n",
      "training for step = 821, loss = 5.509204387664795\n",
      "822\n",
      "[[[2.29889812]]]\n",
      "[[-0.36283856]]\n",
      "training for step = 822, loss = 0.08787812292575836\n",
      "823\n",
      "[[[-0.36283856]]]\n",
      "[[-0.44550252]]\n",
      "training for step = 823, loss = 0.13255581259727478\n",
      "824\n",
      "[[[-0.44550252]]]\n",
      "[[1.45338448]]\n",
      "training for step = 824, loss = 2.37436842918396\n",
      "825\n",
      "[[[1.45338448]]]\n",
      "[[1.57957215]]\n",
      "training for step = 825, loss = 2.758197069168091\n",
      "826\n",
      "[[[1.57957215]]]\n",
      "[[-0.52286003]]\n",
      "training for step = 826, loss = 0.19252285361289978\n",
      "827\n",
      "[[[-0.52286003]]]\n",
      "[[-0.42018682]]\n",
      "training for step = 827, loss = 0.10578157007694244\n",
      "828\n",
      "[[[-0.42018682]]]\n",
      "[[-0.28178461]]\n",
      "training for step = 828, loss = 0.03825231269001961\n",
      "829\n",
      "[[[-0.28178461]]]\n",
      "[[-1.34445051]]\n",
      "training for step = 829, loss = 1.6442734003067017\n",
      "830\n",
      "[[[-1.34445051]]]\n",
      "[[-0.91865195]]\n",
      "training for step = 830, loss = 0.7635135054588318\n",
      "831\n",
      "[[[-0.91865195]]]\n",
      "[[-1.00414077]]\n",
      "training for step = 831, loss = 1.0059664249420166\n",
      "832\n",
      "[[[-1.00414077]]]\n",
      "[[-0.76779757]]\n",
      "training for step = 832, loss = 0.6419580578804016\n",
      "833\n",
      "[[[-0.76779757]]]\n",
      "[[-0.03468489]]\n",
      "training for step = 833, loss = 0.010237585753202438\n",
      "834\n",
      "[[[-0.03468489]]]\n",
      "[[0.23421473]]\n",
      "training for step = 834, loss = 0.02015492133796215\n",
      "835\n",
      "[[[0.23421473]]]\n",
      "[[1.55050049]]\n",
      "training for step = 835, loss = 2.1166129112243652\n",
      "836\n",
      "[[[1.55050049]]]\n",
      "[[-0.99835404]]\n",
      "training for step = 836, loss = 1.1313891410827637\n",
      "837\n",
      "[[[-0.99835404]]]\n",
      "[[0.9843224]]\n",
      "training for step = 837, loss = 0.8879759311676025\n",
      "838\n",
      "[[[0.9843224]]]\n",
      "[[-0.21398884]]\n",
      "training for step = 838, loss = 0.06057337671518326\n",
      "839\n",
      "[[[-0.21398884]]]\n",
      "[[-0.04946371]]\n",
      "training for step = 839, loss = 0.004814801272004843\n",
      "840\n",
      "[[[-0.04946371]]]\n",
      "[[0.67481949]]\n",
      "training for step = 840, loss = 0.4342274069786072\n",
      "841\n",
      "[[[0.67481949]]]\n",
      "[[-1.12272202]]\n",
      "training for step = 841, loss = 1.2874219417572021\n",
      "842\n",
      "[[[-1.12272202]]]\n",
      "[[0.38240975]]\n",
      "training for step = 842, loss = 0.14911067485809326\n",
      "843\n",
      "[[[0.38240975]]]\n",
      "[[0.16645221]]\n",
      "training for step = 843, loss = 0.023282837122678757\n",
      "844\n",
      "[[[0.16645221]]]\n",
      "[[0.49245126]]\n",
      "training for step = 844, loss = 0.22647736966609955\n",
      "845\n",
      "[[[0.49245126]]]\n",
      "[[0.28916864]]\n",
      "training for step = 845, loss = 0.0754711702466011\n",
      "846\n",
      "[[[0.28916864]]]\n",
      "[[2.45530014]]\n",
      "training for step = 846, loss = 5.983888149261475\n",
      "847\n",
      "[[[2.45530014]]]\n",
      "[[-0.63773998]]\n",
      "training for step = 847, loss = 0.3817025423049927\n",
      "848\n",
      "[[[-0.63773998]]]\n",
      "[[-0.53099696]]\n",
      "training for step = 848, loss = 0.2476225048303604\n",
      "849\n",
      "[[[-0.53099696]]]\n",
      "[[-0.62314053]]\n",
      "training for step = 849, loss = 0.34094473719596863\n",
      "850\n",
      "[[[-0.62314053]]]\n",
      "[[-0.55547712]]\n",
      "training for step = 850, loss = 0.2790504992008209\n",
      "851\n",
      "[[[-0.55547712]]]\n",
      "[[-0.63738713]]\n",
      "training for step = 851, loss = 0.3997846245765686\n",
      "852\n",
      "[[[-0.63738713]]]\n",
      "[[1.18901653]]\n",
      "training for step = 852, loss = 1.3738534450531006\n",
      "853\n",
      "[[[1.18901653]]]\n",
      "[[1.42050425]]\n",
      "training for step = 853, loss = 1.938605546951294\n",
      "854\n",
      "[[[1.42050425]]]\n",
      "[[-0.57074629]]\n",
      "training for step = 854, loss = 0.3375178277492523\n",
      "855\n",
      "[[[-0.57074629]]]\n",
      "[[-0.83235557]]\n",
      "training for step = 855, loss = 0.6881953477859497\n",
      "856\n",
      "[[[-0.83235557]]]\n",
      "[[0.47141556]]\n",
      "training for step = 856, loss = 0.22953982651233673\n",
      "857\n",
      "[[[0.47141556]]]\n",
      "[[-0.55222304]]\n",
      "training for step = 857, loss = 0.3150387406349182\n",
      "858\n",
      "[[[-0.55222304]]]\n",
      "[[0.63293182]]\n",
      "training for step = 858, loss = 0.386357843875885\n",
      "859\n",
      "[[[0.63293182]]]\n",
      "[[0.20292302]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training for step = 859, loss = 0.03334147110581398\n",
      "860\n",
      "[[[0.20292302]]]\n",
      "[[-1.51574411]]\n",
      "training for step = 860, loss = 2.3543105125427246\n",
      "861\n",
      "[[[-1.51574411]]]\n",
      "[[1.5475052]]\n",
      "training for step = 861, loss = 2.397592067718506\n",
      "862\n",
      "[[[1.5475052]]]\n",
      "[[1.79587767]]\n",
      "training for step = 862, loss = 3.182953119277954\n",
      "863\n",
      "[[[1.79587767]]]\n",
      "[[-0.61278869]]\n",
      "training for step = 863, loss = 0.36154648661613464\n",
      "864\n",
      "[[[-0.61278869]]]\n",
      "[[-0.38770156]]\n",
      "training for step = 864, loss = 0.13095508515834808\n",
      "865\n",
      "[[[-0.38770156]]]\n",
      "[[0.28586539]]\n",
      "training for step = 865, loss = 0.09787900000810623\n",
      "866\n",
      "[[[0.28586539]]]\n",
      "[[0.33445679]]\n",
      "training for step = 866, loss = 0.12257058173418045\n",
      "867\n",
      "[[[0.33445679]]]\n",
      "[[0.65854427]]\n",
      "training for step = 867, loss = 0.44770547747612\n",
      "868\n",
      "[[[0.65854427]]]\n",
      "[[2.01020454]]\n",
      "training for step = 868, loss = 4.088529586791992\n",
      "869\n",
      "[[[2.01020454]]]\n",
      "[[-0.17694723]]\n",
      "training for step = 869, loss = 0.02097225934267044\n",
      "870\n",
      "[[[-0.17694723]]]\n",
      "[[-0.79829724]]\n",
      "training for step = 870, loss = 0.5726462602615356\n",
      "871\n",
      "[[[-0.79829724]]]\n",
      "[[-1.37931923]]\n",
      "training for step = 871, loss = 1.76646089553833\n",
      "872\n",
      "[[[-1.37931923]]]\n",
      "[[-0.73093004]]\n",
      "training for step = 872, loss = 0.4749223589897156\n",
      "873\n",
      "[[[-0.73093004]]]\n",
      "[[-0.03312697]]\n",
      "training for step = 873, loss = 0.0011926707811653614\n",
      "874\n",
      "[[[-0.03312697]]]\n",
      "[[1.79455786]]\n",
      "training for step = 874, loss = 3.0866949558258057\n",
      "875\n",
      "[[[1.79455786]]]\n",
      "[[-0.5176113]]\n",
      "training for step = 875, loss = 0.29625919461250305\n",
      "876\n",
      "[[[-0.5176113]]]\n",
      "[[0.22378795]]\n",
      "training for step = 876, loss = 0.04091138765215874\n",
      "877\n",
      "[[[0.22378795]]]\n",
      "[[-0.0164229]]\n",
      "training for step = 877, loss = 0.001434473553672433\n",
      "878\n",
      "[[[-0.0164229]]]\n",
      "[[1.18839327]]\n",
      "training for step = 878, loss = 1.362837791442871\n",
      "879\n",
      "[[[1.18839327]]]\n",
      "[[2.52693243]]\n",
      "training for step = 879, loss = 6.333566665649414\n",
      "880\n",
      "[[[2.52693243]]]\n",
      "[[-0.53086877]]\n",
      "training for step = 880, loss = 0.25812238454818726\n",
      "881\n",
      "[[[-0.53086877]]]\n",
      "[[-0.48943944]]\n",
      "training for step = 881, loss = 0.20378150045871735\n",
      "882\n",
      "[[[-0.48943944]]]\n",
      "[[1.04416088]]\n",
      "training for step = 882, loss = 1.1920373439788818\n",
      "883\n",
      "[[[1.04416088]]]\n",
      "[[0.68189149]]\n",
      "training for step = 883, loss = 0.5196712017059326\n",
      "884\n",
      "[[[0.68189149]]]\n",
      "[[1.84670733]]\n",
      "training for step = 884, loss = 3.5572726726531982\n",
      "885\n",
      "[[[1.84670733]]]\n",
      "[[0.58392819]]\n",
      "training for step = 885, loss = 0.3998485505580902\n",
      "886\n",
      "[[[0.58392819]]]\n",
      "[[-0.35929209]]\n",
      "training for step = 886, loss = 0.09281396865844727\n",
      "887\n",
      "[[[-0.35929209]]]\n",
      "[[0.59065483]]\n",
      "training for step = 887, loss = 0.432102769613266\n",
      "888\n",
      "[[[0.59065483]]]\n",
      "[[1.10870358]]\n",
      "training for step = 888, loss = 1.3561480045318604\n",
      "889\n",
      "[[[1.10870358]]]\n",
      "[[0.82048218]]\n",
      "training for step = 889, loss = 0.7563433647155762\n",
      "890\n",
      "[[[0.82048218]]]\n",
      "[[0.50727403]]\n",
      "training for step = 890, loss = 0.30728307366371155\n",
      "891\n",
      "[[[0.50727403]]]\n",
      "[[1.06667469]]\n",
      "training for step = 891, loss = 1.2402119636535645\n",
      "892\n",
      "[[[1.06667469]]]\n",
      "[[1.16929559]]\n",
      "training for step = 892, loss = 1.471665859222412\n",
      "893\n",
      "[[[1.16929559]]]\n",
      "[[1.38215899]]\n",
      "training for step = 893, loss = 2.026411533355713\n",
      "894\n",
      "[[[1.38215899]]]\n",
      "[[0.64870989]]\n",
      "training for step = 894, loss = 0.4730677604675293\n",
      "895\n",
      "[[[0.64870989]]]\n",
      "[[-0.16711808]]\n",
      "training for step = 895, loss = 0.01582448184490204\n",
      "896\n",
      "[[[-0.16711808]]]\n",
      "[[0.14671369]]\n",
      "training for step = 896, loss = 0.03897559270262718\n",
      "897\n",
      "[[[0.14671369]]]\n",
      "[[1.20650897]]\n",
      "training for step = 897, loss = 1.556374192237854\n",
      "898\n",
      "[[[1.20650897]]]\n",
      "[[-0.81693567]]\n",
      "training for step = 898, loss = 0.6298352479934692\n",
      "899\n",
      "[[[-0.81693567]]]\n",
      "[[0.36867331]]\n",
      "training for step = 899, loss = 0.16274385154247284\n",
      "900\n",
      "[[[0.36867331]]]\n",
      "[[-0.39333881]]\n",
      "training for step = 900, loss = 0.1472807079553604\n",
      "901\n",
      "[[[-0.39333881]]]\n",
      "[[0.02874482]]\n",
      "training for step = 901, loss = 0.0008974748780019581\n",
      "902\n",
      "[[[0.02874482]]]\n",
      "[[1.27845186]]\n",
      "training for step = 902, loss = 1.584796667098999\n",
      "903\n",
      "[[[1.27845186]]]\n",
      "[[0.19109907]]\n",
      "training for step = 903, loss = 0.02494986355304718\n",
      "904\n",
      "[[[0.19109907]]]\n",
      "[[0.04643655]]\n",
      "training for step = 904, loss = 0.00014163501327857375\n",
      "905\n",
      "[[[0.04643655]]]\n",
      "[[-1.35985614]]\n",
      "training for step = 905, loss = 1.942996859550476\n",
      "906\n",
      "[[[-1.35985614]]]\n",
      "[[0.74625357]]\n",
      "training for step = 906, loss = 0.5454287528991699\n",
      "907\n",
      "[[[0.74625357]]]\n",
      "[[0.64548418]]\n",
      "training for step = 907, loss = 0.36160117387771606\n",
      "908\n",
      "[[[0.64548418]]]\n",
      "[[2.16325472]]\n",
      "training for step = 908, loss = 4.455414295196533\n",
      "909\n",
      "[[[2.16325472]]]\n",
      "[[-0.30777823]]\n",
      "training for step = 909, loss = 0.12347126752138138\n",
      "910\n",
      "[[[-0.30777823]]]\n",
      "[[0.21915033]]\n",
      "training for step = 910, loss = 0.034635208547115326\n",
      "911\n",
      "[[[0.21915033]]]\n",
      "[[0.24938368]]\n",
      "training for step = 911, loss = 0.048302605748176575\n",
      "912\n",
      "[[[0.24938368]]]\n",
      "[[1.57745328]]\n",
      "training for step = 912, loss = 2.388808012008667\n",
      "913\n",
      "[[[1.57745328]]]\n",
      "[[-0.09529553]]\n",
      "training for step = 913, loss = 0.01739760860800743\n",
      "914\n",
      "[[[-0.09529553]]]\n",
      "[[0.27902153]]\n",
      "training for step = 914, loss = 0.06252548098564148\n",
      "915\n",
      "[[[0.27902153]]]\n",
      "[[0.60789651]]\n",
      "training for step = 915, loss = 0.33318963646888733\n",
      "916\n",
      "[[[0.60789651]]]\n",
      "[[0.18660912]]\n",
      "training for step = 916, loss = 0.022357963025569916\n",
      "917\n",
      "[[[0.18660912]]]\n",
      "[[-0.44643361]]\n",
      "training for step = 917, loss = 0.23467306792736053\n",
      "918\n",
      "[[[-0.44643361]]]\n",
      "[[0.19408999]]\n",
      "training for step = 918, loss = 0.026234664022922516\n",
      "919\n",
      "[[[0.19408999]]]\n",
      "[[1.07363175]]\n",
      "training for step = 919, loss = 1.0526865720748901\n",
      "920\n",
      "[[[1.07363175]]]\n",
      "[[-1.0265153]]\n",
      "training for step = 920, loss = 1.1778372526168823\n",
      "921\n",
      "[[[-1.0265153]]]\n",
      "[[0.13296967]]\n",
      "training for step = 921, loss = 0.009674860164523125\n",
      "922\n",
      "[[[0.13296967]]]\n",
      "[[-0.70012081]]\n",
      "training for step = 922, loss = 0.5713307857513428\n",
      "923\n",
      "[[[-0.70012081]]]\n",
      "[[1.19504663]]\n",
      "training for step = 923, loss = 1.3043047189712524\n",
      "924\n",
      "[[[1.19504663]]]\n",
      "[[-1.5231869]]\n",
      "training for step = 924, loss = 2.5530478954315186\n",
      "925\n",
      "[[[-1.5231869]]]\n",
      "[[-0.55892185]]\n",
      "training for step = 925, loss = 0.3554760217666626\n",
      "926\n",
      "[[[-0.55892185]]]\n",
      "[[0.37721188]]\n",
      "training for step = 926, loss = 0.10023770481348038\n",
      "927\n",
      "[[[0.37721188]]]\n",
      "[[1.56552403]]\n",
      "training for step = 927, loss = 2.18454647064209\n",
      "928\n",
      "[[[1.56552403]]]\n",
      "[[-0.06575026]]\n",
      "training for step = 928, loss = 0.023204831406474113\n",
      "929\n",
      "[[[-0.06575026]]]\n",
      "[[-0.55519953]]\n",
      "training for step = 929, loss = 0.40364712476730347\n",
      "930\n",
      "[[[-0.55519953]]]\n",
      "[[1.88115707]]\n",
      "training for step = 930, loss = 3.294337272644043\n",
      "931\n",
      "[[[1.88115707]]]\n",
      "[[-1.4480139]]\n",
      "training for step = 931, loss = 2.296529769897461\n",
      "932\n",
      "[[[-1.4480139]]]\n",
      "[[-2.19880596]]\n",
      "training for step = 932, loss = 4.96950101852417\n",
      "933\n",
      "[[[-2.19880596]]]\n",
      "[[0.44001445]]\n",
      "training for step = 933, loss = 0.202371746301651\n",
      "934\n",
      "[[[0.44001445]]]\n",
      "[[-0.50205422]]\n",
      "training for step = 934, loss = 0.31470996141433716\n",
      "935\n",
      "[[[-0.50205422]]]\n",
      "[[-1.02123282]]\n",
      "training for step = 935, loss = 1.1908220052719116\n",
      "936\n",
      "[[[-1.02123282]]]\n",
      "[[0.70835645]]\n",
      "training for step = 936, loss = 0.40475454926490784\n",
      "937\n",
      "[[[0.70835645]]]\n",
      "[[0.24380071]]\n",
      "training for step = 937, loss = 0.019647693261504173\n",
      "938\n",
      "[[[0.24380071]]]\n",
      "[[-0.56407863]]\n",
      "training for step = 938, loss = 0.4487695097923279\n",
      "939\n",
      "[[[-0.56407863]]]\n",
      "[[-1.2803044]]\n",
      "training for step = 939, loss = 1.8931665420532227\n",
      "940\n",
      "[[[-1.2803044]]]\n",
      "[[0.87245733]]\n",
      "training for step = 940, loss = 0.6337769627571106\n",
      "941\n",
      "[[[0.87245733]]]\n",
      "[[0.65020118]]\n",
      "training for step = 941, loss = 0.2966952621936798\n",
      "942\n",
      "[[[0.65020118]]]\n",
      "[[-0.09917586]]\n",
      "training for step = 942, loss = 0.04068649932742119\n",
      "943\n",
      "[[[-0.09917586]]]\n",
      "[[1.846637]]\n",
      "training for step = 943, loss = 3.0752363204956055\n",
      "944\n",
      "[[[1.846637]]]\n",
      "[[-1.07008477]]\n",
      "training for step = 944, loss = 1.314380168914795\n",
      "945\n",
      "[[[-1.07008477]]]\n",
      "[[-1.52552517]]\n",
      "training for step = 945, loss = 2.480649948120117\n",
      "946\n",
      "[[[-1.52552517]]]\n",
      "[[-0.69190807]]\n",
      "training for step = 946, loss = 0.5107851028442383\n",
      "947\n",
      "[[[-0.69190807]]]\n",
      "[[-0.04558602]]\n",
      "training for step = 947, loss = 0.009829316288232803\n",
      "948\n",
      "[[[-0.04558602]]]\n",
      "[[0.24333945]]\n",
      "training for step = 948, loss = 0.025318816304206848\n",
      "949\n",
      "[[[0.24333945]]]\n",
      "[[-0.24123606]]\n",
      "training for step = 949, loss = 0.11558263748884201\n",
      "950\n",
      "[[[-0.24123606]]]\n",
      "[[0.3520554]]\n",
      "training for step = 950, loss = 0.06401045620441437\n",
      "951\n",
      "[[[0.3520554]]]\n",
      "[[-1.25153942]]\n",
      "training for step = 951, loss = 1.8361895084381104\n",
      "952\n",
      "[[[-1.25153942]]]\n",
      "[[1.4437646]]\n",
      "training for step = 952, loss = 1.8726438283920288\n",
      "953\n",
      "[[[1.4437646]]]\n",
      "[[-0.08215118]]\n",
      "training for step = 953, loss = 0.029259493574500084\n",
      "954\n",
      "[[[-0.08215118]]]\n",
      "[[1.11729583]]\n",
      "training for step = 954, loss = 1.0712207555770874\n",
      "955\n",
      "[[[1.11729583]]]\n",
      "[[0.34272535]]\n",
      "training for step = 955, loss = 0.07229527086019516\n",
      "956\n",
      "[[[0.34272535]]]\n",
      "[[0.45675322]]\n",
      "training for step = 956, loss = 0.15297336876392365\n",
      "957\n",
      "[[[0.45675322]]]\n",
      "[[0.56976728]]\n",
      "training for step = 957, loss = 0.2619374692440033\n",
      "958\n",
      "[[[0.56976728]]]\n",
      "[[0.44770856]]\n",
      "training for step = 958, loss = 0.15609225630760193\n",
      "959\n",
      "[[[0.44770856]]]\n",
      "[[0.64272276]]\n",
      "training for step = 959, loss = 0.35348036885261536\n",
      "960\n",
      "[[[0.64272276]]]\n",
      "[[1.32915253]]\n",
      "training for step = 960, loss = 1.6481850147247314\n",
      "961\n",
      "[[[1.32915253]]]\n",
      "[[0.19652117]]\n",
      "training for step = 961, loss = 0.024367667734622955\n",
      "962\n",
      "[[[0.19652117]]]\n",
      "[[0.70900376]]\n",
      "training for step = 962, loss = 0.45456185936927795\n",
      "963\n",
      "[[[0.70900376]]]\n",
      "[[-0.08973569]]\n",
      "training for step = 963, loss = 0.015170182101428509\n",
      "964\n",
      "[[[-0.08973569]]]\n",
      "[[1.44011722]]\n",
      "training for step = 964, loss = 1.9923628568649292\n",
      "965\n",
      "[[[1.44011722]]]\n",
      "[[-0.6763923]]\n",
      "training for step = 965, loss = 0.5030094981193542\n",
      "966\n",
      "[[[-0.6763923]]]\n",
      "[[1.80094043]]\n",
      "training for step = 966, loss = 3.1732468605041504\n",
      "967\n",
      "[[[1.80094043]]]\n",
      "[[-0.04015795]]\n",
      "training for step = 967, loss = 0.004539491608738899\n",
      "968\n",
      "[[[-0.04015795]]]\n",
      "[[-1.4307751]]\n",
      "training for step = 968, loss = 2.124779224395752\n",
      "969\n",
      "[[[-1.4307751]]]\n",
      "[[0.12810441]]\n",
      "training for step = 969, loss = 0.01709439791738987\n",
      "970\n",
      "[[[0.12810441]]]\n",
      "[[-0.68105166]]\n",
      "training for step = 970, loss = 0.5125392079353333\n",
      "971\n",
      "[[[-0.68105166]]]\n",
      "[[0.84064355]]\n",
      "training for step = 971, loss = 0.6365842223167419\n",
      "972\n",
      "[[[0.84064355]]]\n",
      "[[-0.65262398]]\n",
      "training for step = 972, loss = 0.5186594724655151\n",
      "973\n",
      "[[[-0.65262398]]]\n",
      "[[-0.44618343]]\n",
      "training for step = 973, loss = 0.2608529031276703\n",
      "974\n",
      "[[[-0.44618343]]]\n",
      "[[-1.88954073]]\n",
      "training for step = 974, loss = 3.86202073097229\n",
      "975\n",
      "[[[-1.88954073]]]\n",
      "[[-0.45230632]]\n",
      "training for step = 975, loss = 0.24736244976520538\n",
      "976\n",
      "[[[-0.45230632]]]\n",
      "[[-2.42387933]]\n",
      "training for step = 976, loss = 6.329752445220947\n",
      "977\n",
      "[[[-2.42387933]]]\n",
      "[[-1.58390282]]\n",
      "training for step = 977, loss = 2.658208131790161\n",
      "978\n",
      "[[[-1.58390282]]]\n",
      "[[0.76041466]]\n",
      "training for step = 978, loss = 0.468666136264801\n",
      "979\n",
      "[[[0.76041466]]]\n",
      "[[0.78580016]]\n",
      "training for step = 979, loss = 0.42781272530555725\n",
      "980\n",
      "[[[0.78580016]]]\n",
      "[[0.42545756]]\n",
      "training for step = 980, loss = 0.08468905091285706\n",
      "981\n",
      "[[[0.42545756]]]\n",
      "[[-0.96697614]]\n",
      "training for step = 981, loss = 1.1961435079574585\n",
      "982\n",
      "[[[-0.96697614]]]\n",
      "[[-0.04771136]]\n",
      "training for step = 982, loss = 0.021049754694104195\n",
      "983\n",
      "[[[-0.04771136]]]\n",
      "[[-0.00360254]]\n",
      "training for step = 983, loss = 0.011363852769136429\n",
      "984\n",
      "[[[-0.00360254]]]\n",
      "[[-1.15836469]]\n",
      "training for step = 984, loss = 1.5923348665237427\n",
      "985\n",
      "[[[-1.15836469]]]\n",
      "[[1.5033983]]\n",
      "training for step = 985, loss = 2.0403146743774414\n",
      "986\n",
      "[[[1.5033983]]]\n",
      "[[0.87736229]]\n",
      "training for step = 986, loss = 0.6156697869300842\n",
      "987\n",
      "[[[0.87736229]]]\n",
      "[[-0.22096417]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training for step = 987, loss = 0.0958307534456253\n",
      "988\n",
      "[[[-0.22096417]]]\n",
      "[[0.02688584]]\n",
      "training for step = 988, loss = 0.0023473238106817007\n",
      "989\n",
      "[[[0.02688584]]]\n",
      "[[0.20838281]]\n",
      "training for step = 989, loss = 0.01903516985476017\n",
      "990\n",
      "[[[0.20838281]]]\n",
      "[[-2.04173487]]\n",
      "training for step = 990, loss = 4.46319580078125\n",
      "991\n",
      "[[[-2.04173487]]]\n",
      "[[-0.24717738]]\n",
      "training for step = 991, loss = 0.0626509040594101\n",
      "992\n",
      "[[[-0.24717738]]]\n",
      "[[-0.68198425]]\n",
      "training for step = 992, loss = 0.5302519798278809\n",
      "993\n",
      "[[[-0.68198425]]]\n",
      "[[-1.00162001]]\n",
      "training for step = 993, loss = 1.113189697265625\n",
      "994\n",
      "[[[-1.00162001]]]\n",
      "[[-0.28110029]]\n",
      "training for step = 994, loss = 0.11220637708902359\n",
      "995\n",
      "[[[-0.28110029]]]\n",
      "[[1.79768653]]\n",
      "training for step = 995, loss = 2.9486122131347656\n",
      "996\n",
      "[[[1.79768653]]]\n",
      "[[0.64084286]]\n",
      "training for step = 996, loss = 0.30501216650009155\n",
      "997\n",
      "[[[0.64084286]]]\n",
      "[[-0.57117899]]\n",
      "training for step = 997, loss = 0.43489089608192444\n",
      "998\n",
      "[[[-0.57117899]]]\n",
      "[[0.57258278]]\n",
      "training for step = 998, loss = 0.255359947681427\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(x)):\n",
    "    print(i)\n",
    "    print(x[i: i + 1])\n",
    "    print(y[i: i + 1])\n",
    "    loss = model.train_on_batch(x[i: i + 1], y[i: i + 1])\n",
    "    print(\"training for step = {}, loss = {}\".format(i, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
